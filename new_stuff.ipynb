{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbaremoney/UpsetsPropertiesThresholds/blob/main/new_stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a few installs and loaders for datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "g-B5ohw4lpl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQKvbH-zlovc",
        "outputId": "756a6184-1b5b-4e81-9204-7a93259966eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.23.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.8.28)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYxWZLZ0lfhr"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import random\n",
        "import torch.autograd as autograd\n",
        "import math\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from matplotlib import pyplot as plt\n",
        "from itertools import combinations_with_replacement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH2n9fbslyCX",
        "outputId": "3895fe74-7b86-475a-e93d-95b36e734299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  6 19:29:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             42W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPq20c4zl0T0",
        "outputId": "a3fcf207-9267-480b-b5b4-56a73b3b246c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTrainingDataLoaders(data_set_name, download=True, BATCH_SIZE=128):\n",
        "    data_flag = data_set_name\n",
        "\n",
        "    info = INFO[data_flag]\n",
        "    task = info['task']\n",
        "    n_channels = info['n_channels']\n",
        "    n_classes = len(info['label'])\n",
        "\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "    # RGBtransform = transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x)\n",
        "\n",
        "    # preprocessing\n",
        "    if n_channels == 3:\n",
        "        data_transform = v2.Compose([\n",
        "            v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "            v2.Normalize(mean=[.5], std=[.5])\n",
        "        ])\n",
        "\n",
        "    if n_channels == 1:\n",
        "        data_transform = v2.Compose([\n",
        "            v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
        "            v2.RGB(),\n",
        "            v2.Normalize(mean=[.5], std=[.5])\n",
        "        ])\n",
        "\n",
        "    # load the data\n",
        "    train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "    test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "    pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "    # encapsulate data into dataloader form\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "    return info, task, n_classes, train_loader, train_loader_at_eval, test_loader"
      ],
      "metadata": {
        "id": "6Odkl4L8l4Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset, Sampler\n",
        "from torchvision.transforms import v2\n",
        "import random\n",
        "import math\n",
        "\n",
        "# --- your PaddedMedMNIST as-is ---\n",
        "TARGET_LENGTH = 14\n",
        "\n",
        "class PaddedMedMNIST(Dataset):\n",
        "    def __init__(self, dataset, target_length=TARGET_LENGTH):\n",
        "        self.dataset = dataset\n",
        "        self.target_length = target_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[idx]\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        padded = torch.zeros(self.target_length, dtype=torch.float32)\n",
        "        padded[:label.numel()] = label\n",
        "        return img, padded\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "# --- Balanced batch sampler ---\n",
        "class BalancedBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Yields batches with (approximately) equal counts from each sub-dataset inside a ConcatDataset.\n",
        "\n",
        "    Args:\n",
        "        concat_ds: ConcatDataset([...])\n",
        "        batch_size: total batch size\n",
        "        strategy: 'upsample' (with replacement so every batch is balanced across entire epoch)\n",
        "                  or 'min' (stop when any dataset can't fill its share; no replacement)\n",
        "        drop_last: drop final incomplete batch (recommended True)\n",
        "        generator: optional torch.Generator for reproducibility\n",
        "    \"\"\"\n",
        "    def __init__(self, concat_ds: ConcatDataset, batch_size: int,\n",
        "                 strategy: str = \"upsample\", drop_last: bool = True,\n",
        "                 generator: torch.Generator | None = None):\n",
        "        assert isinstance(concat_ds, ConcatDataset), \"BalancedBatchSampler requires a ConcatDataset\"\n",
        "        self.concat_ds = concat_ds\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.K = len(concat_ds.datasets)\n",
        "        assert self.K >= 2, \"Need at least 2 datasets to balance.\"\n",
        "        assert self.batch_size >= self.K, \"batch_size must be >= number of datasets\"\n",
        "\n",
        "        # Per-dataset shares sum to batch_size (distribute any remainder to the first few datasets).\n",
        "        base = self.batch_size // self.K\n",
        "        extra = self.batch_size % self.K\n",
        "        self.shares = [base + (1 if i < extra else 0) for i in range(self.K)]\n",
        "\n",
        "        self.lengths = [len(ds) for ds in concat_ds.datasets]\n",
        "        self.offsets = []\n",
        "        running = 0\n",
        "        for L in self.lengths:\n",
        "            self.offsets.append(running)\n",
        "            running += L\n",
        "\n",
        "        self.strategy = strategy\n",
        "        self.drop_last = drop_last\n",
        "        self.gen = generator\n",
        "\n",
        "        # Precompute how many *balanced* batches we can make without replacement (for 'min').\n",
        "        self.max_full_batches_min = min(\n",
        "            (L // s) if s > 0 else 0\n",
        "            for L, s in zip(self.lengths, self.shares)\n",
        "        )\n",
        "\n",
        "        # For 'upsample', define epoch length as number of batches ≈ total_len / batch_size\n",
        "        total_len = sum(self.lengths)\n",
        "        self.num_batches_upsample = max(1, total_len // self.batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.strategy == \"min\":\n",
        "            return self.max_full_batches_min\n",
        "        else:  # 'upsample'\n",
        "            return self.num_batches_upsample\n",
        "\n",
        "    def _randperm(self, n):\n",
        "        if self.gen is None:\n",
        "            return torch.randperm(n)\n",
        "        return torch.randperm(n, generator=self.gen)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Build per-dataset index pools (local indices)\n",
        "        pools = []\n",
        "        for k, L in enumerate(self.lengths):\n",
        "            order = self._randperm(L).tolist()\n",
        "            pools.append(order)\n",
        "\n",
        "        if self.strategy == \"min\":\n",
        "            num_batches = self.max_full_batches_min\n",
        "            for _ in range(num_batches):\n",
        "                batch = []\n",
        "                for k in range(self.K):\n",
        "                    take = self.shares[k]\n",
        "                    # pop 'take' elements from the pool (no replacement)\n",
        "                    chosen_local = pools[k][:take]\n",
        "                    pools[k] = pools[k][take:]\n",
        "                    # map to global indices via offset\n",
        "                    off = self.offsets[k]\n",
        "                    batch.extend([off + i for i in chosen_local])\n",
        "                yield batch\n",
        "            # If not dropping last and any remainder exists (rare with this scheme), we could add a small final batch.\n",
        "            # But by design with 'min' we usually keep batches uniform and drop incomplete ones.\n",
        "            if not self.drop_last:\n",
        "                # Attempt to form one last (possibly smaller) balanced-ish batch\n",
        "                leftovers = []\n",
        "                for k in range(self.K):\n",
        "                    take = min(self.shares[k], len(pools[k]))\n",
        "                    off = self.offsets[k]\n",
        "                    leftovers.extend([off + i for i in pools[k][:take]])\n",
        "                if len(leftovers) > 0:\n",
        "                    yield leftovers\n",
        "\n",
        "        else:  # 'upsample' with replacement from small datasets\n",
        "            num_batches = self.num_batches_upsample\n",
        "            for _ in range(num_batches):\n",
        "                batch = []\n",
        "                for k in range(self.K):\n",
        "                    take = self.shares[k]\n",
        "                    off = self.offsets[k]\n",
        "                    pool = pools[k]\n",
        "                    if len(pool) < take:\n",
        "                        # Re-shuffle / top-up this pool\n",
        "                        pool.extend(self._randperm(self.lengths[k]).tolist())\n",
        "                    chosen_local = pool[:take]\n",
        "                    del pool[:take]\n",
        "                    batch.extend([off + i for i in chosen_local])\n",
        "                yield batch\n",
        "\n",
        "\n",
        "# --- Your loader builder, swapped to use the BalancedBatchSampler ---\n",
        "def get_combined_medmnist_loader(dataset_names, batch_size=128, download=True, train=True,\n",
        "                                 strategy: str = \"upsample\", drop_last: bool = True,\n",
        "                                 num_workers: int = 4, pin_memory: bool = True):\n",
        "    all_datasets = []\n",
        "\n",
        "    for name in dataset_names:\n",
        "        info = INFO[name]\n",
        "        DataClass = getattr(medmnist, info['python_class'])\n",
        "        n_channels = info['n_channels']\n",
        "\n",
        "        if n_channels == 3:\n",
        "            transform = v2.Compose([\n",
        "                v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
        "            ])\n",
        "        else:\n",
        "            transform = v2.Compose([\n",
        "                v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
        "                v2.RGB(),  # force 3 channels\n",
        "                v2.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
        "            ])\n",
        "\n",
        "        split = 'train' if train else 'test'\n",
        "        raw_dataset = DataClass(split=split, transform=transform, download=download)\n",
        "        padded_dataset = PaddedMedMNIST(raw_dataset)\n",
        "        all_datasets.append(padded_dataset)\n",
        "\n",
        "    combined_dataset = ConcatDataset(all_datasets)\n",
        "    batch_sampler = BalancedBatchSampler(\n",
        "        combined_dataset, batch_size=batch_size, strategy=strategy, drop_last=drop_last\n",
        "    )\n",
        "\n",
        "    # IMPORTANT: when using batch_sampler, do not also pass batch_size/shuffle/sampler\n",
        "    loader = DataLoader(\n",
        "        combined_dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "    )\n",
        "    return loader"
      ],
      "metadata": {
        "id": "Bonoxbvkl66l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, on to the good stuff!"
      ],
      "metadata": {
        "id": "Tp3DfdBRl7ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes,bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            *[z for l in layer_sizes\n",
        "              for z in [nn.Linear(l[0], l[1],bias=bias), nn.ReLU()]][:-1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# Set up signed Kaiming initialization.\n",
        "def signed_kaiming_constant_(tensor, a=0, mode='fan_in', nonlinearity='relu', k=0.5, sparsity=0):\n",
        "\n",
        "    fan = nn.init._calculate_correct_fan(tensor, mode)  # calculating correct fan, depends on shape and type of nn\n",
        "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
        "    std = (gain / math.sqrt(fan))\n",
        "    # scale by (1/sqrt(k))\n",
        "    if k != 0:\n",
        "        std *= (1 / math.sqrt(k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tensor.uniform_(-std, std)\n",
        "        if sparsity > 0:\n",
        "            mask = (torch.rand_like(tensor) > sparsity).float()  # Keeps (1 - sparsity)% weights\n",
        "\n",
        "            tensor *= mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "# A function to retreive a subset of the top k% of the weights by their score.\n",
        "# The gradient is estimated by the identity (i.e. it goes \"straight-through\").\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "\n",
        "        # Get the subnetwork by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1-k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return grad, None\n",
        "\n",
        "# Our maskable replacement for the standard linear layer in torch.\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "class LinearSubnet(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "\n",
        "        self.k = k\n",
        "        self.popup_scores = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "        self.popup_scores_extra = nn.Parameter(torch.randn(out_features, in_features), requires_grad=True)\n",
        "        self.bias_popup_scores_extra = nn.Parameter(torch.randn(out_features), requires_grad=True)\n",
        "\n",
        "        self.initial_popup_scores = self.popup_scores.clone()\n",
        "        self.initial_bias_popup_scores = self.bias_popup_scores.clone()\n",
        "\n",
        "        # Initialize weights\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "\n",
        "        self.weight.requires_grad_(False)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(False)\n",
        "    def return_to_initial_popup_scores(self):\n",
        "        self.popup_scores = nn.Parameter(self.initial_popup_scores.clone(),requires_grad=True)\n",
        "        self.bias_popup_scores = nn.Parameter(self.initial_bias_popup_scores.clone(),requires_grad=True)\n",
        "        print('Popup Scores Returned to Initial Values')\n",
        "\n",
        "    def forward(self, x):\n",
        "        adj = GetSubnet.apply(\n",
        "            torch.cat((self.popup_scores.abs(),self.popup_scores_extra.abs()),dim=-1), self.k\n",
        "        )[:, :self.weight.shape[-1]]\n",
        "        bias_adj = GetSubnet.apply(\n",
        "            torch.cat((self.bias_popup_scores.abs(),self.bias_popup_scores_extra.abs()), dim=-1), self.k\n",
        "        )[:self.bias.shape[-1]]\n",
        "\n",
        "        w = self.weight * adj\n",
        "        b = self.bias * bias_adj\n",
        "        return F.linear(x, w, b)\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, layer_sizes, k=0.5, init=signed_kaiming_constant_):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "            self.layers.append(LinearSubnet(in_f, out_f,k=k,init=init))\n",
        "            if i < len(layer_sizes) - 1:\n",
        "                self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1:] != (3, 28, 28):\n",
        "          print(x.shape)\n",
        "          x.unsqueeze_(0)\n",
        "          x = x.repeat(3, 1, 1)\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RKujrQGXl_za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a training function that returns a list of the losses during training.\n",
        "def trainit(model,\n",
        "            NUM_EPOCHS,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            task,\n",
        "            n_classes,\n",
        "            return_losses=False,\n",
        "            no_progress=False):\n",
        "  # define loss function\n",
        "  if task == \"multi-label, binary-class\":\n",
        "      criterion = nn.BCEWithLogitsLoss()\n",
        "  else:\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "  if return_losses:\n",
        "      losses = []\n",
        "  # iterate over epochs for training run\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "      model.train()\n",
        "      if no_progress:\n",
        "        loader = train_loader\n",
        "      else:\n",
        "        loader=tqdm(train_loader)\n",
        "      for inputs, targets in loader:\n",
        "          inputs  = inputs.to(device, non_blocking=True)\n",
        "          targets = targets.to(device, non_blocking=True)\n",
        "          # forward + backward + optimize\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)[:,0:n_classes]\n",
        "          if task == 'multi-label, binary-class':\n",
        "              targets = targets.to(torch.float32)\n",
        "              loss = criterion(outputs, targets)\n",
        "          else:\n",
        "              targets = targets.squeeze(1)\n",
        "              loss = criterion(outputs, targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if return_losses:\n",
        "              losses.append(loss.item())\n",
        "  if return_losses:\n",
        "      return losses\n",
        "\n",
        "# Define an evaluation function\n",
        "def test(split,\n",
        "         model,\n",
        "         train_loader_at_eval,\n",
        "         test_loader,\n",
        "         task,\n",
        "         n_classes,\n",
        "         data_flag,\n",
        "         return_metrics=False):\n",
        "    # define loss function\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            # inputs  = inputs.to(device, non_blocking=True)\n",
        "            # targets = targets.to(device, non_blocking=True)\n",
        "            outputs = model(inputs)[:,0:n_classes]\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze(1)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "        if return_metrics:\n",
        "          return metrics"
      ],
      "metadata": {
        "id": "oUaM9_BmmTe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's actually run the dang thing.  Notice, the number of epochs is REALLY high here, since convergence takes a super long time in this case."
      ],
      "metadata": {
        "id": "Zc-cc3KEmanD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "data_set_name = 'breastmnist'\n",
        "info, task, n_classes, train_loader, train_loader_at_eval, test_loader = getTrainingDataLoaders(data_set_name)\n",
        "layer_sizes=[[3*28*28, 256],[256,256],[256, n_classes]]\n",
        "NUM_EPOCHS = 1000\n",
        "\n",
        "model = Network(layer_sizes=layer_sizes,k=0.5)\n",
        "model.to(device)\n",
        "router_train_score=[]\n",
        "\n",
        "losses=trainit(model,NUM_EPOCHS,train_loader,optim.Adam(model.parameters()),task='multi-class',n_classes=14, return_losses=True)\n",
        "router_train_score.append(losses)\n",
        "\n",
        "classicmodel = ClassicNetwork(layer_sizes=layer_sizes)\n",
        "classicmodel.to(device)\n",
        "classic_train_score=[]\n",
        "losses=trainit(classicmodel,NUM_EPOCHS,train_loader,optim.Adam(classicmodel.parameters()),task='multi-class',n_classes=14, return_losses=True)\n",
        "classic_train_score.append(losses)\n",
        "\n",
        "plt.plot(router_train_score[0], label='Masking')\n",
        "plt.plot(classic_train_score[0], label='Classical')\n",
        "plt.legend()\n",
        "ax = plt.gca()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "# plt.yscale('log')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lnGvSGAkmWyV",
        "outputId": "2739d4e3-bde2-4bbd-c4d6-04d2dcc85daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560k/560k [00:00<00:00, 655kB/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 20.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 13.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 21.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 13.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 14.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 13.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 22.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 21.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 21.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 21.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 23.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 24.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 13.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 14.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.74it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.03it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.80it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.49it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.13it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.44it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.23it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.69it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.67it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 14.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.99it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.05it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.68it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.85it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.53it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.48it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.58it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.77it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.90it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.40it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.33it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.16it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.32it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.78it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.61it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.34it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.93it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.87it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.24it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.70it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.97it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.83it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.94it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.37it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.71it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.25it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.95it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.38it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.07it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.84it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.11it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.72it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.55it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.65it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.27it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.06it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.62it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.50it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.82it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28.14it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.10it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.47it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.22it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.79it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.66it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.43it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.39it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.59it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.81it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.01it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.91it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.20it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.18it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.76it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.15it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.12it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.00it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 27.39it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, now on to the fancy stuff.\n",
        "\n",
        "First off, a recursive router:"
      ],
      "metadata": {
        "id": "Pm_5Gknnm1ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes,bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            *[z for l in layer_sizes\n",
        "              for z in [nn.Linear(l[0], l[1],bias=bias), nn.ReLU()]][:-1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# Set up signed Kaiming initialization.\n",
        "def signed_kaiming_constant_(tensor, a=0, mode='fan_in', nonlinearity='relu', k=0.5, sparsity=0):\n",
        "\n",
        "    fan = nn.init._calculate_correct_fan(tensor, mode)  # calculating correct fan, depends on shape and type of nn\n",
        "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
        "    std = (gain / math.sqrt(fan))\n",
        "    # scale by (1/sqrt(k))\n",
        "    if k != 0:\n",
        "        std *= (1 / math.sqrt(k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tensor.uniform_(-std, std)\n",
        "        if sparsity > 0:\n",
        "            mask = (torch.rand_like(tensor) > sparsity).float()  # Keeps (1 - sparsity)% weights\n",
        "\n",
        "            tensor *= mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "# A function to retreive a subset of the top k% of the weights by their score.\n",
        "# The gradient is estimated by the identity (i.e. it goes \"straight-through\").\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "\n",
        "        # Get the subnetwork by sorting the scores and using the top k%\n",
        "        out = scores.clone()\n",
        "        _, idx = scores.flatten().sort()\n",
        "        j = int((1-k) * scores.numel())\n",
        "\n",
        "        # flat_out and out access the same memory.\n",
        "        flat_out = out.flatten()\n",
        "        flat_out[idx[:j]] = 0\n",
        "        flat_out[idx[j:]] = 1\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "\n",
        "        # send the gradient g straight-through on the backward pass.\n",
        "        return grad, None\n",
        "\n",
        "# Our maskable replacement for the standard linear layer in torch.\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "class LinearSubnet(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, max_recurse_depth=1, router_width=1, bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "\n",
        "        self.k = k\n",
        "        # self.m = m  # number of score choices\n",
        "        # self.used = {}\n",
        "        self.recurse_depth = 1\n",
        "        self.max_recurse_depth = max_recurse_depth\n",
        "        # Define m sets of pop-up scores\n",
        "        self.popup_scores = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(out_features, in_features)) for _ in range(self.max_recurse_depth)\n",
        "        ])\n",
        "        self.bias_popup_scores = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(out_features)) for _ in range(self.max_recurse_depth)\n",
        "        ])\n",
        "        self.popup_scores_extra = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(out_features, in_features)) for _ in range(self.max_recurse_depth)\n",
        "        ])\n",
        "        self.bias_popup_scores_extra = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(out_features)) for _ in range(self.max_recurse_depth)\n",
        "        ])\n",
        "\n",
        "        # Define a router that chooses between m options\n",
        "        self.router = ClassicNetwork(layer_sizes=[\n",
        "            [in_features, router_width],\n",
        "            [router_width, self.max_recurse_depth+1]\n",
        "        ],bias=False)\n",
        "\n",
        "        # Initialize weights\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "\n",
        "        self.weight.requires_grad_(True)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        device = x.device\n",
        "\n",
        "        # [B, m]: scores for each of the m pop-up configurations\n",
        "        router_logits = self.router(x)[:, :-1]\n",
        "        recurse = (self.router(x)[:,-1]>0)\n",
        "        selected = torch.argmax(router_logits, dim=-1)  # [B]\n",
        "        # round=max(k for k in self.used.keys()) + 1 if bool(self.used) else 0\n",
        "        # self.used[round] = [0 for _ in range(self.m)]\n",
        "        # for i in range(self.m):\n",
        "        #   self.used[round][i]+=(selected == i).count_nonzero().item()\n",
        "\n",
        "\n",
        "        # Create empty masked weights for each sample in batch\n",
        "        weight = torch.zeros((B, self.out_features, self.in_features), device=device)\n",
        "        bias = torch.zeros((B, self.out_features), device=device)\n",
        "\n",
        "        for i in range(self.max_recurse_depth):\n",
        "            idx = (selected == i).nonzero(as_tuple=True)[0]\n",
        "            if idx.numel() == 0:\n",
        "                continue  # skip if no samples selected this mask\n",
        "\n",
        "            adj = GetSubnet.apply(\n",
        "                torch.cat((self.popup_scores[i].abs(), self.popup_scores_extra[i].abs()), dim=-1), self.k\n",
        "            )\n",
        "            bias_adj = GetSubnet.apply(\n",
        "                torch.cat((self.bias_popup_scores[i].abs(), self.bias_popup_scores_extra[i].abs()), dim=-1), self.k\n",
        "            )\n",
        "\n",
        "            # Generate mask for top-k of the chosen score\n",
        "            mask = GetSubnet.apply(self.popup_scores[i].abs(), self.k)\n",
        "            bias_mask = GetSubnet.apply(self.bias_popup_scores[i].abs(), self.k)\n",
        "\n",
        "            # Apply mask to weights and assign to appropriate batch elements\n",
        "            weight[idx] = self.weight * adj[:, :self.weight.shape[-1]]\n",
        "            bias[idx] = self.bias * bias_adj[:self.bias.shape[-1]]\n",
        "\n",
        "        # Perform batched linear op: [B, out_features] = [B, out, in] @ [B, in, 1]\n",
        "        out = torch.bmm(weight, x.unsqueeze(-1)).squeeze(-1) + bias\n",
        "        if not torch.any(recurse) or self.recurse_depth==self.max_recurse_depth:\n",
        "            return out\n",
        "        else:\n",
        "            self.recurse_depth+=1\n",
        "            recurse = (recurse.squeeze() > 0)\n",
        "            new_out=self.forward(out)\n",
        "            updated=out.clone()\n",
        "            updated[recurse,:]=new_out[recurse,:]\n",
        "            return updated\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, in_size,out_size,hidden_size,max_recurse_depth,router_width, k=0.5, init=signed_kaiming_constant_,):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(LinearSubnet(in_size, hidden_size,max_recurse_depth=1, router_width=router_width, k=k,init=init))\n",
        "        self.layers.append(nn.ReLU())\n",
        "        self.layers.append(LinearSubnet(hidden_size, hidden_size, max_recurse_depth=max_recurse_depth, router_width=router_width, k=k,init=init))\n",
        "        self.layers.append(nn.ReLU())\n",
        "        self.layers.append(LinearSubnet(hidden_size, out_size, max_recurse_depth=1, router_width=router_width, k=k,init=init))\n",
        "    def forward(self, x):\n",
        "        if x.shape[1:] != (3, 28, 28):\n",
        "          print(x.shape)\n",
        "          x.unsqueeze_(0)\n",
        "          x = x.repeat(3, 1, 1)\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OSpXHZaunPNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "data_set_name = 'breastmnist'\n",
        "info, task, n_classes, train_loader, train_loader_at_eval, test_loader = getTrainingDataLoaders(data_set_name)\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "model = Network(3*28*28,n_classes,64,10,64,k=0.5)\n",
        "model.to(device)\n",
        "router_losses=trainit(model,NUM_EPOCHS,train_loader,optim.Adam(model.parameters()),task=task,n_classes=n_classes, return_losses=True)\n",
        "classicmodel = ClassicNetwork(layer_sizes=[[3*28*28,32],[32,32],[32,n_classes]])\n",
        "classicmodel.to(device)\n",
        "\n",
        "classic_losses=trainit(classicmodel,NUM_EPOCHS,train_loader,optim.Adam(classicmodel.parameters()),task='multi-class',n_classes=n_classes, return_losses=True)\n",
        "\n",
        "plt.plot(router_losses, label='Recursive Masking')\n",
        "plt.plot(classic_losses, label='Classical')\n",
        "plt.legend()\n",
        "ax = plt.gca()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "plt.yscale('log')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "j9-8dfclnR9y",
        "outputId": "73e38602-1333-448e-ca73-556e54fcbf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00,  6.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.21it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.19it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 18.73it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.09it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 19.46it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 18.54it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 18.51it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.57it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.98it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.92it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.29it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.64it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.96it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.08it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.86it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAGFCAYAAAAYSTzrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqBxJREFUeJzsnXeYVOXZ/79n6u7OzvbGso2ldxAUEZEuEiRKbFGMRqP+NBALGqOJ0eSNJTFREw1RX2NPDJhYkjcgShGRotQF6UvbZZftvU87vz+e85w5MzvlTNuZde/PdXHN7JlTni3M+c59f+/7FkRRFEEQBEEQBEFAE+0FEARBEARBxAokjAiCIAiCICRIGBEEQRAEQUiQMCIIgiAIgpAgYUQQBEEQBCFBwoggCIIgCEKChBFBEARBEISELtoL6G84HA6cP38eZrMZgiBEezkEQRAEQahAFEW0tbUhNzcXGo33uBAJowA5f/488vPzo70MgiAIgiCC4Ny5c8jLy/P6OgmjADGbzQDYDzYpKSnKqyEIgiAIQg2tra3Iz8+X7+PeIGEUIDx9lpSURMKIIAiCIPoZ/mwwZL4mCIIgCIKQIGFEEARBEAQhQcKIIAiCIAhCgjxGBEEQBADAbrfDarVGexkEERR6vR5arTbk85AwIgiCGOCIoojq6mo0NzdHeykEERIpKSnIyckJqc8gCSOCIIgBDhdFWVlZSEhIoOa1RL9DFEV0dnaitrYWADBo0KCgz0XCiCAIYgBjt9tlUZSenh7t5RBE0MTHxwMAamtrkZWVFXRajczXBEEQAxjuKUpISIjySggidPjfcSheORJGBEEQBKXPiG8F4fg7JmFEEARBEAQhMaCF0dKlS5Gamoprr7022kshCIIgBhCCIODjjz+O9jLCxpYtWyAIgtfKxrNnz0IQBJSUlPTpuoJhQAuj++67D++88060l0EQBEEEwQ9/+EMIggBBEKDX6zFkyBA8/PDD6O7ujvbS/FJVVYVFixZF9BpFRUUQBAGrV6/u9drYsWMhCALeeuutiK6Bk5+fj6qqKowbN65PrhcKA1oYzZ492++UXYIgCCJ2ueKKK1BVVYXTp0/jhRdewKuvvoonnngiqmuyWCx+98nJyYHRaIz4WvLz8/Hmm2+6bPvqq69QXV0Nk8kU8etztFotcnJyoNPFfjF8wMKIK1D3f8uXLw/borZu3YolS5YgNzfXZ7hx1apVKCoqQlxcHKZNm4Zdu3aFbQ0DHbtDxIr39uGFDSeivRSCIAivGI1G5OTkID8/H1dffTXmz5+PDRs2yK87HA4888wzGDJkCOLj4zFx4kT861//cjnH4cOHceWVVyIpKQlmsxkzZ87EqVOnALAP0Pfff7/L/ldffTV++MMfyl8XFRXhN7/5DW655RYkJSXhrrvugsViwYoVKzBo0CDExcWhsLAQzzzzjHyM8t52ySWX4Gc/+5nLNerq6qDX67F161YAQE9PDx566CEMHjwYJpMJ06ZNw5YtW/z+fJYtW4YvvvgC586dk7e98cYbWLZsWS+R8vzzz2P8+PEwmUzIz8/Hj3/8Y7S3t8uvl5WVYcmSJUhNTYXJZMLYsWOxbt06j9ft7OzEokWLMGPGDDQ3N/dKpfHU26ZNmzB16lQkJCTgkksuwfHjx13O8+STTyIrKwtmsxl33HEHHnnkEUyaNMnv9x0KAQuj3bt3o6qqSv7H/wCvu+46j/tv377dY9nckSNHUFNT4/GYjo4OTJw4EatWrfK6jjVr1mDlypV44oknsG/fPkycOBELFy6UmzsBwKRJkzBu3Lhe/86fPx/ItzwgOVrViv8erMJftpyE3SFGezkEQfQhoiii02KLyj9RDP795tChQ9ixYwcMBoO87ZlnnsE777yDV155BYcPH8YDDzyAm2++GV988QUAoLKyEpdddhmMRiM2b96MvXv34vbbb4fNZgvo2n/4wx8wceJE7N+/H7/85S/x4osv4j//+Q/ef/99HD9+HH//+99RVFTk8dhly5Zh9erVLt/7mjVrkJubi5kzZwIAVqxYgZ07d2L16tU4ePAgrrvuOlxxxRUoLS31ua7s7GwsXLgQb7/9NgAmWNasWYPbb7+9174ajQYvvvgiDh8+jLfffhubN2/Gww8/LL++fPly9PT0YOvWrfjmm2/wu9/9DomJib3O09zcjAULFsDhcGDDhg1ISUnxur5f/OIXeO6557Bnzx7odDqXdf3973/HU089hd/97nfYu3cvCgoK8PLLL/v8fsNBwDGtzMxMl69/+9vfYujQoZg1a1avfR0OB5YvX47hw4dj9erVcrOl48ePY+7cuVi5cqXLD52zaNEiv7nX559/HnfeeSduu+02AMArr7yCtWvX4o033sAjjzwCAP3C5BWrnGvsBABY7SLON3chP416nBDEQKHLaseYxz+NyrWP/M9CJBjU35r++9//IjExETabDT09PdBoNPjzn/8MgEVZnn76aWzcuBHTp08HABQXF2Pbtm149dVXMWvWLKxatQrJyclYvXo19Ho9AGDEiBEBr3vu3Ll48MEH5a/Ly8sxfPhwXHrppRAEAYWFhV6Pvf7663H//fdj27ZtshB67733cOONN0IQBJSXl+PNN99EeXk5cnNzAQAPPfQQ1q9fjzfffBNPP/20z7XdfvvtePDBB/GLX/wC//rXvzB06FCPURdlZKyoqAhPPvkk7r77bvzlL3+Rv6drrrkG48ePB8B+lu5UV1fjhhtuwPDhw/Hee++5iFRPPPXUU7J+eOSRR7B48WJ0d3cjLi4OL730En70ox/J9/nHH38cn332mUsUKxKE5DGyWCz429/+httvv91j7wCNRoN169Zh//79uOWWW+BwOHDq1CnMnTsXV199tUdRpPa6e/fuxfz5812uNX/+fOzcuTPo78cXq1atwpgxY3DhhRdG5PyxRkVTl/y8XBJJBEEQscacOXNQUlKCr7/+Grfeeituu+02XHPNNQCAkydPorOzEwsWLEBiYqL875133pFTZSUlJZg5c6YsioJl6tSpLl//8Ic/RElJCUaOHIl7770Xn332mddjMzMzcfnll+Pvf/87AODMmTPYuXMnli1bBgD45ptvYLfbMWLECJfv44svvpC/D18sXrwY7e3t2Lp1K9544w2P0SIA2LhxI+bNm4fBgwfDbDbjBz/4ARoaGtDZye4B9957L5588knMmDEDTzzxBA4ePNjrHAsWLMCwYcOwZs0av6IIACZMmCA/52M8eObn+PHjuOiii1z2d/86EoTkgvr444/R3Nzskmt1Jzc3F5s3b8bMmTNx0003YefOnZg/f35I4bD6+nrY7XZkZ2e7bM/OzsaxY8dUn2f+/Pk4cOAAOjo6kJeXh3/+85/ypwp3li9fjuXLl6O1tRXJyclBr72/cK7JKYbKGzsxI4prIQiib4nXa3HkfxZG7dqBYDKZMGzYMADMOzNx4kS8/vrr+NGPfiRHFtauXYvBgwe7HMeNz3yMhDc0Gk2v9J4ne4i7kfmCCy7AmTNn8Mknn2Djxo24/vrrMX/+/F7+Js6yZctw77334qWXXsJ7772H8ePHy5GZ9vZ2aLVa7N27t9eYC0+pLHd0Oh1+8IMf4IknnsDXX3+Njz76qNc+Z8+exZVXXol77rkHTz31FNLS0rBt2zb86Ec/gsViQUJCAu644w4sXLgQa9euxWeffYZnnnkGzz33HH7yk5/I51m8eDE++OADHDlyRF6/L5SClAdYHA6H3+MiSUjC6PXXX8eiRYvk0J43CgoK8O6772LWrFkoLi7G66+/HhNdVjdu3BjtJcQsyohRWQNFjAhiICEIQkDprFhBo9Hg5z//OVauXImbbroJY8aMgdFoRHl5uUe7B8AiFm+//TasVqvHqFFmZiaqqqrkr+12Ow4dOoQ5c+b4XU9SUhJuuOEG3HDDDbj22mtxxRVXoLGxEWlpab32veqqq3DXXXdh/fr1eO+993DLLbfIr02ePBl2ux21tbVyqi1Qbr/9dvzhD3/ADTfcgNTU1F6v7927Fw6HA8899xw0GpZMev/993vtl5+fj7vvvht33303Hn30Ubz22msuwui3v/0tEhMTMW/ePGzZsgVjxowJar0AMHLkSOzevdvlZ7F79+6gz6eWoFNpZWVl2LhxI+644w6/+9bU1OCuu+7CkiVL0NnZiQceeCDYywIAMjIyoNVqe5m3a2pqkJOTE9K5Cca5RmXEqCOKKyEIglDPddddB61Wi1WrVsFsNuOhhx7CAw88gLfffhunTp3Cvn378NJLL8lm5BUrVqC1tRXf//73sWfPHpSWluLdd9+Vq6Pmzp2LtWvXYu3atTh27Bjuuecer00MlTz//PP4xz/+gWPHjuHEiRP45z//iZycHK9GZJPJhKuvvhq//OUvcfToUdx4443yayNGjMCyZctwyy234MMPP8SZM2ewa9cuPPPMM1i7dq2qn8vo0aNRX1/fq3SfM2zYMFitVrz00ks4ffo03n33Xbzyyisu+9x///349NNPcebMGezbtw+ff/45Ro8e3etcf/jDH7Bs2TLMnTs3oCyOOz/5yU/w+uuv4+2330ZpaSmefPJJHDx4MOKBlaCF0ZtvvomsrCwsXrzY53719fWYN28eRo8ejQ8//BCbNm3CmjVr8NBDDwV7aRgMBkyZMgWbNm2StzkcDmzatMlrKoxQjyiKFDEiCKJfotPpsGLFCjz77LPo6OjAb37zG/zyl7/EM888g9GjR+OKK67A2rVrMWTIEABAeno6Nm/ejPb2dsyaNQtTpkzBa6+9JkePbr/9dtx666245ZZb5KyHmmiR2WzGs88+i6lTp+LCCy/E2bNnsW7dOjka44lly5bhwIEDmDlzJgoKClxee/PNN3HLLbfgwQcfxMiRI3H11Vdj9+7dvfbzRXp6utfU4cSJE/H888/jd7/7HcaNG4e///3vLu0FABYtW758ufxzHDFihGzMdueFF17A9ddfj7lz5+LEieDavixbtgyPPvooHnroITk1+cMf/hBxcXFBnU8tghhEbaTD4cCQIUNw44034re//a3P/aZNm4asrCx89NFHshHrwIEDmDt3Lh577DGP0aP29nacPHkSAAshPv/885gzZw7S0tLkP4I1a9bg1ltvxauvvoqLLroIf/zjH/H+++/j2LFjvbxH4YR7jFpaWpCUlBSx60ST+vYeTH3SmWY0G3U4+KvLYyL9SRBEeOnu7saZM2cwZMiQiN9wCCJUFixYgJycHLz77rseX/f196z2/h1UEnnjxo0oLy/36mznaDQaPP3005g5c6aLO33ixInYuHFjr9J/zp49e1wU+cqVKwEAt956q9y+/IYbbkBdXR0ef/xxVFdXY9KkSVi/fn1ERdFAgafR0kwGNHZY0NZjQ3OnFakm/xUGUUcUgf+sANKKgZkP+t+fIAiCiEk6OzvxyiuvYOHChdBqtfjHP/6BjRs3ujTwjARBCaPLL79cdROuBQsWeNw+efJkr8fMnj1b1flXrFiBFStWqFoHoZ5zUhptaKYJeq2AmtYelDV29g9hVH8C2P83QGsELl0JUJSLIAiiXyIIAtatW4ennnoK3d3dGDlyJD744AOXVj2RoP+VHRARp0Iq1c9PTYAASRg1dGBSfkp0F6aGdsmQb+8BLO2AkWbhEQRB9Efi4+OjUj0+oIfIEp4518giRnmp8XLH6/L+YsBud46EQWdD9NZBEARB9EsoYkT0gkeM8tISoNMy7dxvul931DufdzYCqUVRWwpBEATR/yBhRPSCl+rnpybAqGPCqKzfCCNlxKgxeusgCIIg+iUkjAgXHA4RlU3OVFqcXooYUSqNIAiCGACQMCJcqG3rgcXugFYjYFByHBIMbC5PdWs3uq12xAU4x6jP6ahzPu+iiBFBEAQRGGS+Jlzgw2NzU+Kg02qQZjIg0cj0c0VTP4gaUcSIIAiCCAESRoQLvLljXgqrRhMEAQVSZVq/GA3iYr4mYUQQBHsf+/jjjyN+nS1btkAQBFWz1NRw9uxZCIKAkpKSsJyPUAcJI8IF2Xid5pynU5jeT4SRKJL5miAGINXV1fjJT36C4uJiGI1G5OfnY8mSJS7zNPuCSy65BFVVVUhOTu7T6xLhhTxGhAtyxCg1Qd7GI0YxX7Lf0wbYup1fU8SIIL71nD17FjNmzEBKSgp+//vfY/z48bBarfj000+xfPnykKa7B4rBYEBOTk6fXY+IDBQxIlzgHiNlxKggvZ8II6XxGqCIEUEMAH784x9DEATs2rUL11xzDUaMGIGxY8di5cqV+Oqrrzwe87Of/QwjRoxAQkICiouL8ctf/hJWq1V+/cCBA5gzZw7MZjOSkpIwZcoU7NmzBwBQVlaGJUuWIDU1FSaTCWPHjsW6desAeE6lbd++HbNnz0ZCQgJSU1OxcOFCNDU1AQDWr1+PSy+9FCkpKUhPT8eVV16JU6dORegnRaiFIkaEC8oeRpzCNBMAoKyhIyprUo3SeA1QVRpBBIsoAtYofRDSJ6iecdjY2Ij169fjqaeegslk6vV6SkqKx+PMZjPeeust5Obm4ptvvsGdd94Js9mMhx9+GACwbNkyTJ48GS+//DK0Wi1KSkqg1+sBAMuXL4fFYsHWrVthMplw5MgRJCYmerxOSUkJ5s2bh9tvvx1/+tOfoNPp8Pnnn8NutwMAOjo6sHLlSkyYMAHt7e14/PHHsXTpUpSUlECjobhFtCBhRMjY7A5UtbBUlDKVxj1G55q64HCI0GhidDArjxiZc4G28yyVJoo0SJbwiM3ugEYQYvfvOZpYO4Gnc6Nz7Z+fBwy9RY4nTp48CVEUMWrUqIAu8dhjj8nPi4qK8NBDD2H16tWyMCovL8dPf/pT+bzDhw+X9y8vL8c111yD8ePHAwCKi4u9XufZZ5/F1KlT8Ze//EXeNnbsWPn5Nddc47L/G2+8gczMTBw5cgTjxo0L6HsiwgdJUkKmqqUbdocIg06DLLNR3j4oOQ46jQCLzYHq1m4fZ4gy3HidOZI92i1skCxBuGGxObDgha34/mueUy1E/0AUxaCOW7NmDWbMmIGcnBwkJibiscceQ3l5ufz6ypUrcccdd2D+/Pn47W9/65Leuvfee/Hkk09ixowZeOKJJ3Dw4EGv1+ERI2+UlpbixhtvRHFxMZKSklBUVAQALmsh+h6KGBEy3F+UlxLv8ilap9VgcGo8yho6Ud7YidyUeG+niC7tUsQotQjQxTEjdmcjYDRHdVlE7FHV0oUz9R04U98Bq90BvZY+I7qgT2CRm2hdWyXDhw+HIAgBGax37tyJZcuW4de//jUWLlyI5ORkrF69Gs8995y8z69+9SvcdNNNWLt2LT755BM88cQTWL16NZYuXYo77rgDCxcuxNq1a/HZZ5/hmWeewXPPPYef/OQnva4VH+/7vXLJkiUoLCzEa6+9htzcXDgcDowbNw4Wi0X190OEH3o3IGQqGpm/aHBq7//McmVaLJfs84hRYhYQn8aeU2Ua4YG2bpv8vLXL6mPPAYogsHRWNP4FkPpOS0vDwoULsWrVKnR09PZAeuontGPHDhQWFuIXv/gFpk6diuHDh6OsrKzXfiNGjMADDzyAzz77DN/73vfw5ptvyq/l5+fj7rvvxocffogHH3wQr732msf1TZgwwWvLgIaGBhw/fhyPPfYY5s2bh9GjR8umbCK6kDAiZCrkirTen9jkXkaNMWzA5uZrUyaQkM6eU2Ua4QEXYaR4TvQ/Vq1aBbvdjosuuggffPABSktLcfToUbz44ouYPn16r/2HDx+O8vJyrF69GqdOncKLL76Ijz76SH69q6sLK1aswJYtW1BWVobt27dj9+7dGD16NADg/vvvx6effoozZ85g3759+Pzzz+XX3Hn00Uexe/du/PjHP8bBgwdx7NgxvPzyy6ivr0dqairS09Pxv//7vzh58iQ2b96MlStXRuaHRAQECSNC5pxieKw7/aL7Ne96bcoEEqSIEVWmER5o63ZGiShi1L8pLi7Gvn37MGfOHDz44IMYN24cFixYgE2bNuHll1/utf93v/tdPPDAA1ixYgUmTZqEHTt24Je//KX8ularRUNDA2655RaMGDEC119/PRYtWoRf//rXAAC73Y7ly5dj9OjRuOKKKzBixAgXc7WSESNG4LPPPsOBAwdw0UUXYfr06fj3v/8NnU4HjUaD1atXY+/evRg3bhweeOAB/P73v4/MD4kICPIYETK8uaOyVJ9TIJXsn4vlXkbKVFoCpdII77hGjEgY9XcGDRqEP//5z/jzn//s8XV3k/azzz6LZ5991mXb/fffD4A1afzHP/7h9VovvfSS19dmz57d61qzZs3C9u3bPe4/f/58HDlyxOtai4qKgjaYE8FDEaMYQRTFqIsO5zgQX6m0GBZG3HxtylKk0kgYEb1xjRhRKo0gCCckjGKA2rZuzHv+Cyz841Z0WqLzJt1js6Omjfcw8p5Ka+60oiUWUw/WLsDSxp4nkseI8E17D0WMCILwDAmjGCAz0Qi7Q0SnxY5PD1dHZQ2VTV0QRSBer0W6ydDrdZNRh4xEtj0mK9O48VprAIxJVJVG+ESZSotJoU8QRNQgYRQDCIKApZMHAwA+3FcZlTU402jxELyUy8b0MFnZeJ3Fyn0plUb4oJXK9QmC8AIJoxjhe5PzAADbT9ajuqXvu0vLzR09GK85henSzLRYLNmXjdeZ7FGuSqO+IERvXDxGlEojCEIBCaMYoSA9ARcWpcIhAv8u6fuokXN4rPdOrTHd5FHuYZTFHqkqjfCBa4NHMl8DgMPhiPYSCCJkwvF3TOX6McTSyXnYfbYJH+6rxF2XFXtNaUUCXhHnK2IU072MekWMFKk0GiRLuEHmaycGgwEajQbnz59HZmYmDAZDn773EEQ4EEURFosFdXV10Gg0MBh6e2XVQsIohlg8fhB+9X+HcbymDUeqWjE2N7nPrn1O4THyBi/Zj0mPkVyq7yaM7BbA0gEYE6OzLiImoQaPTjQaDYYMGYKqqiqcPx+l+WgEESYSEhJQUFAAjSb4hBgJoxgiOUGP+aOzsO6bany0r7JPhVGlCo9RgSSMzrd0wWJzwKCLoUxsh6KHEcAGUWqNgL2HRY1IGBEKqCrNFYPBgIKCAthsNtjt9mgvhyCCQqvVQqfThRzxJGEUK+xiQwiXp9oAzXnU7TsE25gG6IwJgN4EGBLYzd6YBOiCDxF6otNiQ307m+bsqes1JzPRiHi9Fl1WOyqaOlGcGUNigwujREkY8cq0tvNMGKUWRm9tRMxBs9J6IwgC9Ho99Hp9tJdCEFGFhFGssOEJwNqBsQD+YgDgAPCOh/108cDFdwOXPgDEhSeixI3X5jgdkhO8vykKgoCCtAQcr2lDWWOMCSPlAFkOF0YRnJfWabHh82N1mDUyE4lG+u/UH3A4RFePEUWMCIJQEEO5kAHOmKuA0UuAYfNRljgRBx1DUG0oAJLyWLNCXRzbz9YFbHsB+NMk4KtXAJsl5EtXNHmfkeYOT6fFXGWack4aJyGVPUaw+/VbO85i+Xv78PqXZyJ2DSK8tLt1l++xOdBtpfQRQRAM+ogbKyx1ToFuPteMq1Zth9GhwZ6V82GOk6I4DgdQ+imLLtUfB9b/DPj6FWD+E8CYq4OuvDrXyCJGnkaBuFMYi00e7VZnvyL3iBEQ0ZL903Wsp1NVS1fErkGEF55G02sF2BwiRJFti9Nro7wygiBiAYoYxSAT8pIxNNOEHpsDnxxSjAjRaICRi4B7dgBX/pEZjZvOAP/8IfDX+UDZzqCux0v1PQ2PdUceJhtLESPe9VrQOkeBAH0yL622rQeAq2eFiG14RVpSnB5mKf050Ev2CYJwQsIoBhEEAd+7gHXC/nBfRe8dtDpg6m3AvfuB2Y8yc3blHuDNK4B/3ATUnQjoetxjpCZilC9HjGKo+zVPo5kymHjk9MG8tNpW1qW8rYeEUX+Bi1hznA5J8SwaS5VpBEFwSBjFKFdLs9O+Ot0oe4B6YUwEZj/CBNKU21jE5Pha4C8XAyc3qb7WuQA8RnwsSHljJ0RRVH2NiNLuVqrP6YNUmjNiRDfW/kK7JIwS43RIktLUZMAmCIJDwihGGZwSj4uLWcTj3yV+mq6Zs4ElfwR+vBMomgmIdmDf26qv5Rwg618YDU6Jh0YAuq0O1EmiIOq4d73mcGEUoao0i82Bxg5mfm+nVFq/gafNzEY9kqWIEZXsEwTBIWEUwyjTaaqiM5kjgTk/Z8/Lv2KjMPzQ2m2V0whqUmkGnQa5KWy/slgxYHsq1QciXpVW3+4UhuQx6j+4ptIkjxFFjAiCkCBhFMMsGpcDo06DU3UdOFjRou6g3AsArQForwEaT/vdnRuv00wGmFT24Ym5mWkdbuNAOBFOpdUqImbt5DHqNziFkd6ZSqNUKEEQEiSMYhhznB4Lx+YAAD7aX6nuIH0cE0cAixr5QU6jqYgWceSZaQ0xYsB273rNUValRcAPxY3XABNGDkeMeK4In7T3SKk0hfm6tYuELUEQDBJGMc7SC5gJ+z8HzsNqd6g7qOBi9ljuv3yfR4x8zUjrdfo0pwE7JpBTaV6Ekb2HDZINMzVuHiv3xoFEbOKSSoujqjSCIFwhYRTjzByWgYxEIxo7LPjieJ26gwqms8cAIkZ5aYFHjGLGYyRHjNxSaXyQLBCRdFqdImIEkAG7v+DRY0SpNIIgJEgYxTg6rQZXTcoFAHy430NPI0/kX8QeG0qdpexe4K0AAosYxdhYEG/maz5IFohIZVqtW8SIDNj9A95awRynqEqjiBFBEBIkjPoB35PSaRuP1qKlU8UbeEIakDWGPT/nO2rEx4EE4jHi89IaOizRNx07HECn1PnaPZUGRNSA7S6MuHeFiG1aPaTSqFyfIAgOCaN+wJhBSRiZbYbF5sDab6rUHST7jLwLI1EUnc0dVfQw4iTF6ZGawG4oUY8adTUCouS9MmX0fj2CJfs1bqk0urn2D+QGj0an+bqNIkYEQUiQMOoHsBEhLGr0kdp0muwz8m7Abuq0otPCpooPTlEfMQKAArkDdpQr03gaLT4N0Op7vx7BeWk8YsTnbZHHqH/Q1uNMpZHHiCAId0gY9ROumjQYggDsPtuEU3Xt/g/gEaOqA14rsnhFWpbZGPBk8ZjpZdThxV/EiVAqze4Q0SA1eCzOSgRAHqP+Av89JblVpcXMiBuCIKIKCaN+Qk5yHGaNYDf/e/+xH11SpMcryflA0mDAYQMq9njcJZBRIO4UpsVIZVq7lx5GnAgNkm1o74FDBDQCUCR5rshjFPuIouja4FFKpVntIrqtKtthEATxrYaEUT/iqaXjkW4y4PD5Vvz0Xwd8f8IVBL9l++fkirTA0miA04B9LtrCyFvXa06EqtJ4Gi0j0ShXNlEqLfbptjpglxpxJsbpYDJoodUIACidRhAEg4RRP2JwSjz+suwC6DQC/nuwCi9/ccr3AX4aPXJRkx9AqT6nMNZSad4iRhFKpXHjdVaSEeY47lMhYRTr8FJ9jQCYDFoIgoCkOJqXRhCEExJG/Yxpxen41XfHAgB+/+lxbDpa431nHjGq2A3Ye9+0nam04CNGlc1d6jtyR4J2fxGjyFSl8YhRljkOiUYpYhTt1gWEX1oVFWmCwCJF8lgQihgRBAESRv2Smy8uxLJpBRBF4L7VJThZ2+Z5x6zRgDEZsLQDNYd6vXwuiOaOnGxzHAw6DewOEeebuwI+PmyoNl+HWRi1MmGUrYgYtdGNNeZRNnfkyL2MaF4aQRAgYdRveWLJWFxUlIb2HhvufGev58aPGi1QMI09d0unORyiYoBs4MJIoxGcHbCj6TNqDyCVFsaqo9o2lkrLNMfJwogiRrGPchwIh5fs07w0giAAEkb9FoNOg7/cfAEGp8TjTH0HfrJ6v2wqdcGLz6i+vQcWmwMaARiUEhfUGmLCZ9Tho+s14KxKC/Mg2ZpWnkozItHII0YkjGIdLl5dhFEcpdIIgnBCwqgfk5FoxKs/mII4vQZbT9Th2fXHeu+krExTREx4Gm1Qcjz02uD+DPKjHTESRYX52ksqzWByDpINY2VanRQxyjIb5bQMVaXFPp5SaTQvjSAIJSSM+jnjBifj99dOBAC8uvV0787YuRcAWgPQXgM0nZE38zRaMKX6nMJ0HjGKUvfr7hbAbmHPvXmMlINkw1iZJpuvk+KcESNKpcU8nlNpNC+NIAgnJIy+BSyZmIsfzx4KAPjZB9/gYEWz80V9HBNHgEs/I16qH4zxmsOFUXljlMzXvIeRwQzofQi8hPA2eXQ4RNS1kfm6P9LqSRhRuT5BEApIGH1LeOjykZg3KgsWmwN3vbPXNYrDfUZlO+RN5xqDL9WXT5smzUtr6IjOOAUujLyl0TiyMGoKy2UbOy2wOUQIAktn8ptst9UR3dYFhF+cA2QVVWlUrk8QhIIBLYyWLl2K1NRUXHvttdFeSshoNAJe+P4kDM00obq1G/Of/wJP/PsQq57y0AG7ojn45o6cvNR4CALQYbHjfEu3/wPCDa9I82a85oQ5lcZL9dMSDNBrNXIqDSCfUazj9Bj1Nl9TVRpBEMAAF0b33Xcf3nnnnWgvI2wkxenx1m0X4dJhGbDaRby9swyznt2CF0ulJocNpXIVF48YheIxitNrMTk/BQDwp40nQlp7UKiNGIV5XpqzVJ+ZunVaDeKlIbxUsh/bKAfIcni5PvUxIggCGODCaPbs2TCbzdFeRljJT0vA3+6YhvfumIZJ+Snostrx/LZ6lCIfANBzertLU8ZgBsgq+cXiMQCA9/dUoORcc0jnCphAI0Zhqkqrlf1FzjYHzrEgFHWIZdp6fFSl0e+OIAgEKYwqKytx8803Iz09HfHx8Rg/fjz27PE8wT0Ytm7diiVLliA3NxeCIODjjz/2uN+qVatQVFSEuLg4TJs2Dbt27QrbGvo7lwzLwEc/vgSv3TIVI7PN+No2AgDwzw//iT9tPAGbQ4ReK7jc3INhSmEqvnfBYADAE/85DIenXkqRwl/Xa06YU2l1bc4eRpxE3uSRUmkxjceqtDgq1ycIwknAwqipqQkzZsyAXq/HJ598giNHjuC5555Damqqx/23b98Oq7X3G86RI0dQU+N5zldHRwcmTpyIVatWeV3HmjVrsHLlSjzxxBPYt28fJk6ciIULF6K2tlbeZ9KkSRg3blyvf+fPnw/wu+6fCIKABWOyse6+mRh10eUAgHH2I3hx80kAQG5KvDxZPBQeWTQKiUYdDpxrxr/2Vfg/IFzw5o6qzdfhEUbKAbIcMzV57Be0K2alcZTl+lEpIiAIIqbQ+d/Fld/97nfIz8/Hm2++KW8bMmSIx30dDgeWL1+O4cOHY/Xq1dBqmQ/j+PHjmDt3LlauXImHH36413GLFi3CokWLfK7j+eefx5133onbbrsNAPDKK69g7dq1eOONN/DII48AAEpKSgL99ryyatUqrFq1Cna7PWzn7Cu0GgFTL/sOsO9nmKAtQ0GiiPJ2AcOzwpNGzDLH4b55w/HUuqN4dv0xXDEuR/4UHlFUp9LCW5VW2+ocIMuRmzySxyimcZbr956VZneI6LTYYTIG/LZIEMS3iIAjRv/5z38wdepUXHfddcjKysLkyZPx2muveT65RoN169Zh//79uOWWW+BwOHDq1CnMnTsXV199tUdRpAaLxYK9e/di/vz5LteaP38+du7c6ePI4Fm+fDmOHDmC3bt3R+T8ESc5H0gaDI1ow4brE/HSjZPx1NJxYTv9rZcUYWimCfXtFvxxQ2nYzuuTDj9z0jjhrkqTzNfZiogRNXnsH3iqSovTa6DXssgpVaYRBBGwMDp9+jRefvllDB8+HJ9++inuuece3HvvvXj77bc97p+bm4vNmzdj27ZtuOmmmzB37lzMnz8fL7/8ctCLrq+vh91uR3Z2tsv27OxsVFdXqz7P/Pnzcd1112HdunXIy8uLmKiKCQRBLts3Vu3Ckom5IfuLlBh0GjyxZCwA4O2dZ3Gipi1s5/ZKu1SV5s9jpKxKC0OqhJuvM829zdfU5DF2sdgc6LGxPlPKiKYgCDQvjSAImYCFkcPhwAUXXICnn34akydPxl133YU777wTr7zyitdjCgoK8O6772LNmjXQ6XR4/fXXIQihe1tCZePGjairq0NnZycqKiowffr0aC8psnho9BhOLhuRicvHZMPuEPGr/xyOrF/D0gFYpSaWas3X9h7AGtpcN1EUFak0Ml/3J5RpTpNR6/Kac14a/f4IYqATsDAaNGgQxowZ47Jt9OjRKC8v93pMTU0N7rrrLixZsgSdnZ144IEHAl+pgoyMDGi12l7m7ZqaGuTk5IR07m81vNFjxW7AHpkbwC+vHAOjToMdpxrwySH10buA4T2MdHGA0Y9XSjlINsR0WkuXFRapu3WmQhhxzwqZr2MXHs1LMGihcxucbKZBsgRBSAQsjGbMmIHjx4+7bDtx4gQKCws97l9fX4958+Zh9OjR+PDDD7Fp0yasWbMGDz30UHArBmAwGDBlyhRs2rRJ3uZwOLBp06Zvf9QnFLJGA8ZkwNIO1ByKyCXy0xLw/2axuW1PrT2KLkuEzOpyGi2LpQl9IQhhq0zjabTkeD3i9M6oA69KI/N17OKpVJ+TRH2oCIKQCFgYPfDAA/jqq6/w9NNP4+TJk3jvvffwv//7v1i+fHmvfR0OBxYtWoTCwkI5jTZmzBhs2LABb775Jl544QWP12hvb0dJSYlcVXbmzBmUlJS4RKVWrlyJ1157DW+//TaOHj2Ke+65Bx0dHXKVGuEBjRbIv4g9V4wHCTf3zBqKwSnxqGzuwstbTkbmIrLx2k8ajSMbsENr8sjTaErjNeBMpZHHKHZp7e7d3JHDS/bJfE0QRMDC6MILL8RHH32Ef/zjHxg3bhx+85vf4I9//COWLVvW++QaDZ5++ml88MEHMBgM8vaJEydi48aNuO666zxeY8+ePZg8eTImT54MgImgyZMn4/HHH5f3ueGGG/CHP/wBjz/+OCZNmoSSkhKsX7++lyGbcKOQz02LnNE83qDFY4tHAwBe2Xoa5Q2h+Xo8orZUnyNHjEITRnIPI7Orcd1pvg4+YrS3rBGlfWFaH6C0eehhxHE2eaSIH0EMdIJq2HHllVfiyiuvVLXvggULPG7noscTs2fPVmXcXbFiBVasWKFqHYREgUIYiaL/NFSQXDEuBzOGpWP7yQb8Zu0RvHbL1PBegHuMTBnq9g/TvLRaD12vAUW5fpDCqLHDghte/QppJgO+/vm8mChO+LbR7iuVFk+pNIIgGNTJbKCRewGgNQDtNUDTGSCtOCKXEQQBv1oyFov+9CU2HKnBFyfqMGuEM+0liiLq2ntQ2dSFyuYuVDZ1ob69B7kp8RiamYihWYnITY7zLhDkAbJqI0bhmZcmD5B1S6WF2uDxfHMXbA4RtW09aO22yVVSRPjgaU5PzUeTyXxNEIQECaOBhj4OyJ0MnPua+YwiJIwAYHi2GbdeUoTXt53BYx9/gxlDM1DZ3IUKSQxZpJ4y3kgwaFGcaWJCSfo3LCsRI7ITIQScSgtPk0d5gKyXVFqwwqi503lDrm7pJmEUAXybrwdgH6OyHcDet4DLn1Lv1SOIAQAJo4FIwXQmjMp2AJNuiuil7ps/HP8uOY9zjV1Y3XjO5TWNwCbUD06Jx+DUeKSbjKhs7sSpug6cre9Ap8WOQ5WtOFTZ6nLcdVPy8Hs5YqTWfB2eVFod72HUK2LkNF+LohhwKqyp0yI/r27txsic8IxrIZzwruSeU2kD0GO0/UXgxCdA/jTgwh9FezUEETOQMBqIFFwMbAfrZxRhkuL0ePmmCfh89wEY0guRl5qAwSnxyEuNR05yHPRaz/5/q92B8sZOnKptx6m6Dpyqa8fJ2naUnGvGB/sq8HRONfRAEBGjEM3XbZ7N19xjZLWL6LE5XEr51dCsFEYtXSGtkfCM03ztoSpNEksDqiqNf7gIMb1MEN82SBgNRAZLRui640B3KxCXFLlriSIu/Po+XHh8HXDnZmDwCFWH6bUaOX2m5Oa/fo1tJ+tha62VhFGgEaPgbwLeul4DgMmggyAwP3tbty1gYdSkSKVVtXQHvUbCO57mpHHkiNFASqVxQdTVHNVlEESsEXC5PvEtIDETSCkAIALn90X2WsfXsX8AcG5XyKf70cwh0MOGeLtU1q7WfB2GqrT2Hhu6rKxhpXsqTaMRkGgI3mfU2KGMGJEwigSqPEYDKWLEPyR0N0d1GQQRa5AwGqjwqFHFnshdw9oNfPpz59fN57zvq5JZwzMxJYPd4ByCDohLUXegsiotyBlu3HhtNuqQYOh9cw2lyWOzm8eICD9tPho8crN7W48NDkcEZ/zFCnabUxBRxIggXCBhNFDJk4RR5d7IXeOrVUDTWefXLd7n6alFoxFw28QEAECDmASb2nsYF0a27qAHyfLmju6l+hxzCINkm9yq0ojw4ytixLeJItBuGQAGbGWUqLslassgiFiEhNFARRkxCjKC4pPW88DW59jzsUvZYxgiRgAwJ49VfNU4krD+sMpBtQYT698EBJ1Oq/PS3JEjN3kMIpWmjBiRxygytPuoSovTa2HUsbfDAZFOU3rtKJVGEC6QMBqoDJoAaHRs5lhLeASLCxt/BVg7gLyLgEtXsm1huo6hux4Aixi99uUZVV3S2SDZ0CrTnMbrOI+v8xRNMN2vlRGjli4rOgdC1KKPcUaMPPeIGlDz0pQfDrooYkQQSkgYDVT08UD2OPY83D6j8q+Bg2sACMB3npWM3mBvxpaO0M8vlRk3Cik4cK4Z+8qb1B0XYpNH3vXafYAsJ1FOpQV+Y1X2MQL6TzrN7hDx8L8O4PefHov2Unxid4g+I0aAs2R/QPQy6qKIEUF4g4TRQCYSPiOHA/jkYfZ88s2sy3Z8CmCUWgKEI53WzoRRWtZgAMBrW8+oOy4+lT0GGTGq8RcxCnJemtXukI9JM7F0X38xYB+saMb7eyqw6vNTqI3hNSsrBT0NkQUGWMm+8v9ATyvgsEdvLQQRY5AwGshEojKt5G9AVQkTQvOecG5PzmeP4UindbBxIGOGDwMAfHqkGmUNKiJRIc5L4xEj91J9TrBjQfg4EEEARmSzvk39JWK0t8wZrdt2sj6KK/EN/50YtBqvPaYG1Lw096gpGbAJQoaE0UCGR4yqSgB7GG4GXc3Axl+z57N+5jquI0USRs2hV6ZBmpOWmZOPWSMyIYrAm9vP+j8u5FQaixhlejVf84hDoMKIpdGS4/XITYkH0H8M2LvPOkXmttLYFUa+mjtynPPSBlgqDQC6VKajCWIAQMJoIJM2FIhLZiXsNYdDP98XzwKd9UD6cOCiu1xfC2vESBplYMrAHTOHAADe33POv2k2RGHE56RlJ3kzXwcXMeLG69QEAwYls3P3h4iRKIrYc9Y1YqTKCB8FfJXqc5LiucdoIESM3IQR+YwIQoaE0UBGowEGT2HPK0NMp9UdB3a9yp5f8VtAZ3B9XY4YhVEYJWbh0mEZGJVjRqfFjtW7/ESjQhgL0mmxyWX4Xsv1g2zwyI3XKQl65CSziFF/8Bidqe9AQ4cFBp0GcXoNatt6UFrbHu1lecRXc0cOjxgNjKo0d2FEqTSC4JAwGujIPqMQDNiiCKx/FHDYgBGLgOHze+8TroiRw+6M+JiyIAgCfnQpixq9teMsrHaH92NDiBjxUv14vda7eTfIBo88lZaaYMCgpP4TMeLRokl5KbhoCPvZfhmj6TTnAFlfEaMBZL7ulUprjsoyCCIWIWE00JEr00KIGJ1YD5zaxBooLnzK8z68ZD/UiFFnAyA6ADj7En13Ui4yEo2oaunGum+qvB8bQsSI+4uykowQBMHjPtxjFGwqjUWMmDDqDx6jPWXs5zilKBWXDmO/i22lddFckldUpdLkeWkDwGPE/w/walFKpRGEDAmjgQ5PpdWfCO5To62HRYsA4OIfA+lDPe/HhVFbFWCzeN5HDZLxGgnpgJbd5Iw6LW6dXggAeO3L0959LnyQbBBVaXJFmpc0GqBMpQUqjNjPIy3BIAuj+vYeWGw+ol8xAI8YXViUikuHMaP912caY3Ld/po7AoqqtIEQMeJR0zQWbaWIEUE4IWE00DFlAKlF7Pn5fYEfv3MV0HQGSMwBLnvIx3UyAV0cABForQxmpQypVB+mTJfNyy4uRJxeg0OVrdh1xovwUabSAjQJy12vvRivAWc0IlCPUXOHZL42GZCWYIBBy/5b1sSwz6i+vQen61mLhCkFaRiVY0ZGogGdFrv6hpt9iKqqtIFivnY4nFVoadIHGYoYEYQMCSMieJ+RtQvY9kf2fMGvAaPZ+76CACTnseeh+Iw6JA9LoqswSjMZcM0F7Px/3eal4WMIg2RrVESMeIPH9h5bQNVZjQrztUYjIDuZXSOWhRGPFo3MNiNZWveMYRkAYrNsP5BUWjAjXfoVPS2AKDV0pIgRQfSChBERvM/o+CfsTTY5Hxh/vf/9k8NQmcZTaaasXi/dLpmwNx6twZl6Dw0fXQbJBpZOq/PT9RpwpmkcItBpUd9JWGm+BoBBSbHfy2iP1L9oalGqvO1SLoxisNGjv3EgwACalcb/9g2JQGI2e05VaQQhQ8KIcO2AHUiK6eAa9jjhelb674+UMFSm8VRaYm9hNDQzEfNGZUEUgTc8RY1cBskGVpkmm699RIzi9BpoNcyYHUjUQWm+BiD7jGK5Mm2P1PHaRRgNZ8LoYEUzWjpjS1yoK9d3Rvxsvqob+zs8jRafxvqYAZRKIwgFJIwIIGc8oNGz5ozNZeqO6agHTm5kzyd8X90xyWGoTGvnzR0zPb78I6nh44f7KjybgIMWRnyArPeIkSAIiiaP6oWBe8Qo1ivTuix2HKpkEYaphWny9kHJ8RiaaYJDBHaejq2oUauqBo9O0RRoZWG/gv/tJ6QCcSnsOaXSCEKGhBEB6OOYOALUz0079AHrW5Q7Gcgcoe4YOWIUwlgQL+ZrzsVD0pGRaECHNxMwHyQb4AgEZbm+LxIDHCQriqI8K00WRryXUWtXQGvsK0rONcPmEJGTFIe81HiX12YOZ7+XWOtnpKaPkV6rQYKBzVH7Vpfs81RaQjob8AxQxIggFJAwIhiyz0ilAfvAavY44Qb11wiHx0jR9doTGo0ge12+9NRTJ4iIUbfVLosXX6k0IHBh1NZjg83B0pc8lRbrY0GU/iL3nk6x6jNSk0oDlPPSYisVGFZ4u4r4NIoYEYQHSBgRDKXPyB/1pay0X9AC465Vfw0eMWqtZCXDweAnlQb4iVoEIYzqpGiRQaeRe914g99Y1aZieKl+vF4rT32PdY/R7jLevyit12sXD02HTiOgrKET5xoDq/yLJPz3keQjlQYMkJJ9OZWmjBi1BP9/kiC+ZZAwIhg8YlR1wH8DRm66HjavV9m8T8y5TEzZLUB7TeBrFEW/ESPAaQL+prIFTR1u30sQ3a+VxmtvXa85gc5L46X6aSbnbLlB0ry0mrYe2B2xNZTV7hCx34PxmpNo1GFyQQqA2IkaiaKoqsEjMEDmpcmpNEXECCJgaYvWiggipiBhRDDSipn/xt4D1Bzyvp/DoahGCyCNBrBO1Um57HlzED6jribAId2wfESMspPiMDLbDFEEtp9yuzkHFTHy38OIYw6w+7VygCwnI9EAjcBESH17j+p19gXHq9vQ1mNDolGHUTlJHveJtX5GXVa7LDB9ma+BATIvTZlK08dJjVdB6TSCkCBhRDAEwTkexJfP6NxXTNQYzMCoxYFfJ5RhsjxaZEwGdL5FCo8a9bo5ByGMalT0MOIE6jFyr0gDAJ1WI18r1tJpfD7a5IIUuTWBOzOln/32U/UxEfHivwuNANlc7Q2eahsY5mspekol+wThAgkjwokanxE3XY+5CtDHe9/PG9xnFEzESE6j+U/f8Zvzl6X1rl2og5iXJs9J81ORBjhTNWo9Rk0drj2MOLFasr/7rHd/EWdiXgrMRh2aO604fD76jQOVFWn+UqEDYl5aL2GUwh4pYkQQAEgYEUr8dcC2dgOHP2bPJ6jodO2JUCJGrVXs0UPXa3emDUmHQatBZXOXPNMLQHAeo1b/zR05gc5L8xQxApSVabFVsu+p47U7Oq0GFw9lkblYKNtXW5EGKFJp32aPkTKVBlDJPkG4QcKIcMJTaQ0nPff5Kf2UjQBJGgwUzQzuGikhlOzXHmaPmSP97hpv0Mo3b5d0WhCpNGcPI/WpNNURI7mHkZeIUYTmpXVabPjHrvKABt5WNnehqqUbOo2ASfkpPved6S2VGQXUzEnjOMv1v6WpNFF0rUoDKGJEEG6QMCKcJKQxEzbg2Wd0QDJdj79O3QgQT4QSMar+hj3yZpR+cJbtK/oZ8YiRrRuwqCsn58NcI2u+do0YyU0eI5RK+9OmUjz64Tf46T8Pqj6GR4vG5iYhweBbZHAD9t6yJnQFMDcuEgQkjKRy/W9tVZqlg1WFAs7/CxQxIggXSBgRrsg+Izdh1NkIlH7Gnk9UOQLEEymKsSCBzGUDFMJogqrdedRi56kGWPnsK0OiYpCsuqhRXVskzddSxMjkOWIUCWEkiiI++aYaALD+cDX2lqnrAr5bTqN59xdxijNMyE2Og8XuwK6zgQ3sDTd8PIuqVFrctzyVxtNoWiOgT2DPecSIBskSBAASRoQ73nxGhz5gpfI5E4Cs0cGfPzmPPVo7AhvL0VYj9T4SgOwxqg4ZMygJaSY2HmR/eTPbGOAgWavdgQapF1IkzNeNHd48RszYXh2BVNrxmjaUK5ov/u6TY64GdS/skY3X3v1FHEEQFJWBHjqQ9yGBRYy+Hebr5zecwJ3v7EG31S1ap0yjcSM6r0qjVBpBACBhRLijrExT3ix576JQokUAq2TjPYgCqUyrkaJF6cMAg0nVIV7HgwRQmcb7COk0AtLcxIsnwm2+rmrpViVaAuGzw6y55sT8FBh1Guw624jNx2p9HtPSZcXxGtYAcEqh/4gRAFwaI3PT1AyQ5chVaf24XP+/B8/jxU2l2HCkBpuOuv1e3SvSAEqlEYQbJIwIV3LGsVRTVyPQdIZtazgFVOwGBA0w7prQrxGMzyhAfxHnUkXZvkwAlWm8Ii3TbITGS98eJfzm267aY+Q6QJbDo1MWm0PeJ1x8doSl0W66KB+3XzoEAPC79cd89hzaV94EUQSGZJiQqcJrBQAzpMq0Y9VtaKgoVT+HL8wEVJXWz2elVbd04xcfORu0bjrm1mGeR2njFVE/Ml8ThAskjAhXdEanh4f7jA6+zx6L5wDmnNCvEUxlWpDCiPuMDlY0o4ULjABSaYEYrwGnx6jDYvfb3LDbakeXlOpIcfMYGXVapEtjQqrCWLJ/vrkLhypbIQjAvNHZuHvWUCTH63Giph0f7Kvwehw3Xk8p9J9G46QnGjE2Nwla2BH/9yXAXxewOXt9jLKPkT+4+brTYnf60voJDoeIn/7rAFq6rMhIZH87Xxyvc/07dK9IAyhiRBBukDAieqP0GYli+NJoHG7ADipipM54zRmUHI9hWYlwiMAOPh4kkIhRG48Y+TdeA85ZaYB/nxE3Xus0AswebtrcgF0TRp/RhiMsgjC1MBUZiUYkx+uxYs4wAMALG0709qRI7A7AX6Tk0mEZmKE5hISuKkC0AyfWh7D64ODRO38DZAFX8RROA3ZLpxV//fI0aiPUfgEA3v2qDF+W1sOo0+Bvd0yD2ahDQ4cFByqanTt5SqVRxIggXCBhRPRG6TM6t4ul1PSm4EaAeCKZV6ap9BhZOpyRhgAjRoAzarSVp9MCiBg5exipixgZdVoYdOy/lewzaqsBPv4xcOIzl32Vc9I8dWQe5Kn7de1R4MxWVWvxBE+jXT7GGfn7wfRCDE6JR1VLN97acbbXMT02Ow6cawagriJNyaXDM3CVdrtzw8lNAa85VNoCqErTaTWyOApnL6N3dp7Fk2uPYtXnJ8N2TiUna9vx9LqjAICff2c0RuUk4bIRzOP1udI/xv/m4z15jKgqjSAAEkaEJ/KkRo/VB4H977DnY76r2vTsl5QAPUa1RwGIrOO1OTvgyznHg9QxI3MAwogPkM1WGTECIEd/2nts7Gbzt2uAkr8Dnz7qsp+3HkacXiX7Djvw7lLg7e8CtcdUr4fT0mnFV6dZxGDBGOfPMU6vxcoFIwAAf/n8pGwI5xyqbEWPzYE0kwHFGYH9DVyYa8QVmt3ODWU7VPePCheBVKUBynlp4YsYHa1uBQCcquvws6cKbBb2tyBhsTnwwJoS9NgcmDk8Az+4uBAAMHcU6xDvYsDmBQfKVJpyVlqYjf4E0R8hYUT0JnUIe+O0W4CS99i2CTeE7/zJAXqMqqUmhEFEiwA2HkSvFVDR1IWyhs6AqtLkAbIqI0aA8wbc0d4B/OMmZ0Vdw0mgxenj4XPS3Ltec3iTRzliVHUAaKsCILIu5AGy+XgN7A4RI7PNKHITOFdPHoxROWa0dtvwly2nXF7bKw2OnVqY6nfWmDtxpz+DSehBuSMT7XGDAHsPULbd/4FhJBCPERCZkv2Tte0AgLLGEIWRzQKsuhD46zxZxLy0uRTfVLYgOV6PP1w3US4SmD0yE4IAHKlqdYprX6k0h41FZwligEPCiOiNIDjHg4gOwDwIGHJZ+M7PI0ZdjereiIM0XnNMRp1sGv6ytC7AVFpg5muA+Yw0cKBgy0+Asm2AwQykFrEXT38h79fkpVSfkyP1MpI9Rqe3OF88uVH1eji8TP/ysb2jblqNgJ8tGgUAeGvHWVQ2Ow3fagbHekUy7n/smIG9uslsWx+n05wRI/+pNEA5Ly08qTSb3YEz0ry+883doZm6284DTWeB8/uB7mbsLWuS03NPLx2PbMXYmvREIybmpQAAPj8uRY08pdIMJkAjiUYyYBMECSPCC9xnBADjrwU02vCdOy4ZMErhezVRoxCFEaAcD1IfVLm+mq7XHLNBhyd1byCzYgNrfXDje2yMCuAibrz1MOL08hid/tz5YtlOoKdd9Zq6rXZ8cYL1clL6i5TMHpGJi4vTYLE58PxnJwCwLtlyRVqAxmt01MsC7t/2GfiolQkvnOprYcQ9RmpTaeGNGJU3dsJqZ9Edu0NEVXMIBmyFD6izvhwr3y+BQwSWTh6MxRMG9dp9nns6jZfrK1NpgkAGbIJQQMKI8Az3GQHAhDBVoylR6zNy2IEaaXhsgBVpSlzGgxilG7wfYWR3iHKDx+wAUmk3df0NN+k2Q4QAXPNXFm0rns1ePL1FToHw/kTupfocF4+RpRMo/4q9YExiXcjPblO9pu0n69FpsWNQchzGDU7yuI8gCHhkEetq/uH+ChyrbsWpug40dVph1GkwLjdZ9fUAAIc/AkQ7xEGT0JQwBJstoyEKWqD+RGDNPUPAYnOgx8YiNEmqI0bhnZfG02ickNJpCmH0/qadKGvoxOCUePz6qrEed58jCaPtJ+tZxaGcSnMTuVSyTxAyJIwIzxRcwiI0o7/Lmj6GG9lnVOZ7v8bTgLUT0MUD6UODvtzY3GSkJOjR1mPDN01S9MvW5dMI3NDeA4cIaASWllDF1/+LJc1/AwB8OeJRYMxVbHvehWw2VUetZCZXkUqT0iLtPTZ0ntrGPF9JeSyCBwSUTpPTaGOyffqEJuWnYPH4QRBFNipk7+laACIm5afI1XaqkdJowoTrcXFxGlphQpVZ+lvqo3SasgO5yagu6hnueWkn61yFkXIcS8AohFFp6XEIAvCH6yZ6FX1jc5OQnWREl9WOXaXn2SgewDWVBtC8NIJQQMKI8IwhAbh7G3DDu5E5v9omj9x4nT02pHSeViPIE9+/ONPlHCTrI63DS/XTE43Qquh6jUMfAp88DAB4wXoNdqVf7XxNZwQKL2HPpXSaPEDWi/naZNTJ6Z+eY5IIGjobGLaAPVcpjOwOERuPcn+R/wadDy0cCZ1GQPmJEly1/mI8o/tr4P6ixtNAxS65W/r0Ypa62SZOZK/3UTqN+4sSDFrotOre7sJtvuYRI/43FC5hNEhowB2XDsH0oeledxcEQa5O23VYahUgaJ2VaBweMaJUGkGQMCKihNqxIGHwF3Eu42X7J+ud4mLNzcCnvwBsPb32D8h4fXoL8OFdAETsz74Gf7J/r3eDRzmdxrxC/sr1AafPSF8u9S4qngMMmQlo9Ky/VMMpr8dy9pU3oaHDgqQ4HS4a4l/gDMkw4caLCnCl5ivEoQc36j7HPJP/67jwzb+kk80CzDnyzfv9JtYWAKe3AvbIzyPjvwO1/iIg/PPSTknCaEoBS1+dC5MwGhXfigcvH+n3kLmjmNn+0ClpxE9CmnOALEdZsk8QAxwSRkR0UB0xCp8w4kNNS841o2XxK8CFd7IXdv4Z+Ov8XuMquPFaWenjkfP7gdXLmO9nzFXYNfoRAIIcrZDhwujsdsBmUUSMvAujnOR4pKMFiU0s/YYhswCjGSi4mH2tIiX12WHW1HHuqCzoVUZNfjJvGGbqDstfTzj8e8ChsppKFJ1jZKQ2D0MzE5FpNmKfrQhWQwrQ08I6q0eY1gDmpHHkPkZhiBiJoij3LuJ+n7KG4IVRW7Nz5t/0zG7E6f1HUWcMS4dBp0FPq1uDUyVkviYIGRJGRHRIVjkWpFoaiBmC8ZozOCUexZkmOERgZ3knsPgPwI2rmd+i+iDw6mXA3rdlc7Tc9dpbxMjaBRz+GPjbtYClnZmsv/caTHFs/zb3G2vWWCAhg/k8KvegsYN7jLzftAclxWGGRhIo2eOBRCbuMGwee/STkhJFEZ8dUZ9Gk5dqsGGyhglFC/TQVu0DDn+o7uDz+4GGUuYLG30lAJbSmV6cDgc0OJV0EdsviJYDgRJoc0dAWa4fujCqbu1Ge48NWo2Ay0awiGV5QydrNBoErU3OFhOmrmpVxyQYdJhenI5UtLEN7v4igMzXBKGAhBERHXjEqK2aNa3zRHst0F4NQACyx4TlsjOHObtgAwBGLgLu2cEiMdZO4P/uBf55K9DV5HmArN3Gbugf3QP8fjjbt7OeCbcb/g7ojPJNuFcqTaMBimcBABynPpcjEqkmXxGjOMzQSOJw6GznC8Pms8czWz2mATmlte0oa+iEQaeRR0SoonwntKIdLcZc1F9wL9u28deAVUWp+Tf/ZI8jF7HolgRPp22yhGjAbi5XHb0KtLkj4DRfh6MqjfuLCtMTUJyRyNbUYwv63F1tit5bredVd6qeOyoLqYJkAk/wIIz6U8So5gjw2WMBtasgiEAgYUREB1MmoIsDIAKtXqa68zRa+rCwjSPh/Yy2nXSmJJA0CPjBx8CC/2GN7o78G90vTUfTUdaMMdNsBMq/BtY+BDw3ko34OPAeYGljXqkZ9wO3/BuIY2XwXBj1SqUBcjrNfvJz+Z6WEu89YpSTZMSlWunnUDzH+UL2OCAxm4m58p1ej+dptEuHZQQkDrhBPHnsfORe8RBgzgVayoGvX/F9nN0GHPqAPXfrls4N2O81SNWF5/cDHf6bbLrw9f8CfxwPfLVK1e7tkvhUW6oPOMv1wzErjQujYZmJiDdoZZEdbDrN2tHs/MLew3pFqWDuqCw5YmQxpPTeoT9FjNY+COx4Cdj3drRXQnxLIWFERAdBAJLz2HNvPqMw+os4Fw9Nh04joKyhE2UNin4yGg3s0+/FFzPfQ6VmEOI6q/BSz2NYZfgzvr99MfDG5cDu11h0KCEduPAO4Lb1wH0HgQW/dvkUzv0svSJGgCyMdFX7kIhOmON0PqulhmiqMFhogBU6oGC68wVBcEaNfKSk5DTamABnzPEO3UNmsQrFeb9kX3/5nO+b8ZkvgPYalq7h6T6JwvQEDEqOQ6U9FR0pIwGIrk0r/WHpAL74HXvOxZcfgkqlhbFcXxZGWSxaVJCWACD4yjTBXbh4+1DhRn5aAoaYWGSxrMuDZ66/lOt3NADnpH5eVQeiuxbiWwsJIyJ6+KtMi4AwSjTqcEEBHw/CbvAWmwOrd5Vj3nNbcOunNlze+SQ+EmdDK4hYrNkBfXsFYEhkjS6XfQA8eBxY/BxQOJ2lxzxcA/DgMQKAlAIgrRiCaMc0zVGfxmsAKGrZBQDYh1FMoCgZOpc9ntzs8djzzV04WNECQQDmjQ5AGHXUO+e7DWGpP0z4PksX9rQCW37r/VieRhu7FNC6RmkEQZDTaYfjpc7qpzyv3SN732LCFADOl6jqXN4WTFWa5PnqsTlYU8QQOCX1MJoufAO8Ng9zjWz4b7DCSGdtc93QUqn62BFm9vd4tMXDz4JXpcV6Kq30MzamCHC+PxBEmCFhREQPf5VpsjAK3XithHfB3nS0Bm9sO4NZv/8cj3z4Dc42dCIlQY//t2Ai5v7sX8B1bwETb2KPD5UC33sVGD6/1w3fHacw8pKKkaJGl2oO+TReA0B69Q4AwBbruN436aFzAQhA7WHmN3GD9y6aUpDK0oFqOSO1Bsga6zR7azTA5U+y53veAOpO9D7O0gkc/T/23MvQYZ5O+2+X1Kn55CZ1PhlrN7D9RfZc0AIQgbNf+j2Mi9NEo/pUWqJBJ1eze/0dquRkbQcmCSdxye6fAJV7MKubCcFgSvY7emyIdzCh5UiSoq0t6iJGAJAfx665t04Du8PtZ95fUmnH1zmf159Q53kjiAAhYURED1+VaZZOVtkEhDViBACXSsLo8+N1+J//HkFVSzeyk4x4bPFobP/ZXNw7bziLGoxdCix9mT26R2t8wFMxPTYHLDYPJmHJKzRDc8hnDyPYbdCdY5PotznGOSekcxLSnMN+PRiZfQ2N9Qmf58bbC8jrngWMuAIQ7cDGJ3ofd3wdq85LKQTyL/J4ah4x+mdtHkR9AjPX1xz2uK8L+99l+yblAVN+yLad8p+Gaw0ilabRCDAbQy/Zb+m0IqnjDN4wPAutjQ3lTdUwcRKMx+hMfQeSwI7T8G70KlNpAJAsMlFV2ROPknNNri/2B/O1tdv5dy5oAIcNqDsW3TUR30pIGBHRQ44YeZibVXuUhcxNWYA5wBu7Hybkpcgm2IK0BDy9dDy2PjwHd8wshikQg7IXlKMnPPqMhsyECAEjNJUo1PvwdJzfB6GnFS0w47BYhOpWD5+OvfiMWjqt+Oo0MzYv8DI01itnJH+RVEHnwoLfsIjN8XXAGbeIDU+jjb+udwNBibzUBOSnxaPLoUNjxoVso78u2DYLsO2P7Pml9wPDL2fPFQN5vdEehDACnCX7oVSmlZWdxDuG3yJNaGepWABmkaXCgkmlna5phllgAgtZUpVmAKk0oYulHpvERGw+Vuv6Io8Y2XtYG4pY5Ow21urCPAgonMG2UTqNiAAkjIjo4ctjxEeBhDlaBLDRDO/deTHevO1CbH5wFm6aVgCjLvhxI+7otBokGNj52j2lYuJTUWViw1on23wYSKWIyNG4SXBA0ztiBDiF0ektLp2kPz9eC5tDxIjsRAzJCKCir+ks+6fROUeYKMkcAUy9jT3/7BfOsvmOBqc4m3C9z0vwdNpe/QVsg7+y/YOrWWQkMRuYfDNQNIOJs6YzbK0+aAuiwSMQBgN2VzMK1v0AeUI9qnSDgSv/CACIt7UCAKpaujxHE31QUa0QM9lSKrJVvTDinqwmmLHpqJswMphZFEZae0zC02gjrnCm12sORfSSDoeI5X/fh5XvlwTde0rG2uXsy0bENCSMiOjBI0Ytlb370kTAeK1kWFYi5ozMUj0/K1AS/aRijicwUTCqa6/3k0gRkfIUlpaq8iSMBl/A0iDdzcD5ffLmz46wMv3LA40W8Wq0wVNdehC5MPtRdiOtOgAcXMO2Hf6QpTYGTQQyfY+puGQoS2V+0MrEIcp3soozT9htrBIOAC65F9DHs3XlXei6Xi8EU5UGhFiyb+0GVt+ElLZS1IgpWDPyRXkAstbSiji9Bg6RmeMDoaaWpUat2niWrgTUR4zsVtZtHEALEnGsus31+hqNYixIDFamiSJwYj17PvI7zveFCEeMSmvbsfabKny4rzK0GXcA8PnTwCsz2ExFIqYhYURED3Mu++TvsEqNHBVEWBhFGq9NHiVKdJMAAIUtuz2bj3va2BBWAE05lwIAqls83Eg1WmCo1N9Iith0W+3Ycpw1sAzYX+QrjcYxZQAzV7Lnm/6H+cF4Gs2L6VoJ9xltqDHBkVwA2C0sTeKJQ/9iUaGEdGekCug1d84bwQqj5GC7XzvswAc/Asq2o1NIwK2WR5CRPxyIZ5WQQleTXLJfFuCNtqGB/U7thiQgeTDb2FbFrumPLu4pElCcz4zbnx93ixrF8ry06oMsOqZPYB3muceq+pDqJpfBcOBcs/x8b1mT9x3VUFXCHlW2mvhWcvhjoDb2fWEkjIjoodUBSdIbvLIyzWF3GnLDXJHWVyRKqRhvVU17xRHoFvVI6KkD6o733uHsdhaBSS1CQnYxAC8RI6CXz2jHqXp0WuzISYrD+MHJno/xhMPh2r/IFxf/mKVC284Dn/wUOPc1S8WMu8bvZbKT4lCcYYJDFFCZLvVm8pROc9id0aLpy12bfHIxePoLn12wnUNkg0ylBWK+FkXWfPDYfwGtAT8zPIpjYgHrYcQ9PLYuFKcwkRZIBMLhEOU5aZr4FJZW1OiYEb5NxWgQ3togPgWzRw8CAGx2T6fFsgH7+CfscehcQB8HZIxkg5R7Wjx7FMPEgYpm+XnIwqhd6rZ/eov3bv9q6GwE3rgC2PZCaOvpa85sZZMCPror2ivxCwkjIrqkePAZNZ5hJktdvJyC6G/wqqb2Hs831rouAbsco9gXnkzEcmXYHHmIbY0n8zUADJUaKVbuAzob8ekhZzWa4MUE7ZHaI6xPkD7Bmaryhj4OmCdVpu3/G3scchlgVpe6u1iKGu3AJLbBkwH7yL9ZSXZcsnPgL2fwFGZo7mp09lxyw+4QFcIoOPN1a1cAqbQvfgfsfROAAMvV/4v/trK/3WFZiYAxGQD7XYxIZhGeQEr2q1q7EWdnVWV6UwqLFJqZwFHlM+riwigNc6VhtttP1bu2gIjlkn3uLxq5iD3qDECW9P8ngum0gxXOtGLowoj9v4Sl3We3ev+Lep8dv/1PEY2WhR3+4af2qLooZxQhYUREF27AVn7q48br7LHsBtAP8TkWBEBTpwXbHVI6wKMwklJEQ+dgUHI8AB8Ro6RBrOcQRHQe3YD/HGA9jb4zflBgi+ZptMJL2I3HH+OuAXIvcH6tIo3G4QbsNQ1DWDq14aSrkdrhALb+gT2fdo88bkVGqweKWIrRW3WaMo0ZsDAKdF7a7teBLc+w54v/gNL0uRBFICVBj3STgXl4JOExxMSiBS6d1/1wqrYdSQITUgKP7PBoq5peRp3S6JWENIzKMWNQchy6rQ7sPKUYyRKrEaOWSqnLtQAMX+jcni2l2SNkwO622nGsulX++nhNW/DtG+xWpzgFgJMbgl/Y8bXssauJFSD0F3h/NLsloP5b0YCEERFdPJXs93N/EeC7yaMoimjutGIbF0Znt7E3Tk5rldSfRQCKZiInmUWM6tp7YLV7SRtJ4zcq9vwfuqx2jMw2Y9oQD8NCfaE2jcbRaICFT7HnehMw6krVl7pYEkb7ahywDpaiU8p02olPWONKgxm4+G7PJ5F9Rls8vswr0gxaTcBVh07ztZ8boaWDNZ5c9xD7etbPgAvvcJmRJkftJOFRkMBGc5Q3qjdfn65rRxIkIcUjO9xnpCZixFNpCekQBEGOGrmU7cdqxOiElEbLv8jZcBSIuAH7aFUrrHYRaSYDCtISIIrA/vLm4E7mPkanNEhh1NnI0uycyn3e940lupqdHisAaDwdrZWogoQREV08lex/C4SR2YfHqMNih8XuwBGxEGJ8KhtGq3yD4zf63MlAQhrSTQbotQJEEaht6/F8QclnlF71JQQ4cNuMosDSaHYrUCa94bo3dvRF4SVsTIpiiK4aMs1GjMhmvX3OJF/MNvLxIKIIfPEse37RnbJxuRd8nWU7PHZADtZ4Dago1++oZ1VGL4wFNvyS9dya8kNWsQcW4QGcM9IAyN/HICP7HZ5r7FRdAn66vgPJgiSMuElajhgFlkoD4CKM5DXE6rw07i/iaTSObMA+GJHL8jTaxLxkTC1kv7ug02k8jWZMYl68umPeO/77onQD85Vx+oswKtvhHOUCkDAiCJ94GgsSoVEgfUlinHePUVMHS6XodTpndEYZ9eBpNOnGr9EIyDKzqJHHXkYAUHAxbLoEpKMZF8Wfx1WTBge24Mq9zPuQkA5kjwvs2OHzgXw/niQP8HTaJitPKX7BBNrJjezTpT6Bma69kTkKSMwBbN3M/O1GsP4iQFGV5i5sG08zg/ULY5mnqKsJSC0CFj/P/kli9GSdJ2GUAgDI0HbK62vqVJeaOVXXLne9loURH8Kspvu1IpUGsJYJRp0Glc1dOFHT7rK+mEql9bQ5UzAjv+P6Gv87bS6PyJq58XpCXgoukIWR//l8HumQjNepRU7/XjDpNJ5GSy1ij5U+2n3EEvx3yCFhRBA+UI4FEUWgvVYq3ReA7DFRXVooJHFh5CFi1CzdDFMT9BDc00Gi6HzOK68ADEr2I4x0RhzUsQjb3XlliDcE6M3iabSimR4H40YCXrb/YVUGE2SWNuDcLme0aOrtrDWANwTBZzot2OaOgNN83cYjRpX7gH/+EHhpCrD7r0yM5U4Grnsb+Mk+4MIfufjheCptqIeIkcHSghzJUK/WZ3S6rkP2GAUVMeqUIh2SMIo3aOV05tdnGlzPG0uptFObmSclrRjIGOH6WkKaM+KsZqxMgPBS/Yn5yZhaxH53JeXNsHlLZ/uCR4wSs4DhC9jzQNNpypEoUmQSVQdcGrvGLJIw+soh9S5rjG1vFAkjIrrwT73WTpY/59Gi9GGu5dn9DF8eo6ZOFjFKTTA4b+wVu4Cedlax0V7DKvLyp8nHcJ9RladeRgCOV7fhozb2pnOJuD/wBXubjxZBpg1JhyAApXWd6C6QImebn2Q/C60RuOQn/k/iUxixn31iEGNeuMcov+sw8PYS4LU5wOGPWDpg2ALg1v8Cd34OjL26V4GAze7A2XomYoZlKoSRwtzMexmpKdnv6LGhqqXb6TGSI0YBeIzcUmkAMFwSbeV8blssmq+PK5o6ekoN86hRmA3Ybd1WnK5nP+8JeSkYnmWG2ahDh8WOY9VtgZ+wXfJyJWazvx+AfRixeUmNe+LMVhbVNeeysTsGM2DrAuqOBr6evqSjnvkFAay2SR/2KGIUuyxduhSpqam49tpro72UgYs+js1DA4CW8m+FvwhwptLaPDR4dBFGaUNYF2OHjXl8eBqt8BJAZ5SP8RcxemvHWXzhmAgAMJ7fxVIQarF0ABW72XNfjR3DTKrJgNE5zJd0xCSlF8p3sMcLblFX+s/Xe36/ookhI5gBshzuMXrS9gK7IWl0wITvA3dvB27+FzBkptd5cOeaumCxOxCn12BwSrzzBe6V6mpCQToTRmpK9s9IN+h0rSSK5YiR9KGivdZ/Xxy3VBoAeQ2yOIs187XDruh2vcjzPrIBO7w+o28qWyCKwOCUeGQkGqHVCJgspdP2lQfhM+LCyJTJLAKJ2awlSdkO9efgabSRi5gYz53Evo51n9FZNlOxOm4o9onD2bamMz77j0WbAS2M7rvvPrzzzjvRXgah9Bl9S4SRL/O1nEozSSkeZdTDQxoNAHJ4yb6HXkbNnRZ8tL8C5WI2us1FTGS55/R9UbaTdR9PLgBSh6g/LgzwdNonnYq0qUYPzLhP3QmSclmzP4i9vmfnANngUmlGWJAvSN6Qu7cD33vVafj1AU+jFWckQqNRiCeF8JC7Xzf4F0anJL9Suk763XNhZMpgkTWIrNGmLxRVaZx896hVrEWMzu1ika64FCD/Ys/7RKgyTTZe5zsbpE4pYMJoz9kghFEHjxhlsVS1l+HPXnE4nCb0UZLXarDUKuN8jAsj6f/lPs14VIoZsIpalopuq4rywrwzoIXR7NmzYTZ7mQdF9B3KyrRvgfEacKZvPJqvpYhRSoLUK4gLo9INzlLcYjdhxJs8eogYrdl9Dt1WB8YMSoJxlBSm9zeYVYls9r7MaxQkUnAD9oZy0dmXZtKNTrGsBrkL9haXzU6PUeARI5NBizwNExOiLt7v/DclJz1VpAGuEaMAUmmn6ljEqJf5WhCYMAT8+4w8pNL4GuTquFiLGPGmjsMvZ13yPcGFau0x15YXIcL9RRPyUuRt3GcUVGWaMpUGBO4zqtzLUuzGJKDoMrZt8BTna7GMJIw2dI+EHVpUiJJvMIbTaQELo1/96lcQBMHl36hRo8K6qK1bt2LJkiXIzc2FIAj4+OOPPe63atUqFBUVIS4uDtOmTcOuXbvCug6ij+A3wfoTQEMpe97PI0ZJPho88qq01AQpkjFkFgCBfe/WDhZuz3I1njs9Rq7CyGZ34J2dZQCAH84ogiB/Et2gviuuPB9tju/9IsBFxWnQCMDZhk40zHgMGHctMOexwE7ixWfEf/ZJQQgjQRAw3MjEhMWcF5Bg9CqMFBGZ/DT1qbTTUsQoQZSqx+KcUQxnZZoPYeRwONOMiojR4JR4CAJrH9HYYXGuz9oZ2siKcOGtTF9JShHz2th7gPrSsF3aWaqfIm+bmJ8CjQBUNnd5L4LwhjKVBrD/a4IWqD8ONJX5P56n0YbNdzZf5c1Va44A1sAGEvcZLZVAw0mIggabOocBAM6KUoq88VQUF+aboCJGY8eORVVVlfxv2zYvAyABbN++HVZrbyV/5MgR1NTUeDymo6MDEydOxKpVq7yed82aNVi5ciWeeOIJ7Nu3DxMnTsTChQtRW+tsWDZp0iSMGzeu17/z5/2EnYm+hVemnfiMmVtNWYA5wOGnMUaioirNvVdNk1yVJr3BmdKBQYoIWfHsXpVh3GNU09oNh8N5vo1Ha1HZ3IU0kwHfnZjLukFrDayEuf6E/4V2NDijdEMuC+A7DA9JcXqMk+a5fWEbB1z7euC/+8IZ7CbTeNrlJsMjRolBCCMAKNYzMdGdkBvQcR5L9QGXiFGh5O+pau1Gj833eITTdR3Qwg6D3S3lBajrft3d7Owho+gJFafXypHI8sZOV8EV7V5G9aXsg4JGLzcv9YhGwzrkA2FLp9W19aCyuQuCAIzPc/5MEo06jB7EPHEBR4063CJG8SmsYSWgrmz/mBQ9G7XYuS05j71XinagKjK9nEJG8hd1pI9DK1gxjVMYfYsiRgCg0+mQk5Mj/8vI8FxS63A4sHz5ctx0002w253/+Y8fP465c+fi7bff9njcokWL8OSTT2Lp0qVe1/D888/jzjvvxG233YYxY8bglVdeQUJCAt544w15n5KSEhw6dKjXv9zcwN7oABadGjNmDC68MPB+LYQfeMSI+yT6ebQIcPpabA4RPTZXk2GvVBrgWg3moTIs02yERmDnq+9wVrK8uZ2Vvd54UT7i9FrAmMhK7gFg9TL/rfd5tChrDPM/RAHuM3IZTxEIcUlA3lT2nH8/UDZ4DNxjBAAFWraetnj17xeiKHpu7gg4RUl3M9JNBiQYtBBFoKLJ+6d9h0PE6fp2mKGILBkVjTTVVKbxaJHB3GvUi4vPSKN1njva6TQeLSq61FWweYK/X3iZmRcoB6X+RUMzE3tVNE6RDNh7AulnZLM4fwfK/2Nq02n1J1lkSaN3HgOwKGas+4ykNFp50lR5U5koicNvmzAqLS1Fbm4uiouLsWzZMpSXe55urNFosG7dOuzfvx+33HILHA4HTp06hblz5+Lqq6/Gww8/HNSiLRYL9u7di/nz57tca/78+di5M4ThfD5Yvnw5jhw5gt27d0fk/AOaZDc/ybdAGCXotXL2xX2shLKPkYyLMOqd0tJrNcg0syq1mhYmjI6cb8XXZxqh1Qi4+eJC587f+T2rWGooBV5f6DvFIKfRZnvfJ8Jwn9GOYIUR4Fz/qc/lTW0hNHgEgDzJeN2iVzcYFwBqWnvQ3mODViOgKN2t3YSigaIAqPIZVbV2o9vqcFakGRJd/TZqIkYeKtI4Be4pvVgxYMtptO/43g8IuwH7gIc0GocLo32BRIx4c0eNzjXax8v2z2z12LldhqfRPInEWPYZic6CiH1aZ0T8rCyMYreXUcDCaNq0aXjrrbewfv16vPzyyzhz5gxmzpyJtjbP5cG5ubnYvHkztm3bhptuuglz587F/Pnz8fLLLwe96Pr6etjtdmRnu4bcs7OzUV1drfo88+fPx3XXXYd169YhLy8vYqKK8IO70fZbIIw0GgGJBs9NHuVyfZPi03vhDCaIJt/sjAK4wdMevJfR2zvOAgAWjcuRB80CANKHAj/6lDXEa60A3ljIytk9Eeh8tAhwYVEadBoBlc1dAU2cd4GLyTNfyGXAoUaMsh0s/dGgV5/a4/6iwrQEGHRub688YiTagZ42VT4j7i8anixF3JU3VkBRuOAjYiRXpHkXRs6S/Rho8tjZCJz7ij0feYX//eXRIIfCMm2eR4yUFWkcLowOn29Fl0XlhHieRjNluabIc8azzu3WTmebCk94SqNxuM8oFkv2m86wghqNHlu6iuXNZcpUWhh+X5EgYGG0aNEiXHfddZgwYQIWLlyIdevWobm5Ge+//77XYwoKCvDuu+9izZo10Ol0eP311wOb4xQhNm7ciLq6OnR2dqKiogLTp0+P9pIGJnHJgFHxJtTPK9I4Zi8G7GZ3jxHAehbd8jFwlXdfHTdgV7d2o7HDgo9L2M3wthlFvXdOzgNu+4R1Z+5sAN5aApz50nWfpjL25iVoWd+kKGEy6jBB8nIEnU7Lm8qiKZ0NcrM/2WMURINHAMiwsxtarUZ9ivFkLfuAONQ9jQYA+nipvB7MZ8RFiY+SfZ6WG5nEhZHbzVpOpfmIGHmoSOP0EkaxEDEqlbyG2eOBlAL/+2eNYfPHOuuBNvUfjD0hiqJsvJ7gIWI0OCUeOUlxsDlEeWSIX+SKtEzX7YLAxukA3tNp7XXOcTeeTOg8ldZ4qlcfr6jD22fkXYij9ezvNy81HhViJhzQMEHY7tlnHG1CLtdPSUnBiBEjcPLkSa/71NTU4K677sKSJUvQ2dmJBx54IKRrZmRkQKvV9jJv19TUICdHfdibiCF41EgXzyIe3wKc89Kcwshic8hfu6TSVMCjQlUt3Vi9uxw9NgfGD07GBQVehqyaMoBb/495jixtwN+ucX76BJxptLypAQ2AjQSyz+h0kMJIq2dRN0CuTgulKg12G5KtbCL6eWT62dmJV+M1x0OTxzJfESOpuWNRovQ35C6MeCqtqwmweDmPnEpL7/WSM2olpepioWSfl+n7qkZToo93jgsJMZ1W0dSFxg4L9FoBowf1buUiCIIcNVJtwHYv1Vcy/HL26E0YnVgPQAQGTXJWICpJSHPOTfMWFY4W0gcxS8GlqGxmf1+TC1JhhQ6txtg2YIcsjNrb23Hq1CkMGjTI4+v19fWYN28eRo8ejQ8//BCbNm3CmjVr8NBDDwV9TYPBgClTpmDTJmevFofDgU2bNlHUp7/CUwLZY3uNWOivOJs8Oj1GzV0sjaYRnN2V1cIjRhVNXXiXl+hfUuQ7+mo0A8v+BYxczEqa19wMlPyDvRYDaTTOJUNZAcfOUw2qJ873QlG2L4qiYohsEKm01kpoYEePqEOVTb1olEv1M70JoxT22K2uZP+01MMoL0Eqn3cXRnHJLFImrdkjKlJp51u6YLE5oj8vzdbj7MGlVhgBitEgoQkjHgUaPSgJRp3n96HAhZH0Ad7kIfJYPJt5jxpKPXtujkn+Ik9pNI7sM4qhdJrCX3QumRmv000GFKSxD3cNBknQf1uE0UMPPYQvvvgCZ8+exY4dO7B06VJotVrceOONvfZ1OBxYtGgRCgsL5TTamDFjsGHDBrz55pt44YUXPF6jvb0dJSUlKCkpAQCcOXMGJSUlLibvlStX4rXXXsPbb7+No0eP4p577kFHRwduu+22QL8lIhZIlczD3wJ/EcfTvLSmDiaSkuP1rl2RVcBL9j87XI2qlm5kJBpw5UTPH0hc0McB178DTFrG/C0f3w3sXKUwXkdfGE0pTIVBq0F1aze2nKhzaUmgGi6Mynagq6sDdukcQZmvW84BAM6L6WjuVuklAXCylgkZNRGjQkUay5sY5F2vBxm8CCNB8G/A5hEjD6m0jEQD4vWsOq6yuSv6qbSzX7J5YIk5LEqiljAZsJ1pNO+VcFMUo0FU/Z1y87V7Kg1gv08+E9G9C7alw9l81ZcJPRZ9RnXHmbdKF4dvwMaADMtKlD8MVmulSs8YFUYBv2NUVFTgxhtvRENDAzIzM3HppZfiq6++QmZm71+6RqPB008/jZkzZ8JgcPopJk6ciI0bN3o8BgD27NmDOXOclTkrV64EANx666146623AAA33HAD6urq8Pjjj6O6uhqTJk3C+vXrexmyiX7ChXewdMDFP472SsKGJ4+Ry5y0AMmWzNe8/P+maYVeP9X2QqsDvvtnduP7ahXw6c/Zdn0CkBf9FhRxei0uKEzBV6cbcdubu5FmMmDWiEzMHpmJy4ZnuhrVvZE1mqUr2mvQfZqZdzUCkGAIIgLZzIRRpZjRq6rQGy2dVtS3s4pBjx4jwEV4DE5lDRY7LXbUt1vkqkNOp8UmN/TM0LvNSVOSPJiVc3uLGHV5jxgJgoCCtAQcr2lDeWMnhkQ7lSZXo13Rq5eXT2QDdmjCqMRDx2t3xuQmIU6vQXOnFafr2zEsy8/0BB4x8pRKA1gJftl2lk676E7n9lOfs9EZKQXOXk2e4BEjt5L9881d0GoE+X2jT+H+ooKLcaKBvecNy0pEUjwTRhUa6QPdt0UYrV69OqD9FyxY4HH75MmTvR4ze/ZsVeH0FStWYMWKFQGth4hRMoYD3/vfaK8irJg9eIya5R5Ggad3eMQIAHQaATdPU2FMVaLRAAufAhJS2RR7ACiY7jKsNpo8sWQsXtxUim2l9WjssOCj/ZX4aH8lNAIwKT8Fs0dmYc7ILIzNTfIcbRMEFjU6uEbyGU1HolEXXKFHM4tOV4qZaO3q3b3cE9xfNCg5zrvhWxExMuq0GJQUh/Mt3Shv7OwljHgaLc1kQJzNQ9drjhwx8pZK412vewsjgPmMuDCKasSopw04/DF7rqZMXwkv2Gg4xSItBpPv/T1gd4g4VMkiRpPyU7zup9dqMDEvBV+facTesiYVwkiKGJm8eNWGLQA2/spZtq+X/p/LabQrfXdeHzSBmc/bqoDW80BSLqpaurDwj1sRr9di+yNzodd6EZmnPgeqDgCX3BuYEPUHj0YPuQylZ5y+O/6eGOtNHgf0rDSCiCTOeWnKiJGHijSVKD/5LZ4wCFnBfBIUBOCynwJXvgCYc4Gptwd+jggxelASXr55CvY9vgBr7roYd88ailE5ZjhEYF95M57fcAJL/rwNFz+zCV95M2lL6TRjOfvEGmypPlqYMKoIIGLEK8iGevMXAS5NHgH49BnxNNrQTJOzE7XHiBEfCxJ4Kg1w62Ukry8Kna+3v8gqy9KGAkPnBnZsYpYUkRHZiIwgOFXXjk6LHQkGre/fIZxz01QNlHXveu1O9lj2f9HWBZRJUyTsNsl4Df8i0WACMkez51I67bnPTqCt24bath7v40ssncD7twIbn2CVgOHCYQfOSt/HkFny/4vhWWY5lXbSJvmtGmKzZJ+EEUFECE/ma489jFQSp9fKN7HbZgwJbXFTbwcePAqMvjK080QAvVaDacXpeGTRKKy//zLsfHQunvneeCwcmw2TQYvath48+uE3sNkdvQ+WjOQJDd8gCe1BN3d0SaV1qRNGfivSAEWTR3ZD5aNBPDV55BGj4oxE38LIX8RITqX1rkoDIBtiyxsUEaO+TqW1ngd2vMSeL/g1qzIMlBAN2Hxw7LjBydD68f/JBuxyFcJITqV5afvgqWz/3Nfs9xafyqK6/lB0wD5a1YoP9jlFMq8I68XhD4Ee6e8qnMKo+hv292MwoydrvFx1qYwYnbSkAxBYtWxHffiuHSZIGBFEhPBkvvbY9ToA/nrrVLx35zSfof5vG4OS43HjRQV49QdT8dXP5yE1QY8z9R34uMTDzMPkwUDGCAiiA9M1RwKu/JNRptI8zLvzBK9I8+ovAhSptGYAzmhNmYdeRjxiVOw3YuRjLIgo+qxKAyC3DShv7FQItz6OGH3+FIuY5F/MUkfBEKIBm1ekTfRhvObwFhmn6zrYAF5v2HqcvztfI3fcy/Z5y4LhC107nXuDC6PKvXjmk2MuQZjz3oTRnjedz0sDGDrtD+4vKpqBs40W2B0iEo06ZCcZZY9RfY/gjHTGYDqNhBFBRAiP5usOD3PSAmBEtlkubR+ImOP0uOsy1ufqpc2lnqNGUhfsSzWHghsg63DIIqNCzIDdIaJDRZdjv6X6gMLDwyINvlJpPGI0NNNfxEi6wXiKGPW0AQ4p4qUilSZGY1Za9SFg/9/Z88uf9O2n8UWIwohXpE1U8aEjJcEgRwZ9jgfhPYy0ht5dy5UMmcXK9htPMZ/Usf+y7b7K9JVIBmxrxT58eaIGeq2Ai4vZ77vS0yy+qoNA5R42f01rZKnjuuPqruUPLoyGXOb8P5GVCEEQ5A8q7T02iKlS1JuEEUEMHDyZr0OpSiMYt0wvRLrJgLKGTny434MYGMKG6E7VnAguldZeA9gtEAUtGrQs/eQvndZtteNckzNl4BUvESP3VJrDIeKM1NzRJWLEIzpKeMTI0tbbG8TTaLp4wJDgcUl5qWx7W48NLaJkWu5pZV6RvmDD4wBEYOxSID+ECkl5mOyRgNfeY7PjaFUrAM8z0jwxVR4o60MYyeNAMn0LvrgkZ8psx0tA01kmWNR6rbLGQNTFQW9pRZFQg5svLsT0YvYBymMqba8ULRp9JZvBBgAn/QyzVYPdCpRLo7XchBHgfE8URcCaUsT2I2FEEAMHzx6j0FJpBBsh8v9msdlLL20uhdU9aiSVNhcLVUgyBl+RJiTlwpzA/DdrD1b5POR0XQdEkfWnykj0IXrdyuELpUGz1a3d6LY6b+ZVrd3ostqh1wosquQrYmQwOaMR7lEjP2k0gHnXspNYRVxZl2LtfWHAPrkJOLUJ0OjhmPsElr+3D3P+sMV3esob6cOYALR2BDyg9GhVG6x2EakJeuSlxvs/AMAFagbK8oo0X2k0znCpgnvvW+yxeDZg9G0Cl9Hq0WgeBQCYZjyLe+cOR24KK87oJYx62oCD0givKbc5rxsOn9H5/awPVXwakDUWpdKIHC6M4vRaeYZgZ6LUu46EEUEMHOSqNA99jIJNpRGMmy8uREaiAecau/DBXrdqrJRC2AQDjIIVeUIQxk6puSNSCvDDS4oAAE+tO4q/fVXm9RCl8dpnewBFuT7ABDL/O6lockaN+PDYgrQE6GFnN3vAszACFJVpXoSRlzQaR45cNVsBvclljRHDYZeiRQAuuhPvHGMC9Ex9B/570IN/zB8aLetlBQDVBwM61Dk4NkV1ewceMTpQ0cy6hnvCV9drd4bx1jaS12eU+pYF3VY7NrayyOGyvHqkmgwYLAm8XsLom38x8ZI+DBhymdPfVLaTiaZQkMv0ZwIajcf0Mh/R054gTTsgYUQQAwfZY9TjwXxtoohRKCQYdLh7FvcanXS9MWm0qDWwN93BtnJPh/tGihghOR8/nj0U/+8yFp167ONDWL3L8/lU+YsAZ2TH0g7YrRAEQfYZKdNpckWa0l8EANwD5I637tc+mjsqcVlDXzV5PLCaDfyNS8bpMffgmU+OyS/5i9B5RU6nHQpsKee8D471xpAME9JMBvTYHDh83kt0TS7VVyGMskY7/WIQgBHqR6K8vu0MdnSxCMxYkc0tzUuRxr00dzmLB0QR2PMGez7lhyy9lz4USCtmXjQ+JihYFP4iu0OUZ/0Nz1YKI/be12gk8zVBDDiUQ2QdDhEOhyg3eCSPUejcfHEhMs1GVDZ34V9uUaNKPRNGgyzeozxe4cIoJR+CIOCRRaPwo0uZUfTRj77BP/ec63XIKTcvhVeUER/JZySPBlFUpjl7GCmEkTHJ+xxBb5VpKlJpgFsvI7lkP4KpNEun3GTUfumDuP8/bCgyNz7vOtuIuraewM8bpAH7YAAVaRxBEOTqNK9z09oDEEbKsv28CwGzuikODe09eHnLKRwU2QcFTc03gN2KnOQ4CALQbXWggacmz+9j0TStEZh4k/Mkw8KQTrN2A+Vfs+dFl6GiqRMWmwMGnUb2sQGAmVem6aW/2e5m599pjEDCiCAihNnI3gBEEei02tHWbQMfrRRM52vClTi9FvdIUaNVn59Ej83p0SkTmDDK6Dob+IkVqTSA3QAfWzwaP7ykCKIIPPzBQXy031WIuZtMvaLVAUbXQa28XL7MY8TI5IzceEujAd57Gflp7shxMYHz60Sy+/VXq4C280ByAV7unIeDFS1IitPh1ZunYGJ+CkQRWH+4OvDzysJIfcSovccmp0IDiRgBKgbKcmGkJpUGANNXMBP2nEdVr+GlzSfR3mODKWc4xLhkNkak9ggMOg2ypG7qcsk+L9EfcxVgUvS14um0kxuDL9uv2MUGVSfmABnDUVojtZvIMLn0heKptGabjjW2BAL2hEUaEkYEESHi9BropDeEtm6r7C8yGbTqZ5wRPrlpWgGypKjR+3ucYuUUmFBI6QjiDVdq7ojkfHmTIAh4YskYLJtWAFEEHnz/AP5dwkSIze6QK8j8CiMAiOfCw3vJ/mm1Xa853rpf+2nuyCnoy1Raey2w7Y/sehc8hBe2sAjdb64eh5zkOCwez8ZFrAsmncZnirWdV9048JuKFogiMDglvtdYFn9MUVSmeex1FUjECGCjkW5fr7oa7Ux9h+x9e3TxWAi50qgtqQP24BTJZ9TUxf6ODn3AXp/qNmy9aAYzrrdWArXBdQ5XptEgCLLYHJ7tOjKFp9Jau6wshQewNgUxBAkjgogQgiA402ndNjJeR4A4vRbL5wwDAPxFETU6bmNDKk1tpwL7BCyKilSa6yw6QRDwm6vG4fsX5sMhAivfP4C1B6tQ0dQFi92BOL1GvhH5xE/JfqfFhvPSGAe/Xa85XiNGgaXSzjd3wWGMcMRoy28BSzscgybj9t35sDtELJ4wCN+dyKIHi8ax393XZxrkobyqMZoB3h9HZTqNp9EmBJBG40zIS4ZeK6CurQcVnvoFBeIxCoJn1x+DzSFi9shMzBiW4RwoW7kXADBYSmFVNnexSjRrJ5A5qnc3bX283OYi6HSaUhjBu+/Opb9bWmz2MiJhRBARhL8JtCqEERmvw8sNF+YjJykOVS3dWLObRXuOWrJgFwXorO1AWwApmc4G1oEZcEZhFGg0Ap5eOh7XTsmD3SHivtX78coX7NNucUai5+G27rg1eSxUCCNRFF2Gx6aaDAFGjCpdhSBPpfmJGGWajTDqNHCIQLtGupFFImJUd0IuR3/HfAdO1nchy2zEk1eNk6vB8tMSMCEvGQ4R+DSUdJpKA/YBWRilBHypOL0WY3PZ78VjOk0u11fnFwqEvWWN+ORQNTQC8OgiqRovl48G2c++lEr2Kxo7nWm0Kbd57qkkd9/eGPhietpkMcaFUamX9DLvft3arYwYkTAiiAFDotHZ6bWpI/gBsoR3WNTI6TXqttrR0COgXJQ+pdcH0NGXR4sScwCd57SKRiPgd9dMwNLJg2FziFgtiTFVaTSg1yDZ3JR4aCSTbF1bj1zJU5whlc2rihhJXg1bt1MMAc5Umh+PkSAIctSoySEZZSMRMdr4K0C0ozFvPn51kP0cfnfthF6zA3nU6JNvghFGE9ijyogRr0ibmB94xAhQNnp0MxBbu52zyEyZQZ3bG6Io4qm1RwEA103Jx8gcKV3FI0a1RwBLB/KkCGZczV6g9jCgiwMm3uD5pMMk43f5zsCN9+VfAQ4bkFIIpBZCFEXn8NhsN2HkEjEiYUQQAw5n2NhKqbQIcv2F+chNjkNNaw/e2XkWFpsDJ0UpvVR3Qv2JFBVpvtBqBPzhuolYIqV/APidyC7jNkjWoNNgULI0yLWxU76hyOdTI4x0RqfBV1my3ylFMRJS/S6LC6Naa7zrdcPF2e3A8bUQBS2W13wXAPOIzRnZO830HclntPN0Q+DNHnOkYbIqhFFDew8qm7sgCMD4wcEJI6cBu9n1BZ5G0xp8/+6C4NPD1dhX3ox4vRYrLx/hfCFpEGAeBIgOoOqg3Mtoav3H7PVx1ziFuTtpQ4D04YBoB059HtiCeDRqKBvHU9Pag/YeG7QaAUVSE1MOb3xLESOCGKCYFU0eQx0gS3jHqNNi+VzmNXppM+vjcooLo0AiRm4Vab7QagS8cP1ELJ08GAatBrNGqowKuDV5BFx9RqeVo0AAdcII8FyyrzKVBjhN4NU9UqQsnKk0uw347DEAwI6UxdjZloHC9AT84jujPe5emG7C2Nwk2B1i4Ok0nkqrP8GiNj7g89GKM0zyDTtQuDA6Xt3q0uXeabzODn7+mwesdgd+t579Td85cwiyk+Jcd+BRo/P7MDglAclox6WWL6XFupmu3ZGr0wIYD3J+P3B8LSBogIuXs8MlcV+YliB3uuYkxUv2gi6Fx6izIbJVkAFCwoggIoiylxFFjCLLdVPyMTglXh7aW66RfDeBDMf0UJHmC51WgxdumIRvfn05JqkYPgpA4TFqljcV8pL9Bl8RIz/ndzdgWzqdfik/qTRA0cuIjwUJ541q06+B8/tg0yXgvqpF0AjAc9dNhMnofZbdd8azdNq6bwKsTksazMSnwwbUHfO5a8m5ZgDqBsd6IyspDnmp8XCIwKHKVucLcql+eNNonx6uxpn6DqSbDLhLalfhglyZthe5KXG4Rvsl4mCFPWsckDfV98nl8SAb1BctfP40exx/PZDJold8FMhQD+ll3sakrdvKzPI80tkUOyX7JIwIIoIozdc8YpRGEaOIYNBpsEKKGgFAtUGK+tSHP5XmTkDtFzxEjHi0pqyhw3V4LBBAxMitZJ/7izQ6dgPyAxdGZzqkv89wRYwOfQDseBEA8Av73ahHMv7frKGYWuRbrHFhtONUA5oCSacJApAtpdP8GLCdjR1T1J/fAyOlknReog5AUZEWXuP1x/vZuJTrL8yXx8m4MFgyYFfug9mow836zQCAhpE3+Y9cFV7CRsK016gbq3JuN6tiE7TArIflzTxiNNyDMHKar6WJADGYTiNhRBARRDZfu1SlUcQoUlw7JU8eAtoQX8Q2tteoj37IqbTCsK9NxkOfIC5Kdp9tQpfVDp3GOSpEXrs/YeQeMepU9DBSkcrhjSZLW3Wu1w2F6kPAv1cAAD5J/j7WdE3FqBwz7p8/3O+hQzJMGD2IpdM+OxJoOk0yYO97x+vMN1EU5VRaMKX6Srjxnkf7AChSaeGLGDV3WvDFCXbeqycN9rwTjxg1nQGO/RfFqESHaMSx7Cv8X0BnBIpnseelKtJpW6Ro0cQb2WgRCV8NT3kqTU478uNIGBHEwEBpvuYmUkqlRQ69VoN757GbbmpahrOzrtqoUYCptKDwEDHiqTQ+8LMwPQF6rfT2HKzHSGVFGief97zp5h6jFsDhZTiqGjobgTXLAGsnWnJnYnnNldBrBbxwwyTVETa52WOg1WkTvw/oE4BzXwOvzfNowK9o6kJDhwU6jYDRg7zMoFMJTxmd9CSM1Ha9VsHab6pgtYsYlWN2VqK5E58KpEli45NHAAD/tl+C8nbvaUsXlOk0X5TtBE5tZhHJWT91ecmXMJLN11021hRT7mVEqTSCGBCYFR4jMl/3DddNycPrt07FU0vHy54HVT6jrmZneXWAqbSAcGvwCDgjRpxiZYWbWmHEB5DKESNuvFYnjOINWmSajWgFryISAUuQ09YdduCDO4Cms0BKIZ6MfwgOaLB08uCARMgiKZ22/WS9PGdQFYMmALd/ygRu4yngr/N79efZdLQGADB2cDLi9KF1oh/mURix84czlfbvEpZGu3qyl2gRhxuwpbTqe/Z5zrEg/uBz0yp2+Z5hxqNFk28GUovkzU0dFnk2m6dKTV6ub7E70GNzUCqNIAYayi6vTTRAtk8QBAHzRmezLtQZI9lGNZVpPI2WkA4YTL73DQVlg0fJ4Jocr5f/VgCFvwgIPGLUdp4JE5Vdr5UUpCWgBwbYNVLUKNh02uYngVObAF08aha/gQ+Psq7et0vDeNUyNDMRo3LMsDlEbDhSE9gaBk0A7vwcyL+YCd73rgN2rgJEEaIo4u9fMz/ZtRf4ERkq1wkA1a3dzhRRB2/uGJ5UWmVzF3adaYQgQO4S7hXuMwJQax6DQ2KxHI30S0o+kDmalfyf9lK2f+ZL1ulaowdmPuTyEvdZDU6J92iuNxl0cmbXpWS/IXbGgpAwIogIwj1GdW097NMRaIBsnyJHjFSk0voijQY4I0YOKxvRANcGi4Dik7atx1lZ5k8YJeawkmmHjaVxeKpOZSoNcEauunVSmiYYA/bhj4Ftz7PnV/0Zb5SaYHeImDEsHaNyAk9Z8WaPAVenAUyU3PofFtUQHcCnPwf+vQJ7TlWjtLYd8XotrvIXfVFBcrxenrN2SupcHu6I0X+kaNFFRWnI9Td6hkeMAFQPuxGANC9NLb7SaaIIbHmGPZ9ya6/oKo+aeapIA1iDVN7GpLXL5hzh0lHLOmjHACSMCCKC8KqRc03sBqjTCJ4rSYjIEEjEKMiKtIAxmJgvA/DoMwKk4bEA0M3LvwXA6EdUaHWsuR/AfEYBptIAZ3VcuyDd1AKNGNUeBT7+MXs+fQU6RlyNf+xiP9fbZwQWLeIsnsB8RttO1qOly+pnbw/ojMB3/wwsfIYJx5K/If2Da5GOFlw1KVceahoqfCaYnE7j40DC5DHiQ4v9ptEAZj435wLmXIjjvgcA6iNGgGI8yIbePrPTW4Cy7YDWCFy6stehpTXeK9I4vDKtrdvKihF4n60Y8RmRMCKICMLTI50WNtw0JcEgz4Qi+oBMSRg1lQFWPzeGvqhIA1iFmI+SfUAaHgs402jGJECj4u1arkyrcK1KUwmPGLWI0loCiRh1NQOrbwKsHcCQWcD8X+PDfRVo7bahKD3BY4drNQzLMmNEdiKsdhEbA02ncQQBmP5jYNk/4TAmobjrEP5t/CV+NKwjuPN5XKdCGFk6nf6sMAyQPVbdimPVbdBrBSwal+P/AH0ccM924J7tGJSVAQCoae2G1a7STF9wMWAwA531QFWJc7soOvsWTb3Nmb5VwFNpvkbkOLtfx2bJPgkjgoggSt8IQMbrPseUKXl6RKDhpO99ecQo0qk0wGOTRy5K5OGxgHp/EUdZmRZgVZpyDfW2AOelORzAh3eyG1tyAXDtm3AIWry5/SwA4LYZQ9QN2PVCSOk0JcPm45+T3sJpRw7yhHoM/+/3gJObQjsnP7VSGPEeRro4VT2k/MF7F80emaW+qjUhDUhIQ4bJCIM0ILi6xXcncBmtHhg6mz1XptNObmKmbF0ccOkDHg895aMijcMN2K08AkjCiCAGDu5jBqiHUR8jCM6okb/KtL5KpQEeI0a8yeAFBYpZVjxio1YYKXsZBZFK48Koxhrnen1/bHmGNfrTxQHf/xtgSscXJ+pwur4D5jgdrp2Sp3oNnlg8gQmjL0vrmWE3SBwOES8f0uBqy/+gOmM683ht/k1Ia+PIvYzq2l3TaCFGiB0OEf93QKpG89a7yAcajcAKERBsOu0z9iiKwOdPsecX3gGYe0euOnps8jWG+ZgdyN8X2yhiRBADD3c/EUWMokCGZMD218sogDlpIeOhyeO4wcnY8MBl+NP3Jzn3CzhipOh+HUQqLcvMogvNolvXbV+cLwG2PsueL3kRGDQRAPDGduYX+f6F+T5Hf6hheFYihmaaYLE75DL7YNh5ugFnGzohGlOQvPh/2EYuYkKEC6Oyhg5YW6XIVhjSaHvKmlDZ3IVEow7zRgd3vtwUJnQDMmAPm88eK/cCHQ3AiU+B8/tYf6gZ93s85JSURstINPj8ECjPS+t2jxiRx4ggvvUYdBoYFUMUqVQ/CqiJGFk6nBGWvkileYgYAcDwbLOriODChAspfygjRkFUpWk0AvJT49GKAFJpR/7NHkcvASbeAAA4UdOGL0vroRGAW6YXqb6+NwRBwGKpp9HagwE2e1Tw96/LAABLLxiM+CRJMKoRfyrIMhthNurgEIGGGqmXVBiE0ceS6fqKcTlB91viESPVvYwAICkXyB4PQARObnRGiy66y2sLgpPuc/68nTpOYb4GnA0pKWJEEAMDpc+Iul5HAbkyzUfEiJfqG5PUi5BQ8NDk0SPBeoyazgI9UkVbAKk0gKXTWuWIkZ/1Ac5Uy+jvypvelKJFC8fmuJjKQ4E3e9xaWuc6xV4lta3d+OwwizbdNK3A6fOytAF2W8jrEwRBLlFvqQuPMLLYHLKvKpg0GmdwimtnddXwsv3Nv2Gz0wyJwCX3et3dV8drJU6PEU+lSRWLbeeZcT3KkDAiiAijTKdRKi0K8F5G9aXeb4B9mUYDXJs8+iJgj5GUSuusZ4+CRv2xEgVpCWjh3a/9CbeWCjaoVdDIqZfGDgs+3MeEQaANHX0xKseM4gwTLDYHNh+rDfj49/ecg80hYkphKuunFKdof8BFZIhwQdDTJKXSQizV/+JEHZo7rcg0GzF9qPqUqDuDU4PwGAFOYcT/f0y7GzB5X0epj+GxSpyDZCWBm5Dm/D/RdDawNUYAEkYEEWGUBmxKpUWB5AJAF88aKnp70+3LijTAGTHyF5EJNGJkymTdiDlxKYAmsPRLfloCWtRGjE58yh7zLpQjU+99XYYemwMT8pIxtTDVx8GBIQgCvjM+uOo0u0PEP3axm/uyaZL41erZJHkgbOk0Lowc8gDZ0IQRT6MtmZALbQhVfbLHKFBhlHcRYJT+9oxJwPTlPnd3VqT5rsRTTgSQkX1G0e+ATcKIICKMMmJEXa+jgEYDZAxjz701euzLijTAma7zGzEKUBhpNK69ZQJMowFSxEhUGTHiaTSpgslic+CdnczHc/uMIWHv2bVIGiq75XgdOnrUp7+2nqhDZXMXUhL0srgC4Py5BtPh2wO8EkvfxceBBC+M2ntsct+mqyf7GQHihzwplXa+uYsNblWLVgeMXMSeT1/u8++px2ZHWSNLg/lPpfFBsoqUaAxVppEwIogIo/QYUbl+lMjwY8Du61RapDxGgDOdBgRUkcYpSFek0nxFUqxdwOkv2PMRVwBgkZzath5kmY2uAiRMjBmUhKL0BPTYHHh1q/obKDddX3tBnquBWRZG4Y0YJdqkisAQUmmfHqpGj82B4gwTxg8OLB3qTk5yHAQB6LY65AGvqrniGeD6d4HLfupzt7P1nbA7RJiNOmQnGX3u6+x87SliRMKIIL71JCqFEaXSokOmHwN2X81J46j2GAUhjJQRowAq0jj5qU7ztdjdLA+67cXZbWyOW9JgIHssRFGUS/RvmV4Igy78txdBEHDHTHYDfXFTKf68udTvMeebu2RP0o3T3IRvmIVRfloCDDoNMtDMNoQQMeJptKsmDQ458mbQaZBtDqJkH2BRojHf9ZuSVc5I87de/mHRpScVCSOCGDgkuXiMKJUWFXgvI28Roz5PpUUyYhRaKs1k1EFnSgEACA4ba2XgCe4vGn45IAjYW9aEgxUtMOo0uPGiyEXebr64EA8uYL/PP3x2Ai9t8i2OVu8+B4cITC9O711GLveTCo8w0moEjE7XwiT0sA1BCqPatm5sP8kM9FdNCi2NxuE+o4BK9gNAbUUa4C+VFv1eRiSMCCLCKD1GyfEkjKKCHDEq7R0BsfUA7VJvnEjPSePwG3JPC+Cwe98v1IhREMIIADLS0mAVpQiBJ/+NKAKlkjAasRCAs6Hj0smDkZ7oO5USKj+ZNxw/Xch+p89tOIE/bfQsjqx2B1ZLQ2yXXexBrIU5YgQAE1NZqsqmiWPl7UHw3wNVcIjApPwUFGWYwrKuwalBluyrpLSWzYZTI4x4xKjDYoeNz2/jwqilArCqHF0SIUgYEUSE4am0pDgddFr6LxcV0oYCgpb1rGk97/paSwV71MUH5ckJCp5KA3zflEP1GAWRSgOAgnST75L9umMsyqY1AkMuw7nGTqw/xMTlbTPCV6Lvi+Vzhsni6IWNJ/DHjb3TpJuO1qK2rQcZiQZcPsbD8NUICKMxZiY8WrSpQY8D+beURrs6TNEiwNnksSLQVJpKTqos1QdcK3XbuYnelMEq3yACzWWRWKJq6F2aICIM/3RExusoojM4P5G6V6bJxuv8kOdaBbQeHk3w5jOydgM26ZNz0BGj4IRegb+SfZ5GGzITMJjwzs6zcIjApcMyMDIn9KGpalk+Zxh+dsUoAMAfN5bihQ2u4oibrq+fmu/Z88R/rmqH5apgaAKrzKoXgzNMn6nvwIGKFmg1AhZPCKcwCrJkXwV2h4jT9SzlqiZiZNBpEKdnvw/ZgC0IzkaPUfYZkTAiiAjDPx2R8TrKyKNB3CILsr+ojyrSOLIBu9nz63LTQQEwBCA2QvQYAcxE3OqrMo2X6Y+4Au09NqzezcTl7ZcWBXW9ULhn9lA8uoiJoz9tKsXzG05AFEWUN3Tiy9J6CAK8e54iEDHK07OUUoXNHFhpvASPFs0YloFMc/hSkrzJYyQ8RhVNnbDYHDDoNMhLVdfpnPuMWmKwZD+0yX4EQfjlsuEZmDMyE9+7ILQJ40SIyMNk3SJGfV2RxolPZcNeu71EjJRpNE0An2HjU9mgT2tn8Kk0X72MupqA8q/Y8+GX49n1x9DWbUNxhgmzR4Q+GywY/t+soRAE4Ol1x/DiplKIogiL5F25bHim97EkERBGmQI7V7UtCXXtPciSqsHUIIoi/l3CUr3hTKMBIYwFUUFpjXNGmtpGlEnxetS29cRkZRoJI4KIMCkJBrx520XRXgbhLWKkTKX1JXKTx2bPr/PtAY70gCAwQ/TZ7UD2mKCWVpCWgD3SIFlHV5NrauHUZkC0A5mjsLUuAe/sPAQA+NV3x0ITQnfmULnrsqHQCAKeXHsUL20+CZ20lmXuJfpKeNQujMJI18WqyeqQjJO17QEJo4MVLThT34E4vQaXj/XgiQoBXpXW3GlFR4/NdVhxiByrZtFNNWk0ju/u15RKIwiCiDxeI0Y8ldZHFWkcf92vgzFec659E1h5xNkWIECyk+LQBnaTa2+ud33xBEujdQ+Zj5/+6wAA4NbphbhshOeJ633JHTOL8dji0QAAm0NETlIc5o7yEcWKQMQI0jiQejFZHpGhlnWH2KiT+aOzXapZw4E5Ti8Pbw13Ou3rM6yhZSAjYHyW7DdEdywICSOCIAYGXBh11AGdjc7t0Uql+fMYBTpAVokgsFlgQaLVCBCl63a0KISRwy77i16tGoaa1h4UZ5rwyKLRQV8r3Nwxsxi/WjIGBp0GP54z1HclaASFUZ2YLFdqqeVzqRHlgjHZ4VuPAl6yXxFGYWS1O7DnLBP3FxerN/v7jBi1nANsAXboDiOUSiMIYmBgTGSl7K0VrAN2wcWA3Qa0MrNrn5uv5SaPEYgYhQGdKQ1oBnraFCKyci/Q1QiLPgkvlaZBqxHwwvWTEG8IbFBtpPnhjCH4wfQi/36XMM9KAwC0s/lmdWIK2uvUC6OKpk6cqGmHRgBmRSj6NjglHkerWgPvfu2DgxUt6LLakZqgV1Wqz+FjQVw8RonZ7ANKYjb7nYQ4hDdYSBgRBDFwyBzBhFHdcSaM2s4zv4zWwN6M+xK563Kz59dlYZTSB4vpjdHMhJG9UyHcpDL9TdZxsEGH++YMw8T86KzPH6pMwFwYWTtZhEIXYuWoKLKIJIB6JKMngIgRjxZNKUxFSoQqWPOkyrRwGrC/Ot0AAJg2JD0gj5kzlaaIGAkC8MChsK0tWCiVRhDEwCHDbWYaT6MlDQ6s8iscxHjEKDE5AwAgdLfK20Sp2/VnlomYkJeMFXOHRWVtYUP5s+1p9b6fWiztTGSBeYxqWt2qrnzA57nN8eWJCpFIjAXhwuji4sAqIJ2pNHU/n76EhBFBEAOHTLeZaXJFWh+n0QAVHqPoCqPkNCaM9FZpHa3nIVR/A4coYKdmMp6/fhL0/b2Tu0YrdVtGeHxGkr8IehMSzez3psaA3W21Y8cpJjB8msVDRC7ZD1MqzcVfNDSwZqIeU2kxQj//qyYIgggAOWIkCaO+Hh6rJMYjRhkZLLUYZ2cNC2v3/R8AoEQcirsXXRRQaXZME06fkZRGQ2Km/PNRY8DeeaoBPTYHcpPjMDI7cp3DB4c5lab0F43ICmzdSZ7M1zECCSOCIAYOvJdR8znA0ukURslRiBhxYeTXYxQdYZSVxYRRktiB5k4Lzuz4AABwOmUGbpleFJU1RYRwVqZJxmskZjuFkQoDNk+jzR6VBSGCY2n4vLSa1m5Y+fDWEAjWXwQoPEYUMSIIgogipgypG7QINJRGN5UWyT5GYSAxhaXSjIIVv35/J8b3lAAAZi+5JaqNHMNOOOel8VSayRkx8pdKE0VRFkZzR0a2CivdZIBBp4FDBKpbQp9gH6y/CACS4lnEyMV8HSOQMCIIYmAhd8A+HhupNFs3YPWQ2uDCiAuovsZghl26RWhL1yJB6EFXXDYyhk2JznoiRVgjRpIwSszGsEx1qbTS2nZUNnfBoNPgkmHBDf1Vi0YjyFGjUNNpofiLAOcMSTJfEwRBRBve6LHuGNBSwZ73dXNHgA2GFaS3YE/RiihHjKDRoFvDbu5Xa7YBAOLHXMFKqr9NhFMYdXBhlCVHjMobO9FttXs9hEeLphenI8EQ+Q46sjAK0YAdir8IUKbSbEEN240kJIwIghhY8IjRmS8BuwUQtK4T6fsKjUYxq6vZ9TVRDK3zdZiw6tkN7xLtEbZhxMKorSVihHNeWrtkvjZlItNshDlOB4cInG3o8HoI718UyWo0JbxkP9SI0ddngvcXAc5yfbtDRJcP4RgNSBgRBDGw4JVplXvYY1IuoI1Sr1tvPiNbNxNtQFSFUUIyS5FoILImmENmRW0tESNC5mtBEPxWprV0WbGnjP3u+0oY8ZL9UHsZfXWadUSfFoS/CAASDFq5CWes+YxIGBEEMbDgESNRqsqJRhqN461kn9+kBQ1giF5ZvCFRcdMrmsnGqnzbiFAqDYBfn9GXpXWwO0QMy0pEflpC6NdXQThK9pm/iAmjQOajKREEQS7Zj7XKNBJGBEEMLJLzAL3J+XU0KtI43po8Kv1F0fT0KMeRfBvTaED4+hiJosJ8LQkjPxGjzX2cRgPC4zH6prIFnRY7UhL0IfVdilUDNgkjgiAGFoIAZAx3fh2NijSOv4hRFNNoAFwr4oZfHrVlRJRwRYx62lgKFABM/oWRwyHii+PMkzR7ZGSGxnpCWZUWrOnZ2b8oLaTWDbFask/CiCCIgQdPpwGxkUpzj1bEijDiEaOMEUDakKguJWKESxjxaJHBDBhYWmyolEo7Xd8Bu8NVhByoaEZDhwVmow4XFgXn0wmGnOQ4CALQY3OgocMS1Dm4vyjYNBrHbIzNJo8kjAiCGHjwkn0guqk0b+brWBFGeReyx8k/iO46Ign/HYQqjGR/kTP6k5+WAINOA4vNgYqmTpfdP5eiRTNHZPTpzDmDToNss1SZFkQ6LRz+Io4cMYqxsSAkjAiCGHgoI0ZRFUY8ldbsuj0GSvUBAKMWAw+eAC75SXTXEUnCHTEyOf1CWo2A4gzmZ3NPp/Ey/TkR7nbtiVAM2OHyFwGKXkZdFDEiCIKILpmjpCdCdHoYcWTzdYxGjAQBMGd/+5o6KuE/Y1s3YA1hTIab8Zoz1IPPqLa1G99Ust/x7CgIo1zJZxRMyX64/EWA0nwdWxGjKDXvIAiCiCLpw4AL72Cf7vVx0VuHX49RSl+uZmBiMAMQAIjs5x7s30OHZ2HkqWR/i5RGm5iXjEyzMbjrhQA3YFcEkUoLl78IUKbSYitiRMKIIIiBhyAAi5+L9ipUeIxS+nI1AxONBohLYj/z7hYWIQsGRXNHJXJlWp1TGPEy/Tl9WKavJNhUWjj9RUDsRowolUYQBBEtYr1cf6AQDp+RYhyIEmXJviiKsNgc2HayHkDf9i9SkhdkL6NDYfQXAXA2eCSPEUEQBAHAdU6Xw+Hczs3YJIz6hnDMS/OSShuSYYJGYFGRurYe7DnbiPYeGzISjRiXG53fr+wxaglMGPE02kVFofuLACApnsr1CYIgCCU8lSY6gJ5W53aKGPUt4eh+LZuvXVNpcXqtPO7jZG27nEabPTIzLOIiGHgqrbnTio4e9WksbrwORxoNcA6SpVQaQRAEwdDHAzp2k3K5KZMw6ltCTaUpx4GYenexlg3Yde3YfLzvx4C4k2jUIVmK1qj1GYXbXwRQuT5BEAThCU8GbBJGfUuoqbTuFsDew54n9hY83Ge06WgtTtd1QKcRcOnwjOCuFSZyUwIzYB+qbEGHxY7keD1G5YTuLwKcwogiRgRBEIQT9yaPokjCqK8JNZXWIRmvjUksCugG72X0xQm234VFabIoiBaBDpPl/qJw9C/i8HL9LqsdFpvDz959BwkjgiCIaOLe5NHaBTik1AIJo74h1FQaL9X3kEYDnBEjTjTTaJy8AEv2w+0vAlhKj9MWQwZsEkYEQRDRxL3JI785C1rAYIrKkgYcoc5L82K85rgLo2j1L1ISSMQoEv4iANBpNTAZtABiK51GwoggCCKauHuMlGm0b/Mojlgi1IgRT6Uleo4YJcXpkSV1uM5Pi8fQzOgL3kDGgkTCX8SJxZJ9EkYEQRDRxN1jRP6ividcqTQvESPAGTWaOzILQgwI3kC6X0fCX8SJxZJ9GglCEAQRTdw9RiSM+p6QhREv1feeIrtlehE6emy49ZKi4K4RZngqraa1G1a7A3qt9zhJJPxFnFgs2SdhRBAEEU28pdL4diLycGHEo3aBInuMPKfSAOCKcTm4YlxOcOePABmJBhh0GlhsDry7swwzh2dgaGZir4iQLUL+Ik4sptJIGBEEQUQT2XwtCSJuwqaIUd+hjBiJYuDerg7f5utYRBAEDM1MxNGqVvzPf48AAMxGHSbkJ2NSfgom56diUkEKKpq6IuYvAiiVRhAEQbjTK2LUzB5JGPUdPJ3psLJ2CYaEwI5XkUqLRV78/iT8a18F9pc345uKFrT12LD9ZAO2n2yQ9zFLJfUXRcBfBFAqjSAIgnCHzNfRx2Bi7RFEO/v5ByKMHA6n+drcfyJGADA824xHF40GwFJmJ2rasf9cE0rKm1Fyrhkn69rRJs1Su2yE9zRhKPCIUStFjAiCIAgAZL6OBQSB/by7GtnPP2mQ+mO7GgGHdFPvZxEjJTqtBmNykzAmNwnLphUCYL6fg+da0NDRg8XjA/iZBAB5jAiCIAhXeMTI2gHYLAphlBK1JQ1IlMIoEHi0KCEd0BnCv64okhSnj/hMN2cqLXYiRtTHiCAIIpooI0PdzRQxihbBzktrq2aPibFTcdafcJqvYydiRMKIIAgimmi0ruXiJIyiQ7C9jOTmjv03jRZNnKk0ihgRBEEQHKXPiIRRdAh2XhqPGJkpYhQMFDEiCIIgeqMcJEvCKDoEm0pTMQ6E8E4sluuTMCIIgog2PFrR2UjCKFoEm0qjiFFIJPGIUY8NDocY5dUwSBgRBEFEGx4xaq10ln5TVVrfErTHqP91vY4luMdIFIEOS2z4jAa0MFq6dClSU1Nx7bXXRnspBEEMZLgwai5jjxo9oI+P3noGIrLPqzmw49opYhQKRp0GBmmAbawYsAe0MLrvvvvwzjvvRHsZBEEMdPhNuems9HVy4PO6iNAIOpVGHqNQEAQh5gzYA1oYzZ49G2Zz+IfiEQRBBASPGCmFEdG3BCOMetpYY06AhFEIyCX7MdLkMSRh9Nvf/haCIOD+++8P03IYW7duxZIlS5CbmwtBEPDxxx973G/VqlUoKipCXFwcpk2bhl27doV1HQRBEH0CN1+3VLBHEkZ9D4/aBSKMeLTIkAgYE8O+pIGCPC8tRirTghZGu3fvxquvvooJEyb43G/79u2wWnt/s0eOHEFNTY3HYzo6OjBx4kSsWrXK63nXrFmDlStX4oknnsC+ffswceJELFy4ELW1tfI+kyZNwrhx43r9O3/+vMrvkiAIog/gESPRwR5JGPU9wUSMuL+IokUhwUv223r6sTBqb2/HsmXL8NprryE1NdXrfg6HA8uXL8dNN90Eu90ubz9+/Djmzp2Lt99+2+NxixYtwpNPPomlS5d6Pffzzz+PO++8E7fddhvGjBmDV155BQkJCXjjjTfkfUpKSnDo0KFe/3Jzc4P4rgmCICKEewUaCaO+RymMRJVl41SqHxaS4nnEqB+n0pYvX47Fixdj/vz5vk+u0WDdunXYv38/brnlFjgcDpw6dQpz587F1VdfjYcffjioRVssFuzdu9fl+hqNBvPnz8fOnTuDOqc/Vq1ahTFjxuDCCy+MyPkJghjAxLt9wCRh1Pfwn7loByzt6o6hUv2wYDZKEaMYMV/rAj1g9erV2LdvH3bv3q1q/9zcXGzevBkzZ87ETTfdhJ07d2L+/Pl4+eWXA14sp76+Hna7HdnZrn+M2dnZOHbsmOrzzJ8/HwcOHEBHRwfy8vLwz3/+E9OnT/e47/Lly7F8+XK0trYiOZnetAiCCCPcY8QhYdT36ONZmwSHlUWNjCoKc6hUPyzIEaMYKdcPSBidO3cO9913HzZs2IC4uDjVxxUUFODdd9/FrFmzUFxcjNdffx1CDJSibty4MdpLIAiCoIhRLCAI7OfeWc+EUXKe/2PaaIBsODDH2FiQgFJpe/fuRW1tLS644ALodDrodDp88cUXePHFF6HT6Vx8REpqampw1113YcmSJejs7MQDDzwQ0qIzMjKg1Wp7mbdramqQk0PKnSCIfoY+AdAanF+TMIoOgQ6Slc3XdN8JBXksSIxEjAISRvPmzcM333yDkpIS+d/UqVOxbNkylJSUQKvV9jqmvr4e8+bNw+jRo/Hhhx9i06ZNWLNmDR566KGgF20wGDBlyhRs2rRJ3uZwOLBp0yavqTCCIIiYRRBcDdg0DiQ6BFqZxiNGZvIYhYLcx6g/eozMZjPGjRvnss1kMiE9Pb3XdoCJlUWLFqGwsBBr1qyBTqfDmDFjsGHDBsydOxeDBw/2GD1qb2/HyZMn5a/PnDmDkpISpKWloaCgAACwcuVK3HrrrZg6dSouuugi/PGPf0RHRwduu+22QL4lgiCI2CA+FeiQzLzuniOibwhUGFHEKCzIqbQYiRgFbL4OBI1Gg6effhozZ86EweAME0+cOBEbN25EZmamx+P27NmDOXPmyF+vXLkSAHDrrbfirbfeAgDccMMNqKurw+OPP47q6mpMmjQJ69ev72XIJgiC6BcoxRCl0qID/7mrmZdm6wG6mthzMl+HhJxKixGPUcjCaMuWLT5fX7BggcftkydP9nrM7NmzIaroI7FixQqsWLHC734EQRAxj9KATcIoOgQSMeKl+hp9b/M8ERDOiFFsCKMBPSuNIAgiZnDxGJEwigoBCSPF8NgYqLLuz8RauT4JI4IgiFiAIkbRJ5B5aXLXa7JvhAo3X1tsDnRbPVe39yUkjAiCIGIB7jHSGgCd+j5xRBiRI0bN/vcl43XYSDTo5KBbLJTskzAiCIKIBXjEKC6ZUjPRIpBUGpXqhw2NRkCikafTou8zImFEEAQRC/A0DqXRokcgqTTZY0QRo3CQFEPdr0kYEQRBxAKphewxOT+66xjIBJRKo4hRODHHUPfriPYxIgiCIFSSPw34/j+AnPHRXsnAJaBUGvcYkTAKB7HU/ZqEEUEQRCwgCMCo70R7FQMbeVZaK+BwABofSRVluT4RMrE0L41SaQRBEAQBAMYk6YkIWNq87+ewOxs8UtfrsEAeI4IgCIKINfRxzlYJvtJpnQ2AaAcgAKasPlnatx3uMYqFVBoJI4IgCILgqPEZ8TSaKQPQkiMlHHCPEaXSCIIgCCKWUDNIto1K9cMNpdIIgiAIIhZRFTHiFWmURgsXsVSuT8KIIAiCIDhqmjzKc9IoYhQuYqlcn4QRQRAEQXAC8RhRqX7YkM3XXRQxIgiCIIjYQY0woohR2OEeozaKGBEEQRBEDKEqYiT1MKKIUdhwptIoYkQQBEEQsYOaeWntFDEKNzyV1t5jg90hRnUtJIwIgiAIguMvYiSKinJ9ihiFCy6MAKA9ylEjEkb/v727R27bCMMA/IGkRdkKqSZWoRkXaXOFnCGXSJs75H45QlK6UBGl8JDWWB5bRArsUhAMmvYMSSDa52mwsgpvp3fe/QOAbPte2o5g9HEV8flDMxaMDmY+m8Z81kSSoU+mCUYAkO1rjHJbNF9GnL06zZwKMZYj+4IRAGT7gtH2ckdt0aEtR3JkXzACgGzfBY/5RJqN1we3GMmRfcEIALLcGH1cRWwevvz9WmN0LGM5si8YAUCWg1FEf2vkqP7RPN5+rTECgHGYvoh4cdGM+4LR9qi+B2QP7fH2a40RAIzH1zZgbzdfa4wObfkyNUb2GAHAiHwtGOXGaGGP0aHlxshSGgCMicZoEPm4vqU0ABiTXe+lfbp/DEsao4PLx/UtpQHAmOxqjN6nZbTp/PG+Iw4m7zHSGAHAmOx6L+196/HYqjrplEqw1BgBwAjtaozy5Y6W0Y5iYfM1AIzQvqU0t14fRXspra7rweYhGAFA297GyIm0Y8iN0edNHR8+9TzHciKzwf5nABijHIw+vHv679vGSDA6houzafz2y0/b5mgoghEAtO1bSrPH6Ciqqoo/fv156GlYSgOAJ/JR/F1LafYYPWuCEQC02XxdNMEIANpyMPp0F/GQjo5vHiLubpuxzdfPmmAEAG3z5eP4ftV8724j6k1ENYm4eD3MvDgJwQgA2qaziLNFM87vpeVltIvXEZPpINPiNAQjAOjqPiS7tr+oFIIRAHR130t773LHUghGANDVPZm2bYyuhpkPJyMYAUBXNxjlxsit18+eYAQAXV80RpbSSiEYAUDXF43RP83X5utnTzACgK7uQ7I2XxdDMAKArvZ7aXXtuH5BBCMA6Govpd2/i3j42PwsGD17ghEAdLWDUW6Lzi8jXpwPNydOQjACgK52MHJUvyiCEQB0PQlG6UTawjJaCQQjAOhqv5W21hiVRDACgK78Vtrn+4h3b5uxxqgIghEAdJ0tIqJqxv/+1XydSCuCYAQAXZNJxPmyGd/+3XwtpRVBMAKAPnmf0fbWa41RCQQjAOiTg1GmMSqCYAQAffKzIJnGqAiCEQD0aTdGs5cR8+Vwc+FkBCMA6NNujH64iqiqwabC6QhGANCn3Rgt7C8qhWAEAH3awcgdRsUQjACgj8aoSIIRAPTRGBVJMAKAPvm9tAiNUUEEIwDo86QxEoxKIRgBQJ8nwehquHlwUoIRAPSx+bpIs6EnAACjdHEV8erHiNl586UIghEA9JmdRfz+Z0Q1iZhYYCmFYAQAu1xoikojAgMAJIIRAEAiGAEAJIIRAEAiGAEAJIIRAEAiGAEAJIIRAEAiGAEAJIIRAEAiGAEAJIIRAEAiGAEAJLOhJ/B/U9d1RESsVquBZwIAfKv8dzv/Hd9FMPpO6/U6IiLevHkz8EwAgO+1Xq/j8vJy5++rel904onNZhM3NzexWCyiqqqhpwMAfIO6rmO9Xsf19XVMJrt3EglGAACJzdcAAIlgBACQCEYAAIlgBACQCEYAAIlgBACQCEYAAMl/gxLd3V3EBsgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, some routers to predict scores.  First up is the \"implicit\" router that full on guesses the score and is trained as part of the model."
      ],
      "metadata": {
        "id": "HEkJ9WPjnkbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            *[z for l in layer_sizes\n",
        "              for z in [nn.Linear(l[0], l[1]), nn.ReLU()]][:-1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# Set up signed Kaiming initialization.\n",
        "def signed_kaiming_constant_(tensor, a=0, mode='fan_in', nonlinearity='relu', k=0.5, sparsity=0):\n",
        "\n",
        "    fan = nn.init._calculate_correct_fan(tensor, mode)  # calculating correct fan, depends on shape and type of nn\n",
        "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
        "    std = (gain / math.sqrt(fan))\n",
        "    # scale by (1/sqrt(k))\n",
        "    if k != 0:\n",
        "        std *= (1 / math.sqrt(k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tensor.uniform_(-std, std)\n",
        "        if sparsity > 0:\n",
        "            mask = (torch.rand_like(tensor) > sparsity).float()  # Keeps (1 - sparsity)% weights\n",
        "\n",
        "            tensor *= mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "# A function to retreive a subset of the top k% of the weights by their score.\n",
        "# The gradient is estimated by the identity (i.e. it goes \"straight-through\").\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # scores: shape (..., N) or (..., out, in). We operate over the last dimension(s) flattened per-sample\n",
        "        orig_shape = scores.shape\n",
        "        B = scores.shape[0] if scores.dim() > 1 else 1\n",
        "        per_sample_numel = int(scores[0].numel()) if B > 1 else scores.numel()\n",
        "\n",
        "        # Flatten each sample to 1-D, run top-k mask per sample\n",
        "        s = scores.reshape(B, -1).clone()\n",
        "        out = s.clone()\n",
        "        # sort ascending per row\n",
        "        idx = torch.argsort(s, dim=-1)             # [B, M]\n",
        "        j = int((1 - k) * s.shape[-1])             # number to zero per sample\n",
        "        flat_out = out\n",
        "\n",
        "        # zero the smallest (1-k)% per sample\n",
        "        rows = torch.arange(B, device=scores.device).unsqueeze(-1)\n",
        "        flat_out[rows, idx[:, :j]] = 0\n",
        "        flat_out[rows, idx[:, j:]] = 1\n",
        "\n",
        "        return flat_out.reshape(orig_shape)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "        # straight-through estimator\n",
        "        return grad, None\n",
        "\n",
        "\n",
        "class LinearSubnet(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, router=None,\n",
        "                 bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "        self.k = float(k)\n",
        "        self.router = router\n",
        "        self.out_features = out_features\n",
        "        self.in_features = in_features\n",
        "\n",
        "        if router is None:\n",
        "            # unrouted: keep the double-score params as before\n",
        "            self.popup_scores = nn.Parameter(torch.randn(*self.weight.shape))\n",
        "            self.popup_scores_extra = nn.Parameter(torch.randn(*self.weight.shape))\n",
        "            self.bias_popup_scores = nn.Parameter(torch.randn(*self.bias.shape))\n",
        "            self.bias_popup_scores_extra = nn.Parameter(torch.randn(*self.bias.shape))\n",
        "        # else: router produces scores; we don't keep per-layer score params\n",
        "\n",
        "        # init and freeze base weights\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=self.k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "        self.weight.requires_grad_(False)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(False)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        if self.router is not None:\n",
        "            B = x.shape[0]\n",
        "            out_f, in_f = self.out_features, self.in_features\n",
        "\n",
        "            # Router must output: out*(2*in) + (2*out)\n",
        "            router_out = self.router(context)  # [B, out*(2*in) + 2*out]\n",
        "            w_scores_flat = router_out[:, : out_f * (2 * in_f)]\n",
        "            b_scores_flat = router_out[:, out_f * (2 * in_f) : ]\n",
        "\n",
        "            # reshape and abs just like unrouted\n",
        "            w_scores = w_scores_flat.reshape(B, out_f, 2 * in_f).abs()  # [B, out, 2*in]\n",
        "            b_scores = b_scores_flat.reshape(B, 2 * out_f).abs()        # [B, 2*out]\n",
        "\n",
        "            # top-k over doubled scores, then slice first half\n",
        "            w_mask_2x = GetSubnet.apply(w_scores, self.k)               # [B, out, 2*in] in {0,1}\n",
        "            b_mask_2x = GetSubnet.apply(b_scores, self.k)               # [B, 2*out]     in {0,1}\n",
        "            w_mask = w_mask_2x[:, :, :in_f]                             # [B, out, in]\n",
        "            b_mask = b_mask_2x[:, :out_f]                               # [B, out]\n",
        "\n",
        "            # masked linear\n",
        "            W_eff = self.weight.unsqueeze(0) * w_mask                   # [B, out, in]\n",
        "            b_eff = self.bias.unsqueeze(0) * b_mask                     # [B, out]\n",
        "            y = torch.bmm(W_eff, x.unsqueeze(-1)).squeeze(-1) + b_eff\n",
        "            return y\n",
        "\n",
        "        else:\n",
        "            # unrouted path (unchanged)\n",
        "            adj = GetSubnet.apply(\n",
        "                torch.cat((self.popup_scores.abs(), self.popup_scores_extra.abs()), dim=-1), self.k\n",
        "            )[:, : self.weight.shape[-1]]\n",
        "            bias_adj = GetSubnet.apply(\n",
        "                torch.cat((self.bias_popup_scores.abs(), self.bias_popup_scores_extra.abs()), dim=-1), self.k\n",
        "            )[: self.bias.shape[-1]]\n",
        "\n",
        "            w = self.weight * adj\n",
        "            b = self.bias * bias_adj\n",
        "            return F.linear(x, w, b)\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, layer_sizes, routers=None, k=0.5, init=signed_kaiming_constant_):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        if routers is not None:\n",
        "          for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "              self.layers.append(LinearSubnet(in_f, out_f, routers[i], k=k, init=init))\n",
        "              if i < len(layer_sizes) - 1:\n",
        "                  self.layers.append(nn.ReLU())\n",
        "        else:\n",
        "          for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "            self.layers.append(LinearSubnet(in_f, out_f, k=k, init=init))\n",
        "            if i < len(layer_sizes) - 1:\n",
        "                self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, LinearSubnet):\n",
        "                x = layer(x, context)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fLzKWf9UnwFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def testlosses(model, test_data, test_func, context=None):\n",
        "  # define loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  model.eval()\n",
        "  outputs = model(test_data, context.expand(test_data.shape[0], -1)) if context is not None else model(test_data)\n",
        "  targets = test_func(test_data)\n",
        "  loss = criterion(outputs, targets)\n",
        "  return loss.item()\n",
        "def trainloop(model,\n",
        "          optimizer,\n",
        "          test_data,\n",
        "          test_func,\n",
        "          NUM_EPOCHS,\n",
        "          return_training_losses=False,\n",
        "          return_test_losses=True,\n",
        "          context=None):\n",
        "  xs=[]\n",
        "  ys=[]\n",
        "  start = time.time()\n",
        "  # define loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  if return_training_losses:\n",
        "      losses = []\n",
        "  model.train()\n",
        "  for i in range(1,NUM_EPOCHS+1):\n",
        "    for _ in range(100):\n",
        "      end = time.time()\n",
        "      length = end - start\n",
        "      if xs==[]:\n",
        "          xs.append(length)\n",
        "          start = time.time()\n",
        "          ys.append(testlosses(model, test_data, test_func, context=context))\n",
        "      elif length-xs[-1] > 1:\n",
        "        xs.append(xs[-1]+length)\n",
        "        start = time.time()\n",
        "        ys.append(testlosses(model, test_data, test_func, context=context))\n",
        "      inputs=torch.rand(16,1)\n",
        "      inputs.requires_grad_(True)\n",
        "      # forward + backward + optimize\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs, context.expand(inputs.shape[0], -1)) if context is not None else model(inputs)\n",
        "      targets = test_func(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      if return_training_losses:\n",
        "          losses.append(loss.item())\n",
        "  if return_training_losses:\n",
        "    return losses\n",
        "  if return_test_losses:\n",
        "    return xs,ys\n",
        "\n",
        "def get_poly(coeffs):\n",
        "  def poly(x):\n",
        "    result = torch.zeros_like(x)\n",
        "    for i, a in enumerate(coeffs):\n",
        "        result += a * x**i\n",
        "    return result\n",
        "  return poly\n",
        "\n",
        "num_polys_to_test = 100\n",
        "\n",
        "plots={'Classical':{k:{} for k in range(num_polys_to_test)},'Masking':{k:{} for k in range(num_polys_to_test)}}\n",
        "context={}\n",
        "test_data={}\n",
        "test_func={}\n",
        "for k in range(num_polys_to_test):\n",
        "  test_data[k]=torch.rand(1000,1)\n",
        "  coeffs = torch.rand(torch.randint(low=1, high=5, size=(1,)).item(),1)\n",
        "  test_func[k] = get_poly(coeffs)\n",
        "\n",
        "  context_dat = torch.rand(10,1)\n",
        "  context[k] = torch.cat((context_dat, test_func[k](context_dat)), dim=0).view(1, -1)\n",
        "\n",
        "n_low=5\n",
        "n_high=5\n",
        "d_low=1\n",
        "d_high=1\n",
        "\n",
        "n_low_masking=5\n",
        "n_high_masking=5\n",
        "d_low_masking=1\n",
        "d_high_masking=1\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "print('=================')\n",
        "print('No Masking Test')\n",
        "print('=================')\n",
        "for n in range(n_low,n_high+1):\n",
        "  for d in range(d_low,d_high+1):\n",
        "    w=2**n\n",
        "    layer_sizes=[[1, w]]\n",
        "    for _ in range(d):\n",
        "      layer_sizes.append([w,w])\n",
        "    layer_sizes.append([w,1])\n",
        "    classic_model = ClassicNetwork(layer_sizes)\n",
        "    for k in range(num_polys_to_test):\n",
        "      print('  Round '+str(k))\n",
        "      optimizer = optim.Adam(classic_model.parameters())\n",
        "      print(f\"    Width: {w} (2**{n}), Depth: {d}\")\n",
        "      print('    =================')\n",
        "      xs,ys = trainloop(classic_model, optimizer, test_data[k], test_func[k], NUM_EPOCHS, return_training_losses=False, return_test_losses=True)\n",
        "      plots['Classical'][k][(w,d)]=(xs,ys)\n",
        "print('=================')\n",
        "print('Masking Tests')\n",
        "print('=================')\n",
        "for n in range(n_low_masking,n_high_masking+1):\n",
        "  for d in range(d_low_masking,d_high_masking+1):\n",
        "    w=2**n\n",
        "    layer_sizes=[[1, w]]\n",
        "    for _ in range(d):\n",
        "      layer_sizes.append([w,w])\n",
        "    layer_sizes.append([w,1])\n",
        "    context_size=20\n",
        "    routers = [\n",
        "        ClassicNetwork(layer_sizes=[\n",
        "            [context_size, 32],\n",
        "            [32, 32],\n",
        "            [32, l[1] * l[0] + l[1]]]\n",
        "        ) for l in layer_sizes\n",
        "    ]\n",
        "    model = Network(layer_sizes, routers=routers, k=0.5)\n",
        "    for k in range(num_polys_to_test):\n",
        "      print('  Round '+str(k))\n",
        "      optimizer = optim.Adam(model.parameters())\n",
        "      print(f\"    Width: {w} (2**{n}), Depth: {d}\")\n",
        "      print('    =================')\n",
        "      xs,ys = trainloop(model, optimizer, test_data[k], test_func[k], NUM_EPOCHS, return_training_losses=False, return_test_losses=True, context=context[k])\n",
        "      plots['Masking'][k][(w,d)]=(xs,ys)"
      ],
      "metadata": {
        "id": "6Izn_ztEnzkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "223f7549-b6a1-42fa-ccd1-aa5afce4f0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================\n",
            "No Masking Test\n",
            "=================\n",
            "  Round 0\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 1\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 2\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 3\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 4\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 5\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 6\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 7\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 8\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 9\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 10\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 11\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 12\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 13\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 14\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 15\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 16\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 17\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 18\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 19\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 20\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 21\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 22\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 23\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 24\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 25\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 26\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 27\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 28\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 29\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 30\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 31\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 32\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 33\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 34\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 35\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 36\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 37\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 38\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 39\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 40\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 41\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 42\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 43\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 44\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 45\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 46\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 47\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 48\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 49\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 50\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 51\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 52\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 53\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 54\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 55\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 56\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 57\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 58\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 59\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 60\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 61\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 62\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 63\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 64\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 65\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 66\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 67\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 68\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 69\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 70\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 71\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 72\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 73\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 74\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 75\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 76\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 77\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 78\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 79\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 80\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 81\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 82\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 83\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 84\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 85\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 86\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 87\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 88\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 89\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 90\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 91\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 92\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 93\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 94\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 95\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 96\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 97\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 98\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "  Round 99\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n",
            "=================\n",
            "Masking Tests\n",
            "=================\n",
            "  Round 0\n",
            "    Width: 32 (2**5), Depth: 1\n",
            "    =================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[1000, 64]' is invalid for input of size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2305668897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"    Width: {w} (2**{n}), Depth: {d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    ================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m       \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_training_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_test_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0mplots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Masking'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2305668897.py\u001b[0m in \u001b[0;36mtrainloop\u001b[0;34m(model, optimizer, test_data, test_func, NUM_EPOCHS, return_training_losses, return_test_losses, context)\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestlosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2305668897.py\u001b[0m in \u001b[0;36mtestlosses\u001b[0;34m(model, test_data, test_func, context)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3594201821.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearSubnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3594201821.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# reshape and abs just like unrouted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mw_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_scores_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0min_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, out, 2*in]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_scores_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# [B, 2*out]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# top-k over doubled scores, then slice first half\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1000, 64]' is invalid for input of size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for run_type in plots.keys():\n",
        "    for (w,d) in plots[run_type][0].keys():\n",
        "      daty=[plots[run_type][k][(w,d)][-1][-1] for k in sorted(plots[run_type].keys())]\n",
        "      if run_type=='Classical':\n",
        "        line='-'\n",
        "      else:\n",
        "        line='--'\n",
        "      plt.plot([k for k in sorted(plots[run_type].keys())],daty, label=run_type+' (Width: '+str(w)+', Depth: '+str(d)+')', linestyle=line)\n",
        "\n",
        "# Plot the test loss for the model\n",
        "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "plt.xscale('log')\n",
        "# plt.yscale('log')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Test Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6NOMxEHwn3zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, an \"explicit\" router that is trained separately from the rest of the network.  We build a dataset of masks and teach it to guess outputs that the decode head of an autoencoder turns into scores."
      ],
      "metadata": {
        "id": "jlzI4l4Bn_nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskAE(nn.Module):\n",
        "    \"\"\"Small MLP autoencoder for flattened doubled masks of length D.\"\"\"\n",
        "    def __init__(self, D, embed_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(D, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), embed_dim),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, max(128, embed_dim*2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(max(128, embed_dim*2), D)   # raw logits for masks\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        y = self.decoder(z)\n",
        "        return y\n",
        "\n",
        "    def encode(self, x):  # x: [B, D]\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):  # z: [B, E]\n",
        "        return self.decoder(z)\n",
        "\n",
        "class MasksOnlyDataset(Dataset):\n",
        "    def __init__(self, targets):  # targets: [N, D] of {0,1}\n",
        "        self.targets = targets\n",
        "    def __len__(self): return self.targets.size(0)\n",
        "    def __getitem__(self, i):\n",
        "        t = self.targets[i]\n",
        "        return t, t  # (input=mask, target=mask)\n",
        "\n",
        "def train_autoencoder_on_masks(targets,\n",
        "                               D,            # flattened doubled length = out_f*(2*in_f) + 2*out_f\n",
        "                               in_f, out_f,  # layer shape\n",
        "                               k,            # keep ratio used by GetSubnet\n",
        "                               embed_dim=64,\n",
        "                               epochs=20,\n",
        "                               batch=256,\n",
        "                               lr=1e-3,\n",
        "                               device='cpu',\n",
        "                               aux_logit_loss_weight=0.0):\n",
        "    \"\"\"\n",
        "    targets: [N, D] binary doubled masks (weight: [out, 2*in], bias: [2*out], flattened)\n",
        "    Trains AE so that decoder(pred_z) -> logits -> GetSubnet(k) matches targets.\n",
        "    Optionally adds a tiny auxiliary loss on logits (post-sigmoid) for stability.\n",
        "    \"\"\"\n",
        "    ds = MasksOnlyDataset(targets)  # (mask, mask)\n",
        "    loader = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "    ae = MaskAE(D, embed_dim).to(device)\n",
        "    opt = torch.optim.Adam(ae.parameters(), lr=lr)\n",
        "\n",
        "    D_w = out_f * (2 * in_f)\n",
        "    D_b = 2 * out_f\n",
        "\n",
        "    ae.train()\n",
        "    for _ in range(epochs):\n",
        "        for m_in, m_tgt in loader:\n",
        "            m_in, m_tgt = m_in.to(device), m_tgt.to(device)  # [B, D], {0,1}\n",
        "\n",
        "            logits = ae(m_in)  # [B, D]\n",
        "\n",
        "            # Split & reshape to doubled shapes, mirror router path\n",
        "            w_logits = logits[:, :D_w].reshape(-1, out_f, 2*in_f).abs()\n",
        "            b_logits = logits[:, D_w:].reshape(-1, 2*out_f).abs()\n",
        "\n",
        "            # STE top-k to binarize\n",
        "            w_mask_hat = GetSubnet.apply(w_logits, k)    # [B, out, 2*in] in {0,1}\n",
        "            b_mask_hat = GetSubnet.apply(b_logits, k)    # [B, 2*out]   in {0,1}\n",
        "\n",
        "            pred_mask = torch.cat([w_mask_hat.reshape(logits.size(0), -1),\n",
        "                                   b_mask_hat.reshape(logits.size(0), -1)], dim=1)  # [B, D]\n",
        "\n",
        "            # Primary loss: match binary masks after GetSubnet\n",
        "            loss = F.mse_loss(pred_mask, m_tgt)\n",
        "\n",
        "            # Optional tiny auxiliary term (can help stabilize training a bit)\n",
        "            if aux_logit_loss_weight > 0.0:\n",
        "                loss = loss + aux_logit_loss_weight * F.mse_loss(torch.sigmoid(logits), m_tgt)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    # freeze decoder head\n",
        "    for p in ae.decoder.parameters():\n",
        "        p.requires_grad = False\n",
        "    ae.eval()\n",
        "    return ae, ae.decoder\n",
        "\n",
        "def train_autoencoders_for_all_layers(datasets_per_layer,\n",
        "                                      layer_sizes,\n",
        "                                      embed_dims,\n",
        "                                      k=0.5,\n",
        "                                      epochs=20,\n",
        "                                      batch=256,\n",
        "                                      lr=1e-3,\n",
        "                                      device='cpu',\n",
        "                                      aux_logit_loss_weight=0.0):\n",
        "    \"\"\"\n",
        "    Returns: (decoders_frozen, full_AEs)\n",
        "    Each dataset[i].targets is [N, D_i] with doubled masks.\n",
        "    \"\"\"\n",
        "    if isinstance(embed_dims, int):\n",
        "        embed_dims = [embed_dims] * len(layer_sizes)\n",
        "\n",
        "    decoders, aes = [], []\n",
        "    for (in_f, out_f), ds, E in zip(layer_sizes, datasets_per_layer, embed_dims):\n",
        "        D = out_f * (2 * in_f) + 2 * out_f\n",
        "        all_masks = ds.targets.to(device)  # [N, D], {0,1}\n",
        "\n",
        "        ae, decoder = train_autoencoder_on_masks(\n",
        "            targets=all_masks,\n",
        "            D=D,\n",
        "            in_f=in_f,\n",
        "            out_f=out_f,\n",
        "            k=k,\n",
        "            embed_dim=E,\n",
        "            epochs=epochs,\n",
        "            batch=batch,\n",
        "            lr=lr,\n",
        "            device=device,\n",
        "            aux_logit_loss_weight=aux_logit_loss_weight\n",
        "        )\n",
        "        decoders.append(decoder)  # frozen\n",
        "        aes.append(ae)\n",
        "\n",
        "    return decoders, aes"
      ],
      "metadata": {
        "id": "ABNT9MgTn8Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, expect_context=False, context_dim=0):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        if expect_context:\n",
        "            # add context_dim to first layer's input width\n",
        "            in0, out0 = layer_sizes[0]\n",
        "            layer_sizes = [[in0 + context_dim, out0]] + layer_sizes[1:]\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            *[z for l in layer_sizes\n",
        "              for z in [nn.Linear(l[0], l[1]), nn.ReLU()]][:-1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        x = self.flatten(x)\n",
        "        if context is not None:\n",
        "            # broadcast [1, C] or accept [N, C]\n",
        "            if context.dim() == 2 and context.size(0) == 1:\n",
        "                context = context.expand(x.size(0), -1)\n",
        "            elif context.size(0) != x.size(0):\n",
        "                raise ValueError(f\"context batch {context.size(0)} must be 1 or match x batch {x.size(0)}\")\n",
        "            x = torch.cat([x, context], dim=1)\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "# Set up signed Kaiming initialization.\n",
        "def signed_kaiming_constant_(tensor, a=0, mode='fan_in', nonlinearity='relu', k=0.5, sparsity=0):\n",
        "\n",
        "    fan = nn.init._calculate_correct_fan(tensor, mode)  # calculating correct fan, depends on shape and type of nn\n",
        "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
        "    std = (gain / math.sqrt(fan))\n",
        "    # scale by (1/sqrt(k))\n",
        "    if k != 0:\n",
        "        std *= (1 / math.sqrt(k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tensor.uniform_(-std, std)\n",
        "        if sparsity > 0:\n",
        "            mask = (torch.rand_like(tensor) > sparsity).float()  # Keeps (1 - sparsity)% weights\n",
        "\n",
        "            tensor *= mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "# A function to retreive a subset of the top k% of the weights by their score.\n",
        "# The gradient is estimated by the identity (i.e. it goes \"straight-through\").\n",
        "# See the paper \"What's Hidden in a Randomly Weighted Neural Network?\" for\n",
        "# more details (https://arxiv.org/abs/1911.13299)\n",
        "# (this code adapted from https://github.com/iceychris/edge-popup)\n",
        "\n",
        "class GetSubnet(autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, scores, k):\n",
        "        # scores: shape (..., N) or (..., out, in). We operate over the last dimension(s) flattened per-sample\n",
        "        orig_shape = scores.shape\n",
        "        B = scores.shape[0] if scores.dim() > 1 else 1\n",
        "        per_sample_numel = int(scores[0].numel()) if B > 1 else scores.numel()\n",
        "\n",
        "        # Flatten each sample to 1-D, run top-k mask per sample\n",
        "        s = scores.reshape(B, -1).clone()\n",
        "        out = s.clone()\n",
        "        # sort ascending per row\n",
        "        idx = torch.argsort(s, dim=-1)             # [B, M]\n",
        "        j = int((1 - k) * s.shape[-1])             # number to zero per sample\n",
        "        flat_out = out\n",
        "\n",
        "        # zero the smallest (1-k)% per sample\n",
        "        rows = torch.arange(B, device=scores.device).unsqueeze(-1)\n",
        "        flat_out[rows, idx[:, :j]] = 0\n",
        "        flat_out[rows, idx[:, j:]] = 1\n",
        "\n",
        "        return flat_out.reshape(orig_shape)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad):\n",
        "        # straight-through estimator\n",
        "        return grad, None\n",
        "\n",
        "\n",
        "class LinearSubnet(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, router=None, decoder=None,\n",
        "                 bias=True, k=0.5, init=signed_kaiming_constant_, **kwargs):\n",
        "        super().__init__(in_features, out_features, bias if isinstance(bias, bool) else True, **kwargs)\n",
        "        self.k = float(k)\n",
        "        self.router = router\n",
        "        self.decoder = decoder  # frozen module mapping embedding -> mask logits\n",
        "\n",
        "        if router is None:\n",
        "            # unrouted: keep double-score params\n",
        "            self.popup_scores = nn.Parameter(torch.randn(*self.weight.shape))\n",
        "            self.popup_scores_extra = nn.Parameter(torch.randn(*self.weight.shape))\n",
        "            self.bias_popup_scores = nn.Parameter(torch.randn(*self.bias.shape))\n",
        "            self.bias_popup_scores_extra = nn.Parameter(torch.randn(*self.bias.shape))\n",
        "\n",
        "        if init == signed_kaiming_constant_:\n",
        "            init(self.weight, k=self.k)\n",
        "        else:\n",
        "            init(self.weight)\n",
        "        self.weight.requires_grad_(False)\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad_(False)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        if self.router is not None:\n",
        "            B = x.shape[0]\n",
        "            out_f, in_f = self.out_features, self.in_features\n",
        "            D_w = out_f*(2*in_f)\n",
        "\n",
        "            z = self.router(context)           # [B, E]\n",
        "            logits = self.decoder(z)           # [B, D_w + 2*out_f]\n",
        "\n",
        "            w_logits = logits[:, :D_w].reshape(B, out_f, 2*in_f).abs()\n",
        "            b_logits = logits[:, D_w:].reshape(B, 2*out_f).abs()\n",
        "\n",
        "            w_mask_2x = GetSubnet.apply(w_logits, self.k)\n",
        "            b_mask_2x = GetSubnet.apply(b_logits, self.k)\n",
        "\n",
        "            w_mask = w_mask_2x[:, :, :in_f]   # slice like unrouted trick\n",
        "            b_mask = b_mask_2x[:, :out_f]\n",
        "\n",
        "            W_eff = self.weight.unsqueeze(0) * w_mask\n",
        "            b_eff = self.bias.unsqueeze(0) * b_mask\n",
        "            y = torch.bmm(W_eff, x.unsqueeze(-1)).squeeze(-1) + b_eff\n",
        "            return y\n",
        "\n",
        "        # unrouted branch (unchanged)\n",
        "        adj = GetSubnet.apply(\n",
        "            torch.cat((self.popup_scores.abs(), self.popup_scores_extra.abs()), dim=-1), self.k\n",
        "        )[:, : self.weight.shape[-1]]\n",
        "        bias_adj = GetSubnet.apply(\n",
        "            torch.cat((self.bias_popup_scores.abs(), self.bias_popup_scores_extra.abs()), dim=-1), self.k\n",
        "        )[: self.bias.shape[-1]]\n",
        "        return F.linear(x, self.weight * adj, self.bias * bias_adj)\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, layer_sizes, routers=None, k=0.5, init=signed_kaiming_constant_):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        if routers is not None:\n",
        "          for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "              self.layers.append(LinearSubnet(in_f, out_f, routers[i], k=k, init=init))\n",
        "              if i < len(layer_sizes) - 1:\n",
        "                  self.layers.append(nn.ReLU())\n",
        "        else:\n",
        "          for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "            self.layers.append(LinearSubnet(in_f, out_f, k=k, init=init))\n",
        "            if i < len(layer_sizes) - 1:\n",
        "                self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        x = self.flatten(x)\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, LinearSubnet):\n",
        "                x = layer(x, context)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FAady_R_oLcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _flatten_X(X: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Flatten any X to [N, in_dim].\"\"\"\n",
        "    if X.dim() == 2:\n",
        "        return X\n",
        "    return X.reshape(X.size(0), -1)\n",
        "\n",
        "def _process_Y_to_2d(Y: torch.Tensor, num_classes: int | None = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Make Y shape [N, out_dim] in float:\n",
        "      - If long/int and 1D: one-hot to [N, num_classes]\n",
        "      - Else: flatten to [N, -1] and cast float\n",
        "    \"\"\"\n",
        "    if Y.dtype in (torch.int8, torch.int16, torch.int32, torch.int64) and Y.dim() == 1:\n",
        "        if num_classes is None:\n",
        "            num_classes = int(Y.max().item()) + 1\n",
        "        oh = torch.zeros(Y.size(0), num_classes, dtype=torch.float32, device=Y.device)\n",
        "        oh.scatter_(1, Y.view(-1, 1), 1.0)\n",
        "        return oh\n",
        "    # regression or already vector: flatten to 2D and cast\n",
        "    if Y.dim() == 1:\n",
        "        Y = Y.unsqueeze(1)\n",
        "    elif Y.dim() > 2:\n",
        "        Y = Y.reshape(Y.size(0), -1)\n",
        "    return Y.to(torch.float32)\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_contexts_from_function(\n",
        "    test_func,\n",
        "    num_contexts: int = 100,\n",
        "    points_per_context: int = 10,\n",
        "    in_dim: int = 1,          # <- NEW: input dimensionality\n",
        "    device: str = \"cpu\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Build a [num_contexts, points_per_context*(in_dim + out_dim)] context tensor by:\n",
        "      1) sampling X ~ U(0,1) with shape [num_contexts, points, in_dim]\n",
        "      2) Y = test_func(X_flat).view(num_contexts, points, out_dim)\n",
        "      3) per-row context = concat([X, Y], dim=-1) then flatten to [num_contexts, C]\n",
        "    Works for arbitrary in_dim and whatever out_dim test_func returns.\n",
        "    \"\"\"\n",
        "    # [N, P, in_dim]\n",
        "    X = torch.rand(num_contexts, points_per_context, in_dim, device=device)\n",
        "\n",
        "    # flatten to [N*P, in_dim] → run func → [N*P, out_dim]\n",
        "    X_flat = X.reshape(-1, in_dim)\n",
        "    Y_flat = test_func(X_flat)                       # [N*P, out_dim]\n",
        "    out_dim = Y_flat.shape[-1]\n",
        "    Y = Y_flat.reshape(num_contexts, points_per_context, out_dim)\n",
        "\n",
        "    # [N, P, in_dim+out_dim] → [N, P*(in_dim+out_dim)]\n",
        "    ctx = torch.cat([X, Y], dim=-1).reshape(num_contexts, -1)\n",
        "    return ctx  # [num_contexts, points*(in_dim+out_dim)]\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_contexts_from_training(\n",
        "    X_train: torch.Tensor,\n",
        "    Y_train: torch.Tensor,\n",
        "    num_contexts: int = 100,\n",
        "    points_per_context: int = 10,\n",
        "    device: str = \"cpu\",\n",
        "    replace: bool = True,\n",
        "    num_classes: int | None = None,   # <- NEW\n",
        "):\n",
        "    \"\"\"\n",
        "    Build contexts from training data, shape-agnostic.\n",
        "    X_train: [N, ...]  (images OK)\n",
        "    Y_train: [N] (class ids) or [N, ...] (regression/one-hot/etc.)\n",
        "\n",
        "    Returns: [num_contexts, points*(in_dim + out_dim)]\n",
        "    \"\"\"\n",
        "    # Flatten/normalize on CPU for memory friendliness\n",
        "    Xf = _flatten_X(X_train.detach().to(\"cpu\"))\n",
        "    Yf = _process_Y_to_2d(Y_train.detach().to(\"cpu\"), num_classes=num_classes)\n",
        "\n",
        "    N = Xf.size(0)\n",
        "    in_dim  = Xf.size(1)\n",
        "    out_dim = Yf.size(1)\n",
        "\n",
        "    if replace:\n",
        "        idx = torch.randint(low=0, high=N, size=(num_contexts, points_per_context))\n",
        "    else:\n",
        "        if points_per_context > N:\n",
        "            raise ValueError(\"points_per_context cannot exceed dataset size when replace=False\")\n",
        "        idx = torch.stack([torch.randperm(N)[:points_per_context] for _ in range(num_contexts)], dim=0)\n",
        "\n",
        "    Xs = Xf[idx]  # [num_contexts, points, in_dim]\n",
        "    Ys = Yf[idx]  # [num_contexts, points, out_dim]\n",
        "\n",
        "    ctx = torch.cat([Xs, Ys], dim=-1).reshape(num_contexts, -1)  # [num_contexts, points*(in_dim+out_dim)]\n",
        "    return ctx.to(device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_single_context_from_training(\n",
        "    X_train: torch.Tensor,\n",
        "    Y_train: torch.Tensor,\n",
        "    points_per_context: int = 10,\n",
        "    device: str = \"cpu\",\n",
        "    replace: bool = True,\n",
        "    num_classes: int | None = None,   # <- NEW\n",
        "):\n",
        "    return build_contexts_from_training(\n",
        "        X_train, Y_train,\n",
        "        num_contexts=1,\n",
        "        points_per_context=points_per_context,\n",
        "        device=device,\n",
        "        replace=replace,\n",
        "        num_classes=num_classes,\n",
        "    )\n",
        "\n",
        "# ---- Utilities to flatten/unflatten layer masks (shape-agnostic) ----\n",
        "def flatten_layer_masks(w_mask: torch.Tensor, b_mask: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Accepts:\n",
        "      w_mask: [..., out, in]   (or doubled [..., out, 2*in] — caller decides)\n",
        "      b_mask: [..., out]       (or doubled [..., 2*out])\n",
        "    Returns flattened 1D vector of both, concatenated along last dim.\n",
        "    \"\"\"\n",
        "    return torch.cat([w_mask.reshape(-1), b_mask.reshape(-1)], dim=0)\n",
        "\n",
        "\n",
        "def layer_output_size(in_f: int, out_f: int, doubled: bool = False) -> int:\n",
        "    \"\"\"\n",
        "    Returns flattened mask size for a layer, respecting doubled scheme if requested.\n",
        "    \"\"\"\n",
        "    if doubled:\n",
        "        return out_f * (2 * in_f) + 2 * out_f\n",
        "    else:\n",
        "        return out_f * in_f + out_f\n",
        "\n",
        "# ---- Extract masks from scores-only model (no grad), agnostic to sizes ----\n",
        "@torch.no_grad()\n",
        "def extract_masks_from_scores_model(model, k: float, doubled: bool = True):\n",
        "    \"\"\"\n",
        "    Returns list of flattened target vectors per LinearSubnet layer.\n",
        "    If doubled=True, we concatenate popup_scores and *_extra along 'in' (and bias),\n",
        "    matching the doubled scheme used by your router/decoder.\n",
        "    \"\"\"\n",
        "    targets_per_layer = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LinearSubnet) and layer.router is None:\n",
        "            if doubled:\n",
        "                adj = torch.cat((layer.popup_scores.abs(),\n",
        "                                 layer.popup_scores_extra.abs()), dim=-1).detach()\n",
        "                bias_adj = torch.cat((layer.bias_popup_scores.abs(),\n",
        "                                      layer.bias_popup_scores_extra.abs()), dim=-1).detach()\n",
        "            else:\n",
        "                adj = layer.popup_scores.abs().detach()\n",
        "                bias_adj = layer.bias_popup_scores.abs().detach()\n",
        "\n",
        "            targets_per_layer.append(flatten_layer_masks(adj, bias_adj))\n",
        "    return targets_per_layer  # list of 1D tensors\n",
        "\n",
        "class RouterLayerDataset(Dataset):\n",
        "    \"\"\"Holds (context -> target_mask_flat) pairs for ONE layer.\"\"\"\n",
        "    def __init__(self, contexts: torch.Tensor, targets: torch.Tensor):  # [N, C], [N, D]\n",
        "        self.contexts = contexts\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.contexts.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.contexts[idx], self.targets[idx]\n",
        "\n",
        "\n",
        "def build_router_for_layer(context_size, embed_dim, hidden=32):\n",
        "    return ClassicNetwork(layer_sizes=[\n",
        "        [context_size, hidden],\n",
        "        [hidden, hidden],\n",
        "        [hidden, embed_dim],\n",
        "    ])\n",
        "\n",
        "def train_router_with_decoder(router, decoder, dataset, in_f, out_f, k, epochs=10, batch_size=64, lr=1e-3, device='cpu'):\n",
        "    \"\"\"\n",
        "    router(ctx) -> z  (embedding)\n",
        "    decoder(z)  -> mask logits of length D = out_f*(2*in_f) + 2*out_f\n",
        "    STE top-k -> binary masks; loss vs target binary masks (dataset.targets).\n",
        "    \"\"\"\n",
        "    router.to(device)\n",
        "    decoder.to(device)\n",
        "    for p in decoder.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    opt = torch.optim.Adam(router.parameters(), lr=lr)\n",
        "\n",
        "    D_w = out_f * (2 * in_f)\n",
        "    D_b = 2 * out_f\n",
        "\n",
        "    router.train()\n",
        "    for _ in range(epochs):\n",
        "        for ctx, tgt in loader:\n",
        "            ctx = ctx.to(device)\n",
        "            tgt = tgt.to(device)  # [B, D] in {0,1}\n",
        "\n",
        "            z = router(ctx)           # [B, E]\n",
        "            logits = decoder(z)       # [B, D]\n",
        "\n",
        "            w_logits = logits[:, :D_w].reshape(-1, out_f, 2 * in_f).abs()\n",
        "            b_logits = logits[:, D_w:].reshape(-1, 2 * out_f).abs()\n",
        "\n",
        "            w_mask_hat = GetSubnet.apply(w_logits, k)  # [B, out, 2*in]\n",
        "            b_mask_hat = GetSubnet.apply(b_logits, k)  # [B, 2*out]\n",
        "\n",
        "            pred = torch.cat([w_mask_hat.reshape(logits.size(0), -1),\n",
        "                              b_mask_hat.reshape(logits.size(0), -1)], dim=1)  # [B, D]\n",
        "\n",
        "            # BCE on {0,1} masks (pred is {0,1} due to STE; BCE or MSE both fine)\n",
        "            loss = F.binary_cross_entropy(pred, tgt)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    return router\n",
        "\n",
        "def fit_scores_and_collect_targets(layer_sizes,\n",
        "                                   base_snaps,\n",
        "                                   k,\n",
        "                                   x_train,          # tensor [N, in_dim]\n",
        "                                   f_train,          # callable: x -> y\n",
        "                                   epochs_scores=5,\n",
        "                                   batch_size=128,\n",
        "                                   device='cpu'):\n",
        "    # Build scores-only model and APPLY the shared base weights\n",
        "    scores_model = Network(layer_sizes, routers=None, k=k).to(device)\n",
        "    apply_base_weights(scores_model, base_snaps)\n",
        "\n",
        "    # Optimizer: only score params (weights are frozen in LinearSubnet)\n",
        "    params = []\n",
        "    for lyr in scores_model.layers:\n",
        "        if isinstance(lyr, LinearSubnet) and lyr.router is None:\n",
        "            params.extend([lyr.popup_scores, lyr.popup_scores_extra,\n",
        "                           lyr.bias_popup_scores, lyr.bias_popup_scores_extra])\n",
        "    opt = torch.optim.Adam(params)\n",
        "\n",
        "    # Prepare (x, y) tensors\n",
        "    x_train = x_train.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_train = f_train(x_train)  # same device as x\n",
        "\n",
        "    # Train scores on this task using the new trainloop signature\n",
        "    _ = trainloop(scores_model, opt,\n",
        "                  x_train=x_train,\n",
        "                  y_train=y_train,\n",
        "                  NUM_EPOCHS=epochs_scores,\n",
        "                  batch_size=batch_size,\n",
        "                  x_val=None, y_val=None,\n",
        "                  return_training_losses=False,\n",
        "                  return_val_curve=False,\n",
        "                  context=None,   # scores model ignores context\n",
        "                  shuffle=True)\n",
        "\n",
        "    # Extract binary *doubled* masks as supervision targets (unchanged)\n",
        "    targets_per_layer = extract_masks_from_scores_model(scores_model, k)\n",
        "\n",
        "    # (Optional) re-randomize score params so each task starts fresh\n",
        "    for lyr in scores_model.layers:\n",
        "        if isinstance(lyr, LinearSubnet) and lyr.router is None:\n",
        "            dev = next(scores_model.parameters()).device\n",
        "            lyr.popup_scores         = nn.Parameter(torch.randn(*lyr.weight.shape, device=dev))\n",
        "            lyr.popup_scores_extra   = nn.Parameter(torch.randn(*lyr.weight.shape, device=dev))\n",
        "            lyr.bias_popup_scores    = nn.Parameter(torch.randn(*lyr.bias.shape,   device=dev))\n",
        "            lyr.bias_popup_scores_extra = nn.Parameter(torch.randn(*lyr.bias.shape, device=dev))\n",
        "\n",
        "    return targets_per_layer\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_contexts_from_loader_with_model(\n",
        "    dataloader,\n",
        "    model,                      # scores-only model with masks installed\n",
        "    num_contexts: int,\n",
        "    points_per_context: int,\n",
        "    in_dim: int,\n",
        "    device: str = \"cpu\",\n",
        "    forward_bs: int = 4096,     # chunked forward to avoid OOM\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Use ONLY the dataloader's INPUTS as the x-source for contexts.\n",
        "    Targets from the loader are IGNORED.\n",
        "    We compute y = model(x) to complete the context rows [x;y] per point.\n",
        "    Returns: [num_contexts, points_per_context*(in_dim + out_dim)] on `device`.\n",
        "    \"\"\"\n",
        "    needed = num_contexts * points_per_context\n",
        "\n",
        "    # 1) Gather enough inputs from the loader (on CPU for memory friendliness)\n",
        "    X_pool = []\n",
        "    tot = 0\n",
        "    for xb, *_rest in dataloader:\n",
        "        X_pool.append(xb.detach().cpu())\n",
        "        tot += xb.size(0)\n",
        "        if tot >= needed:\n",
        "            break\n",
        "    if not X_pool:\n",
        "        raise RuntimeError(\"DataLoader yielded no batches; cannot build contexts.\")\n",
        "    X_pool = torch.cat(X_pool, dim=0)        # [M, ...]\n",
        "    X_pool = _flatten_X(X_pool)              # [M, in_dim]\n",
        "    M = X_pool.size(0)\n",
        "\n",
        "    # 2) Forward through the masked model in chunks to get Y_pool\n",
        "    Y_pool_list = []\n",
        "    for start in range(0, M, forward_bs):\n",
        "        end = min(start + forward_bs, M)\n",
        "        x_chunk = X_pool[start:end].to(device)\n",
        "        y_chunk = model(x_chunk)             # [B, out_dim]\n",
        "        Y_pool_list.append(y_chunk.detach().cpu())\n",
        "    Y_pool = torch.cat(Y_pool_list, dim=0)   # [M, out_dim]\n",
        "\n",
        "    # 3) Sample indices to assemble contexts\n",
        "    idx = torch.randint(low=0, high=M, size=(num_contexts, points_per_context))\n",
        "    Xs = X_pool[idx]                         # [Nctx, P, in_dim]\n",
        "    Ys = Y_pool[idx]                         # [Nctx, P, out_dim]\n",
        "\n",
        "    # 4) Concatenate per point and flatten per context\n",
        "    ctx = torch.cat([Xs, Ys], dim=-1).reshape(num_contexts, -1)   # [Nctx, P*(in_dim+out_dim)]\n",
        "    return ctx.to(device)\n",
        "\n",
        "\n",
        "def prepare_router_datasets(\n",
        "    layer_sizes,\n",
        "    internal_samples,\n",
        "    k=0.5,\n",
        "    device='cpu',\n",
        "    contexts_per_task=100,\n",
        "    points_per_context=10,\n",
        "    batch_size=128,\n",
        "    dataloader=None,               # <- NEW (optional)\n",
        "):\n",
        "    \"\"\"\n",
        "    Build router datasets WITHOUT fitting scores:\n",
        "      - For each task, sample random doubled scores per layer\n",
        "      - Convert to binary doubled masks via GetSubnet(k)\n",
        "      - Install those scores into a frozen scores-only model (so forward uses the sampled masks)\n",
        "      - Generate many contexts either:\n",
        "          * from a provided dataloader's INPUTS (labels unused) + masked-model outputs, or\n",
        "          * from random inputs (fallback) + masked-model outputs\n",
        "      - Targets are the SAME masks for all contexts of that task\n",
        "\n",
        "    Returns:\n",
        "      datasets_per_layer: list[RouterLayerDataset] (contexts, doubled_mask_targets)\n",
        "      base_snaps:         frozen base weights snapshot\n",
        "    \"\"\"\n",
        "    # 0) Shared frozen backbone weights\n",
        "    base_snaps = build_backbone_template(layer_sizes, k=k, device=device)\n",
        "\n",
        "    # 1) Per-layer collectors\n",
        "    per_layer_targets = [[] for _ in layer_sizes]\n",
        "    contexts_all = []\n",
        "\n",
        "    in_dim = layer_sizes[0][0]  # model input width\n",
        "\n",
        "    for _ in range(internal_samples):\n",
        "        # (a) Build a scores-only model with the shared frozen weights\n",
        "        model = Network(layer_sizes, routers=None, k=k).to(device)\n",
        "        apply_base_weights(model, base_snaps)\n",
        "\n",
        "        # (b) For each LinearSubnet: sample RANDOM doubled scores -> masks, then install scores\n",
        "        targets_this_task = []\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, LinearSubnet) and layer.router is None:\n",
        "                out_f, in_f = layer.out_features, layer.in_features\n",
        "\n",
        "                # sample doubled scores\n",
        "                w_scores_2x = torch.randn(out_f, 2 * in_f, device=device)\n",
        "                b_scores_2x = torch.randn(2 * out_f, device=device)\n",
        "\n",
        "                # masks via GetSubnet\n",
        "                with torch.no_grad():\n",
        "                    w_mask_2x = GetSubnet.apply(w_scores_2x.abs(), k)  # [out, 2*in]\n",
        "                    b_mask_2x = GetSubnet.apply(b_scores_2x.abs(), k)  # [2*out]\n",
        "\n",
        "                # record targets (flattened doubled)\n",
        "                targets_this_task.append(flatten_layer_masks(w_mask_2x, b_mask_2x))\n",
        "\n",
        "                # install scores into the layer so forward matches these masks\n",
        "                with torch.no_grad():\n",
        "                    layer.popup_scores        = nn.Parameter(w_scores_2x[:, :in_f].clone())\n",
        "                    layer.popup_scores_extra  = nn.Parameter(w_scores_2x[:,  in_f:].clone())\n",
        "                    layer.bias_popup_scores        = nn.Parameter(b_scores_2x[:out_f].clone())\n",
        "                    layer.bias_popup_scores_extra  = nn.Parameter(b_scores_2x[ out_f:].clone())\n",
        "\n",
        "        # (c) Build contexts for THIS masked model\n",
        "        if dataloader is not None:\n",
        "            # Use real inputs from dataloader (labels unused) and masked model to form [x;y]\n",
        "            ctx_batch = build_contexts_from_loader_with_model(\n",
        "                dataloader=dataloader,\n",
        "                model=model,\n",
        "                num_contexts=contexts_per_task,\n",
        "                points_per_context=points_per_context,\n",
        "                in_dim=in_dim,\n",
        "                device=device,\n",
        "            )  # [contexts_per_task, C]\n",
        "        else:\n",
        "            # Fallback: random inputs fed through masked model\n",
        "            def f_masked(x):\n",
        "                return model(x)\n",
        "            ctx_batch = build_contexts_from_function(\n",
        "                test_func=f_masked,\n",
        "                num_contexts=contexts_per_task,\n",
        "                points_per_context=points_per_context,\n",
        "                in_dim=in_dim,\n",
        "                device=device\n",
        "            )  # [contexts_per_task, C]\n",
        "\n",
        "        contexts_all.append(ctx_batch)\n",
        "\n",
        "        # (d) Repeat per-layer targets to match number of contexts\n",
        "        for i, t in enumerate(targets_this_task):\n",
        "            T_rep = t.detach().clone().unsqueeze(0).repeat(ctx_batch.size(0), 1)  # [contexts_per_task, D_i]\n",
        "            per_layer_targets[i].append(T_rep)\n",
        "\n",
        "    # 2) Stack across tasks\n",
        "    contexts_all = torch.cat(contexts_all, dim=0)  # [N_total, C]\n",
        "    datasets_per_layer = []\n",
        "    for i, (in_f, out_f) in enumerate(layer_sizes):\n",
        "        T = torch.cat(per_layer_targets[i], dim=0).float()  # [N_total, D_i], doubled masks\n",
        "        datasets_per_layer.append(RouterLayerDataset(contexts_all, T))\n",
        "\n",
        "    return datasets_per_layer, base_snaps\n",
        "\n",
        "@torch.no_grad()\n",
        "def snapshot_base_weights(model):\n",
        "    \"\"\"Return a list of (W, b) for each LinearSubnet in order.\"\"\"\n",
        "    snaps = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LinearSubnet):\n",
        "            snaps.append((layer.weight.detach().clone(), layer.bias.detach().clone()))\n",
        "    return snaps\n",
        "\n",
        "@torch.no_grad()\n",
        "def apply_base_weights(model, snaps):\n",
        "    \"\"\"Copy (W, b) into each LinearSubnet, in order, with shape checks.\"\"\"\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LinearSubnet):\n",
        "            W, B = snaps[i]\n",
        "            assert layer.weight.shape == W.shape, f\"Layer {i} weight shape {layer.weight.shape} != snap {W.shape}\"\n",
        "            assert layer.bias.shape == B.shape,   f\"Layer {i} bias   shape {layer.bias.shape} != snap {B.shape}\"\n",
        "            layer.weight.data.copy_(W)\n",
        "            layer.bias.data.copy_(B)\n",
        "            i += 1\n",
        "    assert i == len(snaps), f\"Used {i} snapshots, but have {len(snaps)}\"\n",
        "\n",
        "def build_backbone_template(layer_sizes, k=0.5, device='cpu'):\n",
        "    \"\"\"Routers=None => scores-only LinearSubnet; weights are frozen by your class.\"\"\"\n",
        "    template = Network(layer_sizes, routers=None, k=k)\n",
        "    template.to(device)\n",
        "    base_snaps = snapshot_base_weights(template)   # <- save once\n",
        "    return base_snaps\n",
        "\n",
        "def build_router_inference_model_with_decoders(layer_sizes, routers_trained, decoders, base_snaps, k=0.5, device='cpu'):\n",
        "    \"\"\"\n",
        "    Build the final model keeping layer order identical to the snapshot template:\n",
        "      - construct Network with routers provided (same order as layer_sizes)\n",
        "      - attach corresponding frozen decoders per LinearSubnet\n",
        "      - apply the same frozen base weights snapshot\n",
        "    \"\"\"\n",
        "    # 1) Build with routers to preserve ordering\n",
        "    model = Network(layer_sizes, routers=routers_trained, k=k, init=signed_kaiming_constant_).to(device)\n",
        "\n",
        "    # 2) Attach decoders (freeze) in order to each LinearSubnet\n",
        "    li = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LinearSubnet):\n",
        "            dec = decoders[li].to(device)\n",
        "            for p in dec.parameters():\n",
        "                p.requires_grad = False\n",
        "            layer.decoder = dec\n",
        "            li += 1\n",
        "    assert li == len(decoders), f\"Attached {li} decoders, expected {len(decoders)}\"\n",
        "\n",
        "    # 3) Apply same frozen backbone weights\n",
        "    apply_base_weights(model, base_snaps)\n",
        "    return model"
      ],
      "metadata": {
        "id": "14-khfBOoPl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def testlosses(model,\n",
        "               x, y,\n",
        "               context=None,\n",
        "               context_from_training: tuple | None = None,\n",
        "               points_per_context: int = 10,\n",
        "               replace: bool = True):\n",
        "    \"\"\"\n",
        "    Evaluate MSE on (x, y), with optional ON-THE-FLY context built from training data.\n",
        "\n",
        "    Args:\n",
        "      x: [N, in_dim]\n",
        "      y: [N, out_dim]\n",
        "      context: optional explicit context:\n",
        "          - [1, C]  -> broadcast to batch\n",
        "          - [N, C]  -> per-sample\n",
        "      context_from_training: optional tuple (X_train, Y_train).\n",
        "          If provided AND 'context' is None, we build a [1, C] context row by sampling\n",
        "          'points_per_context' rows from (X_train, Y_train), concatenating [x;y] per point,\n",
        "          then flattening. This is agnostic to in/out dims.\n",
        "      points_per_context: number of (x,y) pairs to include in the constructed context\n",
        "      replace: sample with replacement from training data when building the context\n",
        "    \"\"\"\n",
        "    device = model_device(model)\n",
        "    criterion = nn.MSELoss()\n",
        "    model.eval()\n",
        "\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Build context on the fly from training data if requested\n",
        "    if context is None and context_from_training is not None:\n",
        "        Xtr, Ytr = context_from_training\n",
        "        context = build_single_context_from_training(\n",
        "            Xtr, Ytr,\n",
        "            points_per_context=points_per_context,\n",
        "            device=device,\n",
        "            replace=replace\n",
        "        )  # [1, C] on device\n",
        "\n",
        "    if context is not None:\n",
        "        ctx = context.to(device)\n",
        "        if ctx.dim() == 2 and ctx.size(0) == 1:\n",
        "            ctx = ctx.expand(x.size(0), -1)\n",
        "        elif ctx.size(0) != x.size(0):\n",
        "            raise ValueError(f\"context batch {ctx.size(0)} must be 1 or match x batch {x.size(0)}\")\n",
        "        outputs = model(x, ctx)\n",
        "    else:\n",
        "        outputs = model(x)\n",
        "\n",
        "    loss = criterion(outputs, y)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "# Optional tiny wrapper if you prefer an explicit name for \"auto-context from training\":\n",
        "@torch.no_grad()\n",
        "def testlosses_with_auto_context(model, x, y, X_train, Y_train, points_per_context=10, replace=True):\n",
        "    return testlosses(\n",
        "        model, x, y,\n",
        "        context=None,\n",
        "        context_from_training=(X_train, Y_train),\n",
        "        points_per_context=points_per_context,\n",
        "        replace=replace\n",
        "    )\n",
        "\n",
        "\n",
        "def trainloop(model,\n",
        "              optimizer,\n",
        "              x_train,\n",
        "              y_train,\n",
        "              NUM_EPOCHS,\n",
        "              batch_size=64,\n",
        "              x_val=None,\n",
        "              y_val=None,\n",
        "              return_training_losses=False,\n",
        "              return_val_curve=True,\n",
        "              context=None,\n",
        "              shuffle=True,\n",
        "              eval_every_secs=1.0):\n",
        "    \"\"\"\n",
        "    x_train: [N, in_dim], y_train: [N, out_dim]\n",
        "    x_val/y_val optional for periodic validation curve.\n",
        "    context (optional):\n",
        "        - [1, C]  -> broadcast to each batch\n",
        "        - [N, C]  -> per-sample; batches are sliced accordingly\n",
        "    \"\"\"\n",
        "    device = model_device(model)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    N = x_train.size(0)\n",
        "    x_train = x_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "\n",
        "    # Prepare context handling\n",
        "    ctx_all = None\n",
        "    if context is not None:\n",
        "        ctx_all = context.to(device)\n",
        "        if ctx_all.dim() == 2 and ctx_all.size(0) not in (1, N):\n",
        "            raise ValueError(f\"context first dim must be 1 or N={N}, got {ctx_all.size(0)}\")\n",
        "\n",
        "    xs, ys = [], []\n",
        "    if return_training_losses:\n",
        "        train_losses = []\n",
        "\n",
        "    # Timing-based validation logging\n",
        "    last_eval_t = time.time()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(NUM_EPOCHS):\n",
        "        # build indices\n",
        "        if shuffle:\n",
        "            idx = torch.randperm(N, device=device)\n",
        "        else:\n",
        "            idx = torch.arange(N, device=device)\n",
        "\n",
        "        # mini-batches\n",
        "        for start in range(0, N, batch_size):\n",
        "            end = min(start + batch_size, N)\n",
        "            bidx = idx[start:end]\n",
        "\n",
        "            xb = x_train[bidx]\n",
        "            yb = y_train[bidx]\n",
        "\n",
        "            if ctx_all is not None:\n",
        "                if ctx_all.size(0) == 1:\n",
        "                    ctxb = ctx_all.expand(xb.size(0), -1)\n",
        "                else:\n",
        "                    ctxb = ctx_all[bidx]\n",
        "            else:\n",
        "                ctxb = None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            if ctxb is not None:\n",
        "                out = model(xb, ctxb)\n",
        "            else:\n",
        "                out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if return_training_losses:\n",
        "                train_losses.append(loss.item())\n",
        "\n",
        "            # periodic validation\n",
        "            if return_val_curve and (time.time() - last_eval_t >= eval_every_secs) and (x_val is not None) and (y_val is not None):\n",
        "                xs.append(xs[-1] + (time.time() - last_eval_t) if xs else 0.0)\n",
        "                last_eval_t = time.time()\n",
        "                ys.append(testlosses(model, x_val, y_val, context=ctx_all if (ctx_all is not None and ctx_all.size(0) == 1) else None))\n",
        "\n",
        "    if return_training_losses and return_val_curve and x_val is not None and y_val is not None:\n",
        "        return train_losses, (xs, ys)\n",
        "    if return_training_losses:\n",
        "        return train_losses\n",
        "    if return_val_curve and x_val is not None and y_val is not None:\n",
        "        return xs, ys\n",
        "\n",
        "def train_routers_for_all_layers_with_decoders(datasets_per_layer, routers, decoders, layer_sizes,\n",
        "                                               k=0.5, epochs=10, batch_size=64, lr=1e-3, device='cpu'):\n",
        "    trained = []\n",
        "    for ds, r, dec, (in_f, out_f) in zip(datasets_per_layer, routers, decoders, layer_sizes):\n",
        "        trained.append(\n",
        "            train_router_with_decoder(r, dec, ds, in_f=in_f, out_f=out_f, k=k,\n",
        "                                      epochs=epochs, batch_size=batch_size, lr=lr, device=device)\n",
        "        )\n",
        "    return trained"
      ],
      "metadata": {
        "id": "9kxtDJhAoS1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sets_to_test=['breastmnist' ,'dermamnist','octmnist','chestmnist','pneumoniamnist','organamnist','organcmnist','organsmnist','pathmnist']\n",
        "train_loader = get_combined_medmnist_loader(data_sets_to_test, batch_size=128)"
      ],
      "metadata": {
        "id": "BBWs-MR8oVg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa4b483-7408-434d-978c-c528a2d6eb44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.7M/19.7M [00:02<00:00, 9.55MB/s]\n",
            "100%|██████████| 54.9M/54.9M [00:03<00:00, 14.3MB/s]\n",
            "100%|██████████| 82.8M/82.8M [00:04<00:00, 17.4MB/s]\n",
            "100%|██████████| 4.17M/4.17M [00:01<00:00, 3.05MB/s]\n",
            "100%|██████████| 38.2M/38.2M [00:02<00:00, 13.6MB/s]\n",
            "100%|██████████| 15.5M/15.5M [00:01<00:00, 8.15MB/s]\n",
            "100%|██████████| 16.5M/16.5M [00:01<00:00, 8.70MB/s]\n",
            "100%|██████████| 206M/206M [00:12<00:00, 16.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- config ---\n",
        "n_low = 4\n",
        "n_high = 5\n",
        "m = 4\n",
        "plot_dict = {n: [] for n in range(n_low, n_high)}\n",
        "classic_plot_dict = {n: [] for n in range(n_low, n_high)}\n",
        "model_dict = {}\n",
        "d = 1\n",
        "w = 2**m\n",
        "default_embed_dim = 128\n",
        "\n",
        "layer_sizes = [[3*28*28, w]]\n",
        "for _ in range(d):\n",
        "    layer_sizes.append([w, w])\n",
        "layer_sizes.append([w, 14])\n",
        "\n",
        "def model_device(model):\n",
        "    return next(model.parameters()).device\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "k_top = 0.5\n",
        "\n",
        "runs = 1\n",
        "\n",
        "datasets_per_layer, base_snaps = prepare_router_datasets(\n",
        "    layer_sizes,\n",
        "    internal_samples=1000,\n",
        "    k=k_top,\n",
        "    device=device,\n",
        "    contexts_per_task=10,         # many contexts share the same mask\n",
        "    points_per_context=10,        # IO pairs per context\n",
        "    dataloader=train_loader,      # <- NEW\n",
        ")\n",
        "\n",
        "print(\"Dataset Constructed\")\n",
        "\n",
        "# infer context size from any per-layer dataset\n",
        "context_size = datasets_per_layer[0].contexts.shape[1]\n",
        "\n",
        "# 2) Pretrain autoencoders on masks (decoders frozen)\n",
        "decoders, _aes = train_autoencoders_for_all_layers(\n",
        "    datasets_per_layer=datasets_per_layer,\n",
        "    layer_sizes=layer_sizes,\n",
        "    embed_dims=default_embed_dim,   # AE embed dim = decoder input dim\n",
        "    k=k_top,\n",
        "    epochs=20,\n",
        "    batch=256,\n",
        "    lr=1e-3,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"Decoders Trained (frozen)\")\n",
        "\n",
        "# 3) Sweep router capacity via hidden width (head size fixed = decoder embed dim)\n",
        "for n in range(n_low, n_high):\n",
        "    hidden_width = 2**n\n",
        "    embed_dim = default_embed_dim  # MUST match decoder input dim\n",
        "\n",
        "    routers_untrained = [\n",
        "        build_router_for_layer(context_size, embed_dim=embed_dim, hidden=hidden_width)\n",
        "        for (_in_f, _out_f) in layer_sizes\n",
        "    ]\n",
        "\n",
        "    routers_trained = train_routers_for_all_layers_with_decoders(\n",
        "                datasets_per_layer=datasets_per_layer,\n",
        "                routers=routers_untrained,\n",
        "                decoders=decoders,\n",
        "                layer_sizes=layer_sizes,\n",
        "                k=k_top,\n",
        "                epochs=10,\n",
        "                batch_size=128,\n",
        "                lr=1e-3,\n",
        "                device=device\n",
        "            )\n",
        "    if runs > 1:\n",
        "      print(\"Trainining Run 1 Complete\")\n",
        "    for run in range(runs-1):\n",
        "\n",
        "        datasets_per_layer, base_snaps = prepare_router_datasets(\n",
        "            layer_sizes,\n",
        "            internal_samples=100,\n",
        "            k=k_top,\n",
        "            device=device,\n",
        "            contexts_per_task=100,         # many contexts share the same mask\n",
        "            points_per_context=10          # IO pairs per context\n",
        "        )\n",
        "\n",
        "        routers_trained = train_routers_for_all_layers_with_decoders(\n",
        "            datasets_per_layer=datasets_per_layer,\n",
        "            routers=routers_trained,\n",
        "            decoders=decoders,\n",
        "            layer_sizes=layer_sizes,\n",
        "            k=k_top,\n",
        "            epochs=10,\n",
        "            batch_size=128,\n",
        "            lr=1e-3,\n",
        "            device=device\n",
        "        )\n",
        "        print(\"Trainining Run \"+str(run+2)+\" Complete\")\n",
        "    print(f\"Routers Trained (hidden={hidden_width}, embed_dim={embed_dim})\")\n",
        "\n",
        "\n",
        "    model_with_router = build_router_inference_model_with_decoders(\n",
        "        layer_sizes=layer_sizes,\n",
        "        routers_trained=routers_trained,\n",
        "        decoders=decoders,\n",
        "        base_snaps=base_snaps,\n",
        "        k=k_top,\n",
        "        device=device\n",
        "    )\n",
        "    model_dict[n] = model_with_router\n",
        "\n",
        "    num_params = sum(param.numel() for param in model_dict[n].parameters() if param.requires_grad)\n",
        "    # we want num_params to equal the number of learnable paramets in our classic model\n",
        "    # that is, we want num_params = (c+3*28*28)*w+w+d*w*w+d*w+w*14+14\n",
        "    # so, solve for w to get w=-(2367 + context_dim + d - math.sqrt(5602689 + context_dim**2 + 4678*d + d**2 + 2*context_dim*(2367 + d) + 4*d*num_params))/(2*d)\n",
        "    points_per_context=10\n",
        "    xb0, yb0 = next(iter(train_loader))\n",
        "    in_dim  = xb0.reshape(xb0.size(0), -1).size(1)                  # flatten X → [N, in_dim]\n",
        "    out_dim = (_process_Y_to_2d(yb0)).size(1)                       # make Y 2D (one-hot if labels) → [N, out_dim]\n",
        "    context_dim = points_per_context * (in_dim + out_dim)\n",
        "    w=max(1,int(-(2367 + context_dim + d - math.sqrt(5602689 + context_dim**2 + 4678*d + d**2 + 2*context_dim*(2367 + d) + 4*d*num_params))/(2*d)))\n",
        "    # print(w)\n",
        "    classic_layer_sizes = [[in_dim, w]]\n",
        "    for _ in range(d):\n",
        "        classic_layer_sizes.append([w, w])\n",
        "    classic_layer_sizes.append([w, out_dim])\n",
        "\n",
        "    classic_model = ClassicNetwork(classic_layer_sizes, expect_context=True, context_dim=context_dim).to(device)\n",
        "    # print(sum(param.numel() for param in classic_model.parameters() if param.requires_grad)/num_params)\n",
        "    classic_model.eval()\n",
        "    model_with_router.eval()\n",
        "\n",
        "    # Build context bank (CPU)\n",
        "    context_bank_X = []\n",
        "    context_bank_Y = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in train_loader:\n",
        "            context_bank_X.append(xb.detach().cpu())\n",
        "            context_bank_Y.append(yb.detach().cpu())\n",
        "            if sum(x.shape[0] for x in context_bank_X) >= 5000:\n",
        "                break\n",
        "    X_bank = torch.cat(context_bank_X, dim=0)  # [N, ...]\n",
        "    Y_bank = torch.cat(context_bank_Y, dim=0)  # [N] or [N, ...]\n",
        "    num_classes = int(Y_bank.max().item()) + 1 if (Y_bank.dim() == 1 and Y_bank.dtype in (torch.int32, torch.int64)) else None\n",
        "\n",
        "    # ---- 2) Evaluate over some batches (can be the same train_loader or a val/test loader) ----\n",
        "    ys_router, xs = [], []\n",
        "    ys_classic = []\n",
        "    max_eval_batches = 1000   # how many batches to score for the curve\n",
        "    points_per_context = 10  # how many (x,y) pairs to include in each context row\n",
        "\n",
        "    with torch.no_grad():\n",
        "        bcount = 0\n",
        "        for x_eval, y_eval in train_loader:  # replace with val_loader if you have one\n",
        "            x_eval = x_eval.to(device)\n",
        "            y_eval = y_eval.to(device)\n",
        "\n",
        "            # Build a [1, C] context row on-the-fly from the bank and evaluate\n",
        "            loss = testlosses(\n",
        "                model_with_router, x_eval, y_eval,\n",
        "                context=None,\n",
        "                context_from_training=(X_bank, Y_bank),\n",
        "                points_per_context=points_per_context,\n",
        "                replace=True,\n",
        "            )\n",
        "            loss_classic = testlosses(\n",
        "                classic_model, x_eval, y_eval,\n",
        "                context=None,\n",
        "                context_from_training=(X_bank, Y_bank),\n",
        "                points_per_context=points_per_context,\n",
        "                replace=True,\n",
        "            )\n",
        "            ys_classic.append(loss_classic)\n",
        "            ys_router.append(loss)\n",
        "            xs.append(len(xs) + 1)\n",
        "\n",
        "            bcount += 1\n",
        "            if bcount >= max_eval_batches:\n",
        "                break\n",
        "\n",
        "    plot_dict[n] = (xs, ys_router)\n",
        "    classic_plot_dict[n] = (xs, ys_classic)\n",
        "\n",
        "# plot\n",
        "for n in range(n_low, n_high):\n",
        "    plt.plot(plot_dict[n][0], plot_dict[n][1], label=f\"Router (hidden={2**n}, embed={default_embed_dim})\")\n",
        "    plt.plot(classic_plot_dict[n][0], classic_plot_dict[n][1], label=f\"Classic (hidden={w})\")\n",
        "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")"
      ],
      "metadata": {
        "id": "v4ITiM4ioZNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "64925929-9f30-40a4-b0a0-65c5b1c9aab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Constructed\n",
            "Decoders Trained (frozen)\n",
            "Routers Trained (hidden=16, embed_dim=128)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ed9b09bf860>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}